 @keyframes go2264125279{from{transform:scale(0) rotate(45deg);opacity:0;}to{transform:scale(1) rotate(45deg);opacity:1;}}@keyframes go3020080000{from{transform:scale(0);opacity:0;}to{transform:scale(1);opacity:1;}}@keyframes go463499852{from{transform:scale(0) rotate(90deg);opacity:0;}to{transform:scale(1) rotate(90deg);opacity:1;}}@keyframes go1268368563{from{transform:rotate(0deg);}to{transform:rotate(360deg);}}@keyframes go1310225428{from{transform:scale(0) rotate(45deg);opacity:0;}to{transform:scale(1) rotate(45deg);opacity:1;}}@keyframes go651618207{0%{height:0;width:0;opacity:0;}40%{height:0;width:6px;opacity:1;}100%{opacity:1;height:10px;}}@keyframes go901347462{from{transform:scale(0.6);opacity:0.4;}to{transform:scale(1);opacity:1;}}.go4109123758{z-index:9999;}.go4109123758 > \*{pointer-events:auto;}:where(html\[dir="ltr"\]),:where(\[data-sonner-toaster\]\[dir="ltr"\]){--toast-icon-margin-start: -3px;--toast-icon-margin-end: 4px;--toast-svg-margin-start: -1px;--toast-svg-margin-end: 0px;--toast-button-margin-start: auto;--toast-button-margin-end: 0;--toast-close-button-start: 0;--toast-close-button-end: unset;--toast-close-button-transform: translate(-35%, -35%)}:where(html\[dir="rtl"\]),:where(\[data-sonner-toaster\]\[dir="rtl"\]){--toast-icon-margin-start: 4px;--toast-icon-margin-end: -3px;--toast-svg-margin-start: 0px;--toast-svg-margin-end: -1px;--toast-button-margin-start: 0;--toast-button-margin-end: auto;--toast-close-button-start: unset;--toast-close-button-end: 0;--toast-close-button-transform: translate(35%, -35%)}:where(\[data-sonner-toaster\]){position:fixed;width:var(--width);font-family:ui-sans-serif,system-ui,-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji;--gray1: hsl(0, 0%, 99%);--gray2: hsl(0, 0%, 97.3%);--gray3: hsl(0, 0%, 95.1%);--gray4: hsl(0, 0%, 93%);--gray5: hsl(0, 0%, 90.9%);--gray6: hsl(0, 0%, 88.7%);--gray7: hsl(0, 0%, 85.8%);--gray8: hsl(0, 0%, 78%);--gray9: hsl(0, 0%, 56.1%);--gray10: hsl(0, 0%, 52.3%);--gray11: hsl(0, 0%, 43.5%);--gray12: hsl(0, 0%, 9%);--border-radius: 8px;box-sizing:border-box;padding:0;margin:0;list-style:none;outline:none;z-index:999999999;transition:transform .4s ease}:where(\[data-sonner-toaster\]\[data-lifted="true"\]){transform:translateY(-10px)}@media (hover: none) and (pointer: coarse){:where(\[data-sonner-toaster\]\[data-lifted="true"\]){transform:none}}:where(\[data-sonner-toaster\]\[data-x-position="right"\]){right:var(--offset-right)}:where(\[data-sonner-toaster\]\[data-x-position="left"\]){left:var(--offset-left)}:where(\[data-sonner-toaster\]\[data-x-position="center"\]){left:50%;transform:translate(-50%)}:where(\[data-sonner-toaster\]\[data-y-position="top"\]){top:var(--offset-top)}:where(\[data-sonner-toaster\]\[data-y-position="bottom"\]){bottom:var(--offset-bottom)}:where(\[data-sonner-toast\]){--y: translateY(100%);--lift-amount: calc(var(--lift) \* var(--gap));z-index:var(--z-index);position:absolute;opacity:0;transform:var(--y);filter:blur(0);touch-action:none;transition:transform .4s,opacity .4s,height .4s,box-shadow .2s;box-sizing:border-box;outline:none;overflow-wrap:anywhere}:where(\[data-sonner-toast\]\[data-styled="true"\]){padding:16px;background:var(--normal-bg);border:1px solid var(--normal-border);color:var(--normal-text);border-radius:var(--border-radius);box-shadow:0 4px 12px #0000001a;width:var(--width);font-size:13px;display:flex;align-items:center;gap:6px}:where(\[data-sonner-toast\]:focus-visible){box-shadow:0 4px 12px #0000001a,0 0 0 2px #0003}:where(\[data-sonner-toast\]\[data-y-position="top"\]){top:0;--y: translateY(-100%);--lift: 1;--lift-amount: calc(1 \* var(--gap))}:where(\[data-sonner-toast\]\[data-y-position="bottom"\]){bottom:0;--y: translateY(100%);--lift: -1;--lift-amount: calc(var(--lift) \* var(--gap))}:where(\[data-sonner-toast\]) :where(\[data-description\]){font-weight:400;line-height:1.4;color:inherit}:where(\[data-sonner-toast\]) :where(\[data-title\]){font-weight:500;line-height:1.5;color:inherit}:where(\[data-sonner-toast\]) :where(\[data-icon\]){display:flex;height:16px;width:16px;position:relative;justify-content:flex-start;align-items:center;flex-shrink:0;margin-left:var(--toast-icon-margin-start);margin-right:var(--toast-icon-margin-end)}:where(\[data-sonner-toast\]\[data-promise="true"\]) :where(\[data-icon\])>svg{opacity:0;transform:scale(.8);transform-origin:center;animation:sonner-fade-in .3s ease forwards}:where(\[data-sonner-toast\]) :where(\[data-icon\])>\*{flex-shrink:0}:where(\[data-sonner-toast\]) :where(\[data-icon\]) svg{margin-left:var(--toast-svg-margin-start);margin-right:var(--toast-svg-margin-end)}:where(\[data-sonner-toast\]) :where(\[data-content\]){display:flex;flex-direction:column;gap:2px}\[data-sonner-toast\]\[data-styled=true\] \[data-button\]{border-radius:4px;padding-left:8px;padding-right:8px;height:24px;font-size:12px;color:var(--normal-bg);background:var(--normal-text);margin-left:var(--toast-button-margin-start);margin-right:var(--toast-button-margin-end);border:none;cursor:pointer;outline:none;display:flex;align-items:center;flex-shrink:0;transition:opacity .4s,box-shadow .2s}:where(\[data-sonner-toast\]) :where(\[data-button\]):focus-visible{box-shadow:0 0 0 2px #0006}:where(\[data-sonner-toast\]) :where(\[data-button\]):first-of-type{margin-left:var(--toast-button-margin-start);margin-right:var(--toast-button-margin-end)}:where(\[data-sonner-toast\]) :where(\[data-cancel\]){color:var(--normal-text);background:rgba(0,0,0,.08)}:where(\[data-sonner-toast\]\[data-theme="dark"\]) :where(\[data-cancel\]){background:rgba(255,255,255,.3)}:where(\[data-sonner-toast\]) :where(\[data-close-button\]){position:absolute;left:var(--toast-close-button-start);right:var(--toast-close-button-end);top:0;height:20px;width:20px;display:flex;justify-content:center;align-items:center;padding:0;color:var(--gray12);border:1px solid var(--gray4);transform:var(--toast-close-button-transform);border-radius:50%;cursor:pointer;z-index:1;transition:opacity .1s,background .2s,border-color .2s}\[data-sonner-toast\] \[data-close-button\]{background:var(--gray1)}:where(\[data-sonner-toast\]) :where(\[data-close-button\]):focus-visible{box-shadow:0 4px 12px #0000001a,0 0 0 2px #0003}:where(\[data-sonner-toast\]) :where(\[data-disabled="true"\]){cursor:not-allowed}:where(\[data-sonner-toast\]):hover :where(\[data-close-button\]):hover{background:var(--gray2);border-color:var(--gray5)}:where(\[data-sonner-toast\]\[data-swiping="true"\]):before{content:"";position:absolute;left:-50%;right:-50%;height:100%;z-index:-1}:where(\[data-sonner-toast\]\[data-y-position="top"\]\[data-swiping="true"\]):before{bottom:50%;transform:scaleY(3) translateY(50%)}:where(\[data-sonner-toast\]\[data-y-position="bottom"\]\[data-swiping="true"\]):before{top:50%;transform:scaleY(3) translateY(-50%)}:where(\[data-sonner-toast\]\[data-swiping="false"\]\[data-removed="true"\]):before{content:"";position:absolute;inset:0;transform:scaleY(2)}:where(\[data-sonner-toast\]):after{content:"";position:absolute;left:0;height:calc(var(--gap) + 1px);bottom:100%;width:100%}:where(\[data-sonner-toast\]\[data-mounted="true"\]){--y: translateY(0);opacity:1}:where(\[data-sonner-toast\]\[data-expanded="false"\]\[data-front="false"\]){--scale: var(--toasts-before) \* .05 + 1;--y: translateY(calc(var(--lift-amount) \* var(--toasts-before))) scale(calc(-1 \* var(--scale)));height:var(--front-toast-height)}:where(\[data-sonner-toast\])>\*{transition:opacity .4s}:where(\[data-sonner-toast\]\[data-expanded="false"\]\[data-front="false"\]\[data-styled="true"\])>\*{opacity:0}:where(\[data-sonner-toast\]\[data-visible="false"\]){opacity:0;pointer-events:none}:where(\[data-sonner-toast\]\[data-mounted="true"\]\[data-expanded="true"\]){--y: translateY(calc(var(--lift) \* var(--offset)));height:var(--initial-height)}:where(\[data-sonner-toast\]\[data-removed="true"\]\[data-front="true"\]\[data-swipe-out="false"\]){--y: translateY(calc(var(--lift) \* -100%));opacity:0}:where(\[data-sonner-toast\]\[data-removed="true"\]\[data-front="false"\]\[data-swipe-out="false"\]\[data-expanded="true"\]){--y: translateY(calc(var(--lift) \* var(--offset) + var(--lift) \* -100%));opacity:0}:where(\[data-sonner-toast\]\[data-removed="true"\]\[data-front="false"\]\[data-swipe-out="false"\]\[data-expanded="false"\]){--y: translateY(40%);opacity:0;transition:transform .5s,opacity .2s}:where(\[data-sonner-toast\]\[data-removed="true"\]\[data-front="false"\]):before{height:calc(var(--initial-height) + 20%)}\[data-sonner-toast\]\[data-swiping=true\]{transform:var(--y) translateY(var(--swipe-amount-y, 0px)) translate(var(--swipe-amount-x, 0px));transition:none}\[data-sonner-toast\]\[data-swiped=true\]{user-select:none}\[data-sonner-toast\]\[data-swipe-out=true\]\[data-y-position=bottom\],\[data-sonner-toast\]\[data-swipe-out=true\]\[data-y-position=top\]{animation-duration:.2s;animation-timing-function:ease-out;animation-fill-mode:forwards}\[data-sonner-toast\]\[data-swipe-out=true\]\[data-swipe-direction=left\]{animation-name:swipe-out-left}\[data-sonner-toast\]\[data-swipe-out=true\]\[data-swipe-direction=right\]{animation-name:swipe-out-right}\[data-sonner-toast\]\[data-swipe-out=true\]\[data-swipe-direction=up\]{animation-name:swipe-out-up}\[data-sonner-toast\]\[data-swipe-out=true\]\[data-swipe-direction=down\]{animation-name:swipe-out-down}@keyframes swipe-out-left{0%{transform:var(--y) translate(var(--swipe-amount-x));opacity:1}to{transform:var(--y) translate(calc(var(--swipe-amount-x) - 100%));opacity:0}}@keyframes swipe-out-right{0%{transform:var(--y) translate(var(--swipe-amount-x));opacity:1}to{transform:var(--y) translate(calc(var(--swipe-amount-x) + 100%));opacity:0}}@keyframes swipe-out-up{0%{transform:var(--y) translateY(var(--swipe-amount-y));opacity:1}to{transform:var(--y) translateY(calc(var(--swipe-amount-y) - 100%));opacity:0}}@keyframes swipe-out-down{0%{transform:var(--y) translateY(var(--swipe-amount-y));opacity:1}to{transform:var(--y) translateY(calc(var(--swipe-amount-y) + 100%));opacity:0}}@media (max-width: 600px){\[data-sonner-toaster\]{position:fixed;right:var(--mobile-offset-right);left:var(--mobile-offset-left);width:100%}\[data-sonner-toaster\]\[dir=rtl\]{left:calc(var(--mobile-offset-left) \* -1)}\[data-sonner-toaster\] \[data-sonner-toast\]{left:0;right:0;width:calc(100% - var(--mobile-offset-left) \* 2)}\[data-sonner-toaster\]\[data-x-position=left\]{left:var(--mobile-offset-left)}\[data-sonner-toaster\]\[data-y-position=bottom\]{bottom:var(--mobile-offset-bottom)}\[data-sonner-toaster\]\[data-y-position=top\]{top:var(--mobile-offset-top)}\[data-sonner-toaster\]\[data-x-position=center\]{left:var(--mobile-offset-left);right:var(--mobile-offset-right);transform:none}}\[data-sonner-toaster\]\[data-theme=light\]{--normal-bg: #fff;--normal-border: var(--gray4);--normal-text: var(--gray12);--success-bg: hsl(143, 85%, 96%);--success-border: hsl(145, 92%, 91%);--success-text: hsl(140, 100%, 27%);--info-bg: hsl(208, 100%, 97%);--info-border: hsl(221, 91%, 91%);--info-text: hsl(210, 92%, 45%);--warning-bg: hsl(49, 100%, 97%);--warning-border: hsl(49, 91%, 91%);--warning-text: hsl(31, 92%, 45%);--error-bg: hsl(359, 100%, 97%);--error-border: hsl(359, 100%, 94%);--error-text: hsl(360, 100%, 45%)}\[data-sonner-toaster\]\[data-theme=light\] \[data-sonner-toast\]\[data-invert=true\]{--normal-bg: #000;--normal-border: hsl(0, 0%, 20%);--normal-text: var(--gray1)}\[data-sonner-toaster\]\[data-theme=dark\] \[data-sonner-toast\]\[data-invert=true\]{--normal-bg: #fff;--normal-border: var(--gray3);--normal-text: var(--gray12)}\[data-sonner-toaster\]\[data-theme=dark\]{--normal-bg: #000;--normal-bg-hover: hsl(0, 0%, 12%);--normal-border: hsl(0, 0%, 20%);--normal-border-hover: hsl(0, 0%, 25%);--normal-text: var(--gray1);--success-bg: hsl(150, 100%, 6%);--success-border: hsl(147, 100%, 12%);--success-text: hsl(150, 86%, 65%);--info-bg: hsl(215, 100%, 6%);--info-border: hsl(223, 100%, 12%);--info-text: hsl(216, 87%, 65%);--warning-bg: hsl(64, 100%, 6%);--warning-border: hsl(60, 100%, 12%);--warning-text: hsl(46, 87%, 65%);--error-bg: hsl(358, 76%, 10%);--error-border: hsl(357, 89%, 16%);--error-text: hsl(358, 100%, 81%)}\[data-sonner-toaster\]\[data-theme=dark\] \[data-sonner-toast\] \[data-close-button\]{background:var(--normal-bg);border-color:var(--normal-border);color:var(--normal-text)}\[data-sonner-toaster\]\[data-theme=dark\] \[data-sonner-toast\] \[data-close-button\]:hover{background:var(--normal-bg-hover);border-color:var(--normal-border-hover)}\[data-rich-colors=true\]\[data-sonner-toast\]\[data-type=success\],\[data-rich-colors=true\]\[data-sonner-toast\]\[data-type=success\] \[data-close-button\]{background:var(--success-bg);border-color:var(--success-border);color:var(--success-text)}\[data-rich-colors=true\]\[data-sonner-toast\]\[data-type=info\],\[data-rich-colors=true\]\[data-sonner-toast\]\[data-type=info\] \[data-close-button\]{background:var(--info-bg);border-color:var(--info-border);color:var(--info-text)}\[data-rich-colors=true\]\[data-sonner-toast\]\[data-type=warning\],\[data-rich-colors=true\]\[data-sonner-toast\]\[data-type=warning\] \[data-close-button\]{background:var(--warning-bg);border-color:var(--warning-border);color:var(--warning-text)}\[data-rich-colors=true\]\[data-sonner-toast\]\[data-type=error\],\[data-rich-colors=true\]\[data-sonner-toast\]\[data-type=error\] \[data-close-button\]{background:var(--error-bg);border-color:var(--error-border);color:var(--error-text)}.sonner-loading-wrapper{--size: 16px;height:var(--size);width:var(--size);position:absolute;inset:0;z-index:10}.sonner-loading-wrapper\[data-visible=false\]{transform-origin:center;animation:sonner-fade-out .2s ease forwards}.sonner-spinner{position:relative;top:50%;left:50%;height:var(--size);width:var(--size)}.sonner-loading-bar{animation:sonner-spin 1.2s linear infinite;background:var(--gray11);border-radius:6px;height:8%;left:-10%;position:absolute;top:-3.9%;width:24%}.sonner-loading-bar:nth-child(1){animation-delay:-1.2s;transform:rotate(.0001deg) translate(146%)}.sonner-loading-bar:nth-child(2){animation-delay:-1.1s;transform:rotate(30deg) translate(146%)}.sonner-loading-bar:nth-child(3){animation-delay:-1s;transform:rotate(60deg) translate(146%)}.sonner-loading-bar:nth-child(4){animation-delay:-.9s;transform:rotate(90deg) translate(146%)}.sonner-loading-bar:nth-child(5){animation-delay:-.8s;transform:rotate(120deg) translate(146%)}.sonner-loading-bar:nth-child(6){animation-delay:-.7s;transform:rotate(150deg) translate(146%)}.sonner-loading-bar:nth-child(7){animation-delay:-.6s;transform:rotate(180deg) translate(146%)}.sonner-loading-bar:nth-child(8){animation-delay:-.5s;transform:rotate(210deg) translate(146%)}.sonner-loading-bar:nth-child(9){animation-delay:-.4s;transform:rotate(240deg) translate(146%)}.sonner-loading-bar:nth-child(10){animation-delay:-.3s;transform:rotate(270deg) translate(146%)}.sonner-loading-bar:nth-child(11){animation-delay:-.2s;transform:rotate(300deg) translate(146%)}.sonner-loading-bar:nth-child(12){animation-delay:-.1s;transform:rotate(330deg) translate(146%)}@keyframes sonner-fade-in{0%{opacity:0;transform:scale(.8)}to{opacity:1;transform:scale(1)}}@keyframes sonner-fade-out{0%{opacity:1;transform:scale(1)}to{opacity:0;transform:scale(.8)}}@keyframes sonner-spin{0%{opacity:1}to{opacity:.15}}@media (prefers-reduced-motion){\[data-sonner-toast\],\[data-sonner-toast\]>\*,.sonner-loading-bar{transition:none!important;animation:none!important}}.sonner-loader{position:absolute;top:50%;left:50%;transform:translate(-50%,-50%);transform-origin:center;transition:opacity .2s,transform .2s}.sonner-loader\[data-visible=false\]{opacity:0;transform:scale(.8) translate(-50%,-50%)} Structured Outputs - GroqDocs/\* For our datagrail consent banner \*/ /\* https://docs.datagrail.io/docs/consent/banner/css-customization/ \*/ :host(.dg-consent-banner) { /\* Fonts - matching Groq Console system \*/ --dg-primary-font: Inter, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif; --dg-secondary-font: Montserrat, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif; /\* General banner styling \*/ --dg-consent-background-color: rgb(255, 255, 255); --dg-consent-background-border: rgb(231, 229, 228); --consent-border-radius: 12px; /\* Body text styling \*/ --dg-body-font-size: 14px; --dg-body-font-weight: 400; --dg-body-font-color: rgb(118, 111, 107); --dg-body-line-height: 1.5; /\* Heading styling \*/ --dg-heading-font-size: 18px; --dg-heading-font-weight: 600; --dg-heading-font-color: rgb(12, 10, 9); --dg-heading-line-height: 1.4; /\* Title styling \*/ --dg-title-font-size: 16px; --dg-title-font-weight: 500; --dg-title-font-color: rgb(30, 30, 30); --dg-title-line-height: 1.4; /\* Button styling \*/ --dg-button-border: rgb(231, 229, 228) 1px solid; --dg-button-primary-background: rgb(30, 30, 30); --dg-button-primary-color: rgb(248, 248, 247); --dg-button-secondary-background: rgb(243, 243, 242); --dg-button-secondary-color: rgb(28, 25, 23); /\* Category styling \*/ --dg-policy-option-heading-size: 15px; --dg-policy-option-heading-weight: 500; --dg-policy-option-heading-color: rgb(30, 30, 30); --dg-policy-option-heading-enabled-color: rgb(245, 80, 54); --dg-policy-option-chevron-size: 16; /\* Category description \*/ --dg-policy-option-description-font-size: 13px; --dg-policy-option-description-font-weight: 400; --dg-policy-option-description-font-color: rgb(118, 111, 107); /\* Essential categories \*/ --dg-policy-option-essential-label-font-size: 12px; --dg-policy-option-essential-label-font-weight: 500; --dg-policy-option-essential-label-font-color: rgb(118, 111, 107); /\* Slider styling - inspired by switch component \*/ --dg-slider-primary: rgb(231, 229, 228); --dg-slider-secondary: rgb(255, 255, 255); --dg-slider-enabled-primary: rgb(30, 30, 30); --dg-slider-enabled-secondary: rgb(255, 255, 255); /\* For Enabled Categories \*/ --dg-policy-option-heading-enabled-color: rgb(245, 80, 54); } :host(.dg-consent-banner) strong { font-weight: 500; } /\* Slider styling for checked enabled categories \*/ :host(.dg-consent-banner) input\[type="checkbox"\]:not(:disabled):checked + label .dg-slider { background: rgb(30, 30, 30) !important; } /\* Advanced button styling to match Groq Console \*/ :host(.dg-consent-banner) .dg-button { border-radius: 8px !important; padding: 8px 16px !important; font-weight: 500 !important; font-size: 14px !important; transition: all 0.2s ease !important; } :host(.dg-consent-banner) .dg-button.accept\_all, :host(.dg-consent-banner) .dg-button.accept\_some, :host(.dg-consent-banner) .dg-button.reject\_all, :host(.dg-consent-banner) .dg-button.open\_layer, :host(.dg-consent-banner) .dg-button.custom { background: rgb(243, 243, 242) !important; color: rgb(28, 25, 23) !important; border: 1px solid rgb(231, 229, 228) !important; } :host(.dg-consent-banner) .dg-button.accept\_all:hover, :host(.dg-consent-banner) .dg-button.accept\_some:hover, :host(.dg-consent-banner) .dg-button.reject\_all:hover, :host(.dg-consent-banner) .dg-button.open\_layer:hover, :host(.dg-consent-banner) .dg-button.custom:hover { background: rgb(231, 229, 228) !important; } /\* Link styling to match Groq Console \*/ :host(.dg-consent-banner) .dg-link { color: rgb(245, 80, 54) !important; text-decoration: none !important; font-weight: 500 !important; } :host(.dg-consent-banner) .dg-link:hover { text-decoration: underline !important; } :host(.dg-consent-banner) .dg-main-content-policy-option-description p { margin-top: 0 !important; margin-bottom: 16px; } /\* Dark mode support \*/ :host(.dg-consent-banner) .dark { --dg-consent-background-color: rgb(18, 20, 24); --dg-consent-background-border: rgba(153, 153, 153, 0.161); --dg-body-font-color: rgb(165, 160, 156); --dg-heading-font-color: rgb(248, 248, 247); --dg-title-font-color: rgb(248, 248, 247); --dg-policy-option-heading-color: rgb(248, 248, 247); --dg-button-secondary-background: rgb(38, 38, 38); --dg-button-secondary-color: rgb(248, 248, 247); --dg-slider-primary: rgba(153, 153, 153, 0.35); --dg-slider-background: rgb(107, 114, 128); } /\* Overall banner container styling \*/ :host(.dg-consent-banner) .dg-app { box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -2px rgba(0, 0, 0, 0.1) !important; border: 1px solid rgb(231, 229, 228) !important; } !function(){try{var d=document.documentElement,c=d.classList;c.remove('light','dark');var e=localStorage.getItem('theme');if('system'===e||(!e&&true)){var t='(prefers-color-scheme: dark)',m=window.matchMedia(t);if(m.media!==t||m.matches){d.style.colorScheme = 'dark';c.add('dark')}else{d.style.colorScheme = 'light';c.add('light')}}else if(e){c.add(e|| '')}if(e==='light'||e==='dark')d.style.colorScheme=e}catch(e){}}()(self.\_\_next\_f=self.\_\_next\_f||\[\]).push(\[0\])self.\_\_next\_f.push(\[1,"1:\\"$Sreact.fragment\\"\\n3:I\[53692,\[\],\\"ClientSegmentRoot\\"\]\\n4:I\[30352,\[\\"8779\\",\\"static/chunks/8285d696-4c2af9547952b91b.js\\",\\"3596\\",\\"static/chunks/3596-81e8162c1dd9940f.js\\",\\"9170\\",\\"static/chunks/9170-d2c224567d46ff41.js\\",\\"1874\\",\\"static/chunks/1874-1af85b5fe730b1d1.js\\",\\"6603\\",\\"static/chunks/6603-5a9bea7a37afd382.js\\",\\"5193\\",\\"static/chunks/5193-5a50519070c43274.js\\",\\"888\\",\\"static/chunks/888-7cd7f38e76441637.js\\",\\"1466\\",\\"static/chunks/1466-ba3c67344a908bbe.js\\",\\"1727\\",\\"static/chunks/1727-8cb7c763d81e3223.js\\",\\"4215\\",\\"static/chunks/4215-210105fc188a4582.js\\",\\"8285\\",\\"static/chunks/8285-cf692dbe291dd0a9.js\\",\\"5674\\",\\"static/chunks/5674-883f5bd3e8483206.js\\",\\"3528\\",\\"static/chunks/3528-5e66c33acdac1843.js\\",\\"5789\\",\\"static/chunks/5789-d4359a1055e0aacd.js\\",\\"7860\\",\\"static/chunks/7860-a6cd4bd13b0a2513.js\\",\\"4209\\",\\"static/chunks/4209-19ded76058a94842.js\\",\\"9558\\",\\"static/chunks/9558-076fb64cebb3d532.js\\",\\"9870\\",\\"static/chunks/app/(console)/layout-77f984215e0a0987.js\\"\],\\"default\\"\]\\n5:I\[17421,\[\],\\"\\"\]\\n6:I\[47289,\[\],\\"\\"\]\\n9:I\[27666,\[\\"3596\\",\\"static/chunks/3596-81e8162c1dd9940f.js\\",\\"9170\\",\\"static/chunks/9170-d2c224567d46ff41.js\\",\\"888\\",\\"static/chunks/888-7cd7f38e76441637.js\\",\\"1466\\",\\"static/chunks/1466-ba3c67344a908bbe.js\\",\\"3148\\",\\"static/chunks/app/(console)/docs/(mdx-pages)/layout-11e495940bad72c6.js\\"\],\\"FeedbackCollector\\"\]\\na:I\[47864,\[\\"8779\\",\\"static/chunks/8285d696-4c2af9547952b91b.js\\",\\"3596\\",\\"static/chunks/3596-81e8162c1dd9940f.js\\",\\"9170\\",\\"static/chunks/9170-d2c224567d46ff41.js\\",\\"1874\\",\\"static/chunks/1874-1af85b5fe730b1d1.js\\",\\"3354\\",\\"static/chunks/3354-1c66ad7116e53618.js\\",\\"6603\\",\\"static/chunks/6603-5a9bea7a37afd382.js\\",\\"1103\\",\\"static/chunks/1103-6ee8bf0e353f128c.js\\",\\"7764\\",\\"static/chunks/7764-9237aa9acd440644.js\\",\\"5193\\",\\"static/chunks/5193-5a50519070c43274.js\\",\\"888\\",\\"static/chunks/888-7cd7f38e76441637.js\\",\\"1466\\",\\"static/chunks/1466-ba3c67344a908bbe.js\\",\\"1727\\",\\"static/chunks/1727-8cb7c763d81e3223.js\\",\\"4215\\",\\"static/chunks/4215-210105fc188a4582.js\\",\\"8285\\",\\"static/chunks/8285-cf692dbe291dd0a9.js\\",\\"1662\\",\\"static/chunks/1662-214b17dccb7b372e.js\\",\\"8708\\",\\"static/ch"\])self.\_\_next\_f.push(\[1,"unks/8708-4ccc2d8c82372303.js\\",\\"2266\\",\\"static/chunks/2266-da70c83850170f05.js\\",\\"1008\\",\\"static/chunks/1008-b91c14cb674bac7f.js\\",\\"6438\\",\\"static/chunks/6438-f6051aa8abcfb715.js\\",\\"4273\\",\\"static/chunks/4273-b4995127e1ab9b73.js\\",\\"5789\\",\\"static/chunks/5789-d4359a1055e0aacd.js\\",\\"4454\\",\\"static/chunks/4454-c3cbd02a8687a7b6.js\\",\\"7429\\",\\"static/chunks/7429-6f51c3e2c8a0b85a.js\\",\\"7538\\",\\"static/chunks/7538-f0ed33951d7e5274.js\\",\\"4170\\",\\"static/chunks/4170-eb09d77bcaed405c.js\\",\\"8052\\",\\"static/chunks/app/(console)/docs/(mdx-pages)/structured-outputs/page-b04830c0d0f91a8e.js\\"\],\\"CopyAsMarkdownButton\\"\]\\nb:I\[26179,\[\\"8779\\",\\"static/chunks/8285d696-4c2af9547952b91b.js\\",\\"3596\\",\\"static/chunks/3596-81e8162c1dd9940f.js\\",\\"9170\\",\\"static/chunks/9170-d2c224567d46ff41.js\\",\\"1874\\",\\"static/chunks/1874-1af85b5fe730b1d1.js\\",\\"3354\\",\\"static/chunks/3354-1c66ad7116e53618.js\\",\\"6603\\",\\"static/chunks/6603-5a9bea7a37afd382.js\\",\\"1103\\",\\"static/chunks/1103-6ee8bf0e353f128c.js\\",\\"7764\\",\\"static/chunks/7764-9237aa9acd440644.js\\",\\"5193\\",\\"static/chunks/5193-5a50519070c43274.js\\",\\"888\\",\\"static/chunks/888-7cd7f38e76441637.js\\",\\"1466\\",\\"static/chunks/1466-ba3c67344a908bbe.js\\",\\"1727\\",\\"static/chunks/1727-8cb7c763d81e3223.js\\",\\"4215\\",\\"static/chunks/4215-210105fc188a4582.js\\",\\"8285\\",\\"static/chunks/8285-cf692dbe291dd0a9.js\\",\\"1662\\",\\"static/chunks/1662-214b17dccb7b372e.js\\",\\"8708\\",\\"static/chunks/8708-4ccc2d8c82372303.js\\",\\"2266\\",\\"static/chunks/2266-da70c83850170f05.js\\",\\"1008\\",\\"static/chunks/1008-b91c14cb674bac7f.js\\",\\"6438\\",\\"static/chunks/6438-f6051aa8abcfb715.js\\",\\"4273\\",\\"static/chunks/4273-b4995127e1ab9b73.js\\",\\"5789\\",\\"static/chunks/5789-d4359a1055e0aacd.js\\",\\"4454\\",\\"static/chunks/4454-c3cbd02a8687a7b6.js\\",\\"7429\\",\\"static/chunks/7429-6f51c3e2c8a0b85a.js\\",\\"7538\\",\\"static/chunks/7538-f0ed33951d7e5274.js\\",\\"4170\\",\\"static/chunks/4170-eb09d77bcaed405c.js\\",\\"8052\\",\\"static/chunks/app/(console)/docs/(mdx-pages)/structured-outputs/page-b04830c0d0f91a8e.js\\"\],\\"Link\\"\]\\nc:I\[24544,\[\\"8779\\",\\"static/chunks/8285d696-4c2af9547952b91b.js\\",\\"3596\\",\\"static/chunks/3596-81e8162c1dd9940f.js\\",\\"9170\\",\\"static/chunks/9170-d2c2"\])self.\_\_next\_f.push(\[1,"24567d46ff41.js\\",\\"1874\\",\\"static/chunks/1874-1af85b5fe730b1d1.js\\",\\"3354\\",\\"static/chunks/3354-1c66ad7116e53618.js\\",\\"6603\\",\\"static/chunks/6603-5a9bea7a37afd382.js\\",\\"1103\\",\\"static/chunks/1103-6ee8bf0e353f128c.js\\",\\"7764\\",\\"static/chunks/7764-9237aa9acd440644.js\\",\\"5193\\",\\"static/chunks/5193-5a50519070c43274.js\\",\\"888\\",\\"static/chunks/888-7cd7f38e76441637.js\\",\\"1466\\",\\"static/chunks/1466-ba3c67344a908bbe.js\\",\\"1727\\",\\"static/chunks/1727-8cb7c763d81e3223.js\\",\\"4215\\",\\"static/chunks/4215-210105fc188a4582.js\\",\\"8285\\",\\"static/chunks/8285-cf692dbe291dd0a9.js\\",\\"1662\\",\\"static/chunks/1662-214b17dccb7b372e.js\\",\\"8708\\",\\"static/chunks/8708-4ccc2d8c82372303.js\\",\\"2266\\",\\"static/chunks/2266-da70c83850170f05.js\\",\\"1008\\",\\"static/chunks/1008-b91c14cb674bac7f.js\\",\\"6438\\",\\"static/chunks/6438-f6051aa8abcfb715.js\\",\\"4273\\",\\"static/chunks/4273-b4995127e1ab9b73.js\\",\\"5789\\",\\"static/chunks/5789-d4359a1055e0aacd.js\\",\\"4454\\",\\"static/chunks/4454-c3cbd02a8687a7b6.js\\",\\"7429\\",\\"static/chunks/7429-6f51c3e2c8a0b85a.js\\",\\"7538\\",\\"static/chunks/7538-f0ed33951d7e5274.js\\",\\"4170\\",\\"static/chunks/4170-eb09d77bcaed405c.js\\",\\"8052\\",\\"static/chunks/app/(console)/docs/(mdx-pages)/structured-outputs/page-b04830c0d0f91a8e.js\\"\],\\"CopyableCode\\"\]\\nd:I\[14454,\[\\"8779\\",\\"static/chunks/8285d696-4c2af9547952b91b.js\\",\\"3596\\",\\"static/chunks/3596-81e8162c1dd9940f.js\\",\\"9170\\",\\"static/chunks/9170-d2c224567d46ff41.js\\",\\"1874\\",\\"static/chunks/1874-1af85b5fe730b1d1.js\\",\\"3354\\",\\"static/chunks/3354-1c66ad7116e53618.js\\",\\"6603\\",\\"static/chunks/6603-5a9bea7a37afd382.js\\",\\"1103\\",\\"static/chunks/1103-6ee8bf0e353f128c.js\\",\\"7764\\",\\"static/chunks/7764-9237aa9acd440644.js\\",\\"5193\\",\\"static/chunks/5193-5a50519070c43274.js\\",\\"888\\",\\"static/chunks/888-7cd7f38e76441637.js\\",\\"1466\\",\\"static/chunks/1466-ba3c67344a908bbe.js\\",\\"1727\\",\\"static/chunks/1727-8cb7c763d81e3223.js\\",\\"4215\\",\\"static/chunks/4215-210105fc188a4582.js\\",\\"8285\\",\\"static/chunks/8285-cf692dbe291dd0a9.js\\",\\"1662\\",\\"static/chunks/1662-214b17dccb7b372e.js\\",\\"8708\\",\\"static/chunks/8708-4ccc2d8c82372303.js\\",\\"2266\\",\\"static/chunks/2266-da70c83850170f05.js\\",\\"1008\\",\\"static/chunks/1008-b91c14"\])self.\_\_next\_f.push(\[1,"cb674bac7f.js\\",\\"6438\\",\\"static/chunks/6438-f6051aa8abcfb715.js\\",\\"4273\\",\\"static/chunks/4273-b4995127e1ab9b73.js\\",\\"5789\\",\\"static/chunks/5789-d4359a1055e0aacd.js\\",\\"4454\\",\\"static/chunks/4454-c3cbd02a8687a7b6.js\\",\\"7429\\",\\"static/chunks/7429-6f51c3e2c8a0b85a.js\\",\\"7538\\",\\"static/chunks/7538-f0ed33951d7e5274.js\\",\\"4170\\",\\"static/chunks/4170-eb09d77bcaed405c.js\\",\\"8052\\",\\"static/chunks/app/(console)/docs/(mdx-pages)/structured-outputs/page-b04830c0d0f91a8e.js\\"\],\\"default\\"\]\\n11:I\[55876,\[\\"8779\\",\\"static/chunks/8285d696-4c2af9547952b91b.js\\",\\"3596\\",\\"static/chunks/3596-81e8162c1dd9940f.js\\",\\"9170\\",\\"static/chunks/9170-d2c224567d46ff41.js\\",\\"1874\\",\\"static/chunks/1874-1af85b5fe730b1d1.js\\",\\"3354\\",\\"static/chunks/3354-1c66ad7116e53618.js\\",\\"6603\\",\\"static/chunks/6603-5a9bea7a37afd382.js\\",\\"1103\\",\\"static/chunks/1103-6ee8bf0e353f128c.js\\",\\"7764\\",\\"static/chunks/7764-9237aa9acd440644.js\\",\\"5193\\",\\"static/chunks/5193-5a50519070c43274.js\\",\\"888\\",\\"static/chunks/888-7cd7f38e76441637.js\\",\\"1466\\",\\"static/chunks/1466-ba3c67344a908bbe.js\\",\\"1727\\",\\"static/chunks/1727-8cb7c763d81e3223.js\\",\\"4215\\",\\"static/chunks/4215-210105fc188a4582.js\\",\\"8285\\",\\"static/chunks/8285-cf692dbe291dd0a9.js\\",\\"1662\\",\\"static/chunks/1662-214b17dccb7b372e.js\\",\\"8708\\",\\"static/chunks/8708-4ccc2d8c82372303.js\\",\\"2266\\",\\"static/chunks/2266-da70c83850170f05.js\\",\\"1008\\",\\"static/chunks/1008-b91c14cb674bac7f.js\\",\\"6438\\",\\"static/chunks/6438-f6051aa8abcfb715.js\\",\\"4273\\",\\"static/chunks/4273-b4995127e1ab9b73.js\\",\\"5789\\",\\"static/chunks/5789-d4359a1055e0aacd.js\\",\\"4454\\",\\"static/chunks/4454-c3cbd02a8687a7b6.js\\",\\"7429\\",\\"static/chunks/7429-6f51c3e2c8a0b85a.js\\",\\"7538\\",\\"static/chunks/7538-f0ed33951d7e5274.js\\",\\"4170\\",\\"static/chunks/4170-eb09d77bcaed405c.js\\",\\"8052\\",\\"static/chunks/app/(console)/docs/(mdx-pages)/structured-outputs/page-b04830c0d0f91a8e.js\\"\],\\"default\\"\]\\n12:I\[15112,\[\\"8779\\",\\"static/chunks/8285d696-4c2af9547952b91b.js\\",\\"3596\\",\\"static/chunks/3596-81e8162c1dd9940f.js\\",\\"9170\\",\\"static/chunks/9170-d2c224567d46ff41.js\\",\\"1874\\",\\"static/chunks/1874-1af85b5fe730b1d1.js\\",\\"3354\\",\\"static/chunks/3354-1c66ad7116e53618.js\\",\\"6603\\","\])self.\_\_next\_f.push(\[1,"\\"static/chunks/6603-5a9bea7a37afd382.js\\",\\"1103\\",\\"static/chunks/1103-6ee8bf0e353f128c.js\\",\\"7764\\",\\"static/chunks/7764-9237aa9acd440644.js\\",\\"5193\\",\\"static/chunks/5193-5a50519070c43274.js\\",\\"888\\",\\"static/chunks/888-7cd7f38e76441637.js\\",\\"1466\\",\\"static/chunks/1466-ba3c67344a908bbe.js\\",\\"1727\\",\\"static/chunks/1727-8cb7c763d81e3223.js\\",\\"4215\\",\\"static/chunks/4215-210105fc188a4582.js\\",\\"8285\\",\\"static/chunks/8285-cf692dbe291dd0a9.js\\",\\"1662\\",\\"static/chunks/1662-214b17dccb7b372e.js\\",\\"8708\\",\\"static/chunks/8708-4ccc2d8c82372303.js\\",\\"2266\\",\\"static/chunks/2266-da70c83850170f05.js\\",\\"1008\\",\\"static/chunks/1008-b91c14cb674bac7f.js\\",\\"6438\\",\\"static/chunks/6438-f6051aa8abcfb715.js\\",\\"4273\\",\\"static/chunks/4273-b4995127e1ab9b73.js\\",\\"5789\\",\\"static/chunks/5789-d4359a1055e0aacd.js\\",\\"4454\\",\\"static/chunks/4454-c3cbd02a8687a7b6.js\\",\\"7429\\",\\"static/chunks/7429-6f51c3e2c8a0b85a.js\\",\\"7538\\",\\"static/chunks/7538-f0ed33951d7e5274.js\\",\\"4170\\",\\"static/chunks/4170-eb09d77bcaed405c.js\\",\\"8052\\",\\"static/chunks/app/(console)/docs/(mdx-pages)/structured-outputs/page-b04830c0d0f91a8e.js\\"\],\\"ContentSwitcher\\"\]\\n13:I\[15112,\[\\"8779\\",\\"static/chunks/8285d696-4c2af9547952b91b.js\\",\\"3596\\",\\"static/chunks/3596-81e8162c1dd9940f.js\\",\\"9170\\",\\"static/chunks/9170-d2c224567d46ff41.js\\",\\"1874\\",\\"static/chunks/1874-1af85b5fe730b1d1.js\\",\\"3354\\",\\"static/chunks/3354-1c66ad7116e53618.js\\",\\"6603\\",\\"static/chunks/6603-5a9bea7a37afd382.js\\",\\"1103\\",\\"static/chunks/1103-6ee8bf0e353f128c.js\\",\\"7764\\",\\"static/chunks/7764-9237aa9acd440644.js\\",\\"5193\\",\\"static/chunks/5193-5a50519070c43274.js\\",\\"888\\",\\"static/chunks/888-7cd7f38e76441637.js\\",\\"1466\\",\\"static/chunks/1466-ba3c67344a908bbe.js\\",\\"1727\\",\\"static/chunks/1727-8cb7c763d81e3223.js\\",\\"4215\\",\\"static/chunks/4215-210105fc188a4582.js\\",\\"8285\\",\\"static/chunks/8285-cf692dbe291dd0a9.js\\",\\"1662\\",\\"static/chunks/1662-214b17dccb7b372e.js\\",\\"8708\\",\\"static/chunks/8708-4ccc2d8c82372303.js\\",\\"2266\\",\\"static/chunks/2266-da70c83850170f05.js\\",\\"1008\\",\\"static/chunks/1008-b91c14cb674bac7f.js\\",\\"6438\\",\\"static/chunks/6438-f6051aa8abcfb715.js\\",\\"4273\\",\\"static/chunks/4273-b4995127e1ab9b73.js\\",\\"5789"\])self.\_\_next\_f.push(\[1,"\\",\\"static/chunks/5789-d4359a1055e0aacd.js\\",\\"4454\\",\\"static/chunks/4454-c3cbd02a8687a7b6.js\\",\\"7429\\",\\"static/chunks/7429-6f51c3e2c8a0b85a.js\\",\\"7538\\",\\"static/chunks/7538-f0ed33951d7e5274.js\\",\\"4170\\",\\"static/chunks/4170-eb09d77bcaed405c.js\\",\\"8052\\",\\"static/chunks/app/(console)/docs/(mdx-pages)/structured-outputs/page-b04830c0d0f91a8e.js\\"\],\\"ContentItem\\"\]\\n26:I\[18195,\[\],\\"OutletBoundary\\"\]\\n29:I\[18195,\[\],\\"ViewportBoundary\\"\]\\n2b:I\[18195,\[\],\\"MetadataBoundary\\"\]\\n2d:I\[15065,\[\\"888\\",\\"static/chunks/888-7cd7f38e76441637.js\\",\\"1466\\",\\"static/chunks/1466-ba3c67344a908bbe.js\\",\\"4219\\",\\"static/chunks/app/global-error-008962f800b9c493.js\\"\],\\"default\\"\]\\n:HL\[\\"/\_next/static/media/17e5ee57c5ca5e5a-s.p.woff2\\",\\"font\\",{\\"crossOrigin\\":\\"\\",\\"type\\":\\"font/woff2\\"}\]\\n:HL\[\\"/\_next/static/media/36966cca54120369-s.p.woff2\\",\\"font\\",{\\"crossOrigin\\":\\"\\",\\"type\\":\\"font/woff2\\"}\]\\n:HL\[\\"/\_next/static/media/904be59b21bd51cb-s.p.woff2\\",\\"font\\",{\\"crossOrigin\\":\\"\\",\\"type\\":\\"font/woff2\\"}\]\\n:HL\[\\"/\_next/static/media/98e207f02528a563-s.p.woff2\\",\\"font\\",{\\"crossOrigin\\":\\"\\",\\"type\\":\\"font/woff2\\"}\]\\n:HL\[\\"/\_next/static/media/d3ebbfd689654d3a-s.p.woff2\\",\\"font\\",{\\"crossOrigin\\":\\"\\",\\"type\\":\\"font/woff2\\"}\]\\n:HL\[\\"/\_next/static/media/e4af272ccee01ff0-s.p.woff2\\",\\"font\\",{\\"crossOrigin\\":\\"\\",\\"type\\":\\"font/woff2\\"}\]\\n:HL\[\\"/\_next/static/media/f36144f235cd456e-s.p.woff2\\",\\"font\\",{\\"crossOrigin\\":\\"\\",\\"type\\":\\"font/woff2\\"}\]\\n:HL\[\\"/\_next/static/css/7bf466619b61d92d.css\\",\\"style\\"\]\\n:HL\[\\"/\_next/static/css/5f71e76d6445edb3.css\\",\\"style\\"\]\\n:HL\[\\"/\_next/static/css/c145a7ada77054e8.css\\",\\"style\\"\]\\n:HL\[\\"/\_next/static/css/0cec16494c374a65.css\\",\\"style\\"\]\\n:HL\[\\"/\_next/static/css/b1dbd2d25ec6d91f.css\\",\\"style\\"\]\\ne:T4bc,import Groq from \\"groq-sdk\\";\\n\\nconst groq = new Groq();\\n\\nconst response = await groq.chat.completions.create({\\n model: \\"moonshotai/kimi-k2-instruct-0905\\",\\n messages: \[\\n { role: \\"system\\", content: \\"Extract product review information from the text.\\" },\\n {\\n role: \\"user\\",\\n content: \\"I bought the UltraSound Headphones last week and I'm really impressed! The noise cancellation is amazing and the battery lasts all day. Sound quali"\])self.\_\_next\_f.push(\[1,"ty is crisp and clear. I'd give it 4.5 out of 5 stars.\\",\\n },\\n \],\\n response\_format: {\\n type: \\"json\_schema\\",\\n json\_schema: {\\n name: \\"product\_review\\",\\n schema: {\\n type: \\"object\\",\\n properties: {\\n product\_name: { type: \\"string\\" },\\n rating: { type: \\"number\\" },\\n sentiment: { \\n type: \\"string\\",\\n enum: \[\\"positive\\", \\"negative\\", \\"neutral\\"\]\\n },\\n key\_features: { \\n type: \\"array\\",\\n items: { type: \\"string\\" }\\n }\\n },\\n required: \[\\"product\_name\\", \\"rating\\", \\"sentiment\\", \\"key\_features\\"\],\\n additionalProperties: false\\n }\\n }\\n }\\n});\\n\\nconst result = JSON.parse(response.choices\[0\].message.content || \\"{}\\");\\nconsole.log(result);f:T433,from groq import Groq\\nfrom pydantic import BaseModel\\nfrom typing import Literal\\nimport json\\n\\nclient = Groq()\\n\\nclass ProductReview(BaseModel):\\n product\_name: str\\n rating: float\\n sentiment: Literal\[\\"positive\\", \\"negative\\", \\"neutral\\"\]\\n key\_features: list\[str\]\\n\\nresponse = client.chat.completions.create(\\n model=\\"moonshotai/kimi-k2-instruct-0905\\",\\n messages=\[\\n {\\"role\\": \\"system\\", \\"content\\": \\"Extract product review information from the text.\\"},\\n {\\n \\"role\\": \\"user\\",\\n \\"content\\": \\"I bought the UltraSound Headphones last week and I'm really impressed! The noise cancellation is amazing and the battery lasts all day. Sound quality is crisp and clear. I'd give it 4.5 out of 5 stars.\\",\\n },\\n \],\\n response\_format={\\n \\"type\\": \\"json\_schema\\",\\n \\"json\_schema\\": {\\n \\"name\\": \\"product\_review\\",\\n \\"schema\\": ProductReview.model\_json\_schema()\\n }\\n }\\n)\\n\\nreview = ProductReview.model\_validate(json.loads(response.choices\[0\].message.content))\\nprint(json.dumps(review.model\_dump(), indent=2))10:T511,curl https://api.groq.com/openai/v1/chat/completions \\\\\\n -H \\"Authorization: Bearer $GROQ\_API\_KEY\\" \\\\\\n -H \\"Content-Type: application/json\\" \\\\\\n -d '{\\n \\"model\\": \\"moonshotai/kimi-k2-instruct-"\])self.\_\_next\_f.push(\[1,"0905\\",\\n \\"messages\\": \[\\n {\\n \\"role\\": \\"system\\",\\n \\"content\\": \\"Extract product review information from the text.\\"\\n },\\n {\\n \\"role\\": \\"user\\",\\n \\"content\\": \\"I bought the UltraSound Headphones last week and I'\\\\''m really impressed! The noise cancellation is amazing and the battery lasts all day. Sound quality is crisp and clear. I'\\\\''d give it 4.5 out of 5 stars.\\"\\n }\\n \],\\n \\"response\_format\\": {\\n \\"type\\": \\"json\_schema\\",\\n \\"json\_schema\\": {\\n \\"name\\": \\"product\_review\\",\\n \\"schema\\": {\\n \\"type\\": \\"object\\",\\n \\"properties\\": {\\n \\"product\_name\\": { \\"type\\": \\"string\\" },\\n \\"rating\\": { \\"type\\": \\"number\\" },\\n \\"sentiment\\": { \\n \\"type\\": \\"string\\",\\n \\"enum\\": \[\\"positive\\", \\"negative\\", \\"neutral\\"\]\\n },\\n \\"key\_features\\": { \\n \\"type\\": \\"array\\",\\n \\"items\\": { \\"type\\": \\"string\\" }\\n }\\n },\\n \\"required\\": \[\\"product\_name\\", \\"rating\\", \\"sentiment\\", \\"key\_features\\"\],\\n \\"additionalProperties\\": false\\n }\\n }\\n }\\n }'14:T734,import Groq from \\"groq-sdk\\";\\n\\nconst groq = new Groq();\\n\\nconst response = await groq.chat.completions.create({\\n model: \\"moonshotai/kimi-k2-instruct-0905\\",\\n messages: \[\\n {\\n role: \\"system\\",\\n content: \\"You are a SQL expert. Generate structured SQL queries from natural language descriptions with proper syntax validation and metadata.\\",\\n },\\n { role: \\"user\\", content: \\"Find all customers who made orders over $500 in the last 30 days, show their name, email, and total order amount\\" },\\n \],\\n response\_format: {\\n type: \\"json\_schema\\",\\n json\_schema: {\\n name: \\"sql\_query\_generation\\",\\n schema: {\\n type: \\"object\\",\\n properties: {\\n query: { type: \\"string\\" },\\n query\_type: { \\n type: \\"string\\", \\n enum: \[\\"SELECT\\", \\"INSERT\\", \\"UPDATE\\", \\"DELETE\\", \\"CREATE\\", \\"ALTER\\", \\"DROP\\"\] \\n },\\n tables\_used: {\\n type: \\"array\\",\\n items: {"\])self.\_\_next\_f.push(\[1," type: \\"string\\" }\\n },\\n estimated\_complexity: {\\n type: \\"string\\",\\n enum: \[\\"low\\", \\"medium\\", \\"high\\"\]\\n },\\n execution\_notes: {\\n type: \\"array\\",\\n items: { type: \\"string\\" }\\n },\\n validation\_status: {\\n type: \\"object\\",\\n properties: {\\n is\_valid: { type: \\"boolean\\" },\\n syntax\_errors: {\\n type: \\"array\\",\\n items: { type: \\"string\\" }\\n }\\n },\\n required: \[\\"is\_valid\\", \\"syntax\_errors\\"\],\\n additionalProperties: false\\n }\\n },\\n required: \[\\"query\\", \\"query\_type\\", \\"tables\_used\\", \\"estimated\_complexity\\", \\"execution\_notes\\", \\"validation\_status\\"\],\\n additionalProperties: false\\n }\\n }\\n }\\n});\\n\\nconst result = JSON.parse(response.choices\[0\].message.content || \\"{}\\");\\nconsole.log(result);15:T4bc,from groq import Groq\\nfrom pydantic import BaseModel\\nimport json\\n\\nclient = Groq()\\n\\nclass ValidationStatus(BaseModel):\\n is\_valid: bool\\n syntax\_errors: list\[str\]\\n\\nclass SQLQueryGeneration(BaseModel):\\n query: str\\n query\_type: str\\n tables\_used: list\[str\]\\n estimated\_complexity: str\\n execution\_notes: list\[str\]\\n validation\_status: ValidationStatus\\n\\nresponse = client.chat.completions.create(\\n model=\\"moonshotai/kimi-k2-instruct-0905\\",\\n messages=\[\\n {\\n \\"role\\": \\"system\\",\\n \\"content\\": \\"You are a SQL expert. Generate structured SQL queries from natural language descriptions with proper syntax validation and metadata.\\",\\n },\\n {\\"role\\": \\"user\\", \\"content\\": \\"Find all customers who made orders over $500 in the last 30 days, show their name, email, and total order amount\\"},\\n \],\\n response\_format={\\n \\"type\\": \\"json\_schema\\",\\n \\"json\_schema\\": {\\n \\"name\\": \\"sql\_query\_generation\\",\\n \\"schema\\": SQLQueryGeneration.model\_json\_schema()\\n }\\n }\\n)\\n\\nsql\_query\_generation = SQLQueryGeneration.model\_validate(json.loads(response.choices\["\])self.\_\_next\_f.push(\[1,"0\].message.content))\\nprint(json.dumps(sql\_query\_generation.model\_dump(), indent=2))16:T7c9,curl https://api.groq.com/openai/v1/chat/completions \\\\\\n -H \\"Authorization: Bearer $GROQ\_API\_KEY\\" \\\\\\n -H \\"Content-Type: application/json\\" \\\\\\n -d '{\\n \\"model\\": \\"moonshotai/kimi-k2-instruct-0905\\",\\n \\"messages\\": \[\\n {\\n \\"role\\": \\"system\\",\\n \\"content\\": \\"You are a SQL expert. Generate structured SQL queries from natural language descriptions with proper syntax validation and metadata.\\"\\n },\\n {\\n \\"role\\": \\"user\\",\\n \\"content\\": \\"Find all customers who made orders over $500 in the last 30 days, show their name, email, and total order amount\\"\\n }\\n \],\\n \\"response\_format\\": {\\n \\"type\\": \\"json\_schema\\",\\n \\"json\_schema\\": {\\n \\"name\\": \\"sql\_query\_generation\\",\\n \\"schema\\": {\\n \\"type\\": \\"object\\",\\n \\"properties\\": {\\n \\"query\\": { \\"type\\": \\"string\\" },\\n \\"query\_type\\": { \\n \\"type\\": \\"string\\", \\n \\"enum\\": \[\\"SELECT\\", \\"INSERT\\", \\"UPDATE\\", \\"DELETE\\", \\"CREATE\\", \\"ALTER\\", \\"DROP\\"\] \\n },\\n \\"tables\_used\\": {\\n \\"type\\": \\"array\\",\\n \\"items\\": { \\"type\\": \\"string\\" }\\n },\\n \\"estimated\_complexity\\": {\\n \\"type\\": \\"string\\",\\n \\"enum\\": \[\\"low\\", \\"medium\\", \\"high\\"\]\\n },\\n \\"execution\_notes\\": {\\n \\"type\\": \\"array\\",\\n \\"items\\": { \\"type\\": \\"string\\" }\\n },\\n \\"validation\_status\\": {\\n \\"type\\": \\"object\\",\\n \\"properties\\": {\\n \\"is\_valid\\": { \\"type\\": \\"boolean\\" },\\n \\"syntax\_errors\\": {\\n \\"type\\": \\"array\\",\\n \\"items\\": { \\"type\\": \\"string\\" }\\n }\\n },\\n \\"required\\": \[\\"is\_valid\\", \\"syntax\_errors\\"\],\\n \\"additionalProperties\\": false\\n }\\n },\\n \\"required\\": \[\\"query\\", \\"query\_type\\", \\"tables\_used\\", \\"estimated\_complexity\\", \\"execution\_notes\\", \\"validation\_status\\"\],\\n \\"additionalProperties\\""\])self.\_\_next\_f.push(\[1,": false\\n }\\n }\\n }\\n }'17:T976,"\])self.\_\_next\_f.push(\[1,"import Groq from \\"groq-sdk\\";\\n\\nconst groq = new Groq();\\n\\nconst response = await groq.chat.completions.create({\\n model: \\"moonshotai/kimi-k2-instruct-0905\\",\\n messages: \[\\n {\\n role: \\"system\\",\\n content: \\"You are an email classification expert. Classify emails into structured categories with confidence scores, priority levels, and suggested actions.\\",\\n },\\n { role: \\"user\\", content: \\"Subject: URGENT: Server downtime affecting production\\\\n\\\\nHi Team,\\\\n\\\\nOur main production server went down at 2:30 PM EST. Customer-facing services are currently unavailable. We need immediate action to restore services. Please join the emergency call.\\\\n\\\\nBest regards,\\\\nDevOps Team\\" },\\n \],\\n response\_format: {\\n type: \\"json\_schema\\",\\n json\_schema: {\\n name: \\"email\_classification\\",\\n schema: {\\n type: \\"object\\",\\n properties: {\\n category: { \\n type: \\"string\\", \\n enum: \[\\"urgent\\", \\"support\\", \\"sales\\", \\"marketing\\", \\"internal\\", \\"spam\\", \\"notification\\"\] \\n },\\n priority: { \\n type: \\"string\\", \\n enum: \[\\"low\\", \\"medium\\", \\"high\\", \\"critical\\"\] \\n },\\n confidence\_score: { \\n type: \\"number\\", \\n minimum: 0, \\n maximum: 1 \\n },\\n sentiment: { \\n type: \\"string\\", \\n enum: \[\\"positive\\", \\"negative\\", \\"neutral\\"\] \\n },\\n key\_entities: {\\n type: \\"array\\",\\n items: {\\n type: \\"object\\",\\n properties: {\\n entity: { type: \\"string\\" },\\n type: { \\n type: \\"string\\", \\n enum: \[\\"person\\", \\"organization\\", \\"location\\", \\"datetime\\", \\"system\\", \\"product\\"\] \\n }\\n },\\n required: \[\\"entity\\", \\"type\\"\],\\n additionalProperties: false\\n }\\n },\\n suggested\_actions: {\\n type: \\"array\\",\\n items: { type: \\"string\\" }\\n },\\n requires\_immediate\_attention: { type: \\"boolean\\" },\\n estimated\_response\_time: { type: \\"string\\" }\\n },\\n required: \[\\"category\\", \\"priority\\", \\"confidence\_score\\", \\"sentiment\\", \\"key\_entities\\", \\"suggested\_actions\\", \\"requires\_immediate\_attention\\", \\"estimated\_response\_time\\"\],\\n additionalProperties: false\\n }\\n }\\n }\\n});\\n\\nconst result = JSON.parse(response.choices\[0\].message.content || \\"{}\\");\\nconsole.log(result);"\])self.\_\_next\_f.push(\[1,"18:T59f,from groq import Groq\\nfrom pydantic import BaseModel\\nimport json\\n\\nclient = Groq()\\n\\nclass KeyEntity(BaseModel):\\n entity: str\\n type: str\\n\\nclass EmailClassification(BaseModel):\\n category: str\\n priority: str\\n confidence\_score: float\\n sentiment: str\\n key\_entities: list\[KeyEntity\]\\n suggested\_actions: list\[str\]\\n requires\_immediate\_attention: bool\\n estimated\_response\_time: str\\n\\nresponse = client.chat.completions.create(\\n model=\\"moonshotai/kimi-k2-instruct-0905\\",\\n messages=\[\\n {\\n \\"role\\": \\"system\\",\\n \\"content\\": \\"You are an email classification expert. Classify emails into structured categories with confidence scores, priority levels, and suggested actions.\\",\\n },\\n {\\"role\\": \\"user\\", \\"content\\": \\"Subject: URGENT: Server downtime affecting production\\\\\\\\n\\\\\\\\nHi Team,\\\\\\\\n\\\\\\\\nOur main production server went down at 2:30 PM EST. Customer-facing services are currently unavailable. We need immediate action to restore services. Please join the emergency call.\\\\\\\\n\\\\\\\\nBest regards,\\\\\\\\nDevOps Team\\"},\\n \],\\n response\_format={\\n \\"type\\": \\"json\_schema\\",\\n \\"json\_schema\\": {\\n \\"name\\": \\"email\_classification\\",\\n \\"schema\\": EmailClassification.model\_json\_schema()\\n }\\n }\\n)\\n\\nemail\_classification = EmailClassification.model\_validate(json.loads(response.choices\[0\].message.content))\\nprint(json.dumps(email\_classification.model\_dump(), indent=2))19:Ta29,"\])self.\_\_next\_f.push(\[1,"curl https://api.groq.com/openai/v1/chat/completions \\\\\\n -H \\"Authorization: Bearer $GROQ\_API\_KEY\\" \\\\\\n -H \\"Content-Type: application/json\\" \\\\\\n -d '{\\n \\"model\\": \\"moonshotai/kimi-k2-instruct-0905\\",\\n \\"messages\\": \[\\n {\\n \\"role\\": \\"system\\",\\n \\"content\\": \\"You are an email classification expert. Classify emails into structured categories with confidence scores, priority levels, and suggested actions.\\"\\n },\\n {\\n \\"role\\": \\"user\\",\\n \\"content\\": \\"Subject: URGENT: Server downtime affecting production\\\\n\\\\nHi Team,\\\\n\\\\nOur main production server went down at 2:30 PM EST. Customer-facing services are currently unavailable. We need immediate action to restore services. Please join the emergency call.\\\\n\\\\nBest regards,\\\\nDevOps Team\\"\\n }\\n \],\\n \\"response\_format\\": {\\n \\"type\\": \\"json\_schema\\",\\n \\"json\_schema\\": {\\n \\"name\\": \\"email\_classification\\",\\n \\"schema\\": {\\n \\"type\\": \\"object\\",\\n \\"properties\\": {\\n \\"category\\": { \\n \\"type\\": \\"string\\", \\n \\"enum\\": \[\\"urgent\\", \\"support\\", \\"sales\\", \\"marketing\\", \\"internal\\", \\"spam\\", \\"notification\\"\] \\n },\\n \\"priority\\": { \\n \\"type\\": \\"string\\", \\n \\"enum\\": \[\\"low\\", \\"medium\\", \\"high\\", \\"critical\\"\] \\n },\\n \\"confidence\_score\\": { \\n \\"type\\": \\"number\\", \\n \\"minimum\\": 0, \\n \\"maximum\\": 1 \\n },\\n \\"sentiment\\": { \\n \\"type\\": \\"string\\", \\n \\"enum\\": \[\\"positive\\", \\"negative\\", \\"neutral\\"\] \\n },\\n \\"key\_entities\\": {\\n \\"type\\": \\"array\\",\\n \\"items\\": {\\n \\"type\\": \\"object\\",\\n \\"properties\\": {\\n \\"entity\\": { \\"type\\": \\"string\\" },\\n \\"type\\": { \\n \\"type\\": \\"string\\", \\n \\"enum\\": \[\\"person\\", \\"organization\\", \\"location\\", \\"datetime\\", \\"system\\", \\"product\\"\] \\n }\\n },\\n \\"required\\": \[\\"entity\\", \\"type\\"\],\\n \\"additionalProperties\\": false\\n }\\n },\\n \\"suggested\_actions\\": {\\n \\"type\\": \\"array\\",\\n \\"items\\": { \\"type\\": \\"string\\" }\\n },\\n \\"requires\_immediate\_attention\\": { \\"type\\": \\"boolean\\" },\\n \\"estimated\_response\_time\\": { \\"type\\": \\"string\\" }\\n },\\n \\"required\\": \[\\"category\\", \\"priority\\", \\"confidence\_score\\", \\"sentiment\\", \\"key\_entities\\", \\"suggested\_actions\\", \\"requires\_immediate\_attention\\", \\"estimated\_response\_time\\"\],\\n \\"additionalProperties\\": false\\n }\\n }\\n }\\n }'"\])self.\_\_next\_f.push(\[1,"1a:Tda5,"\])self.\_\_next\_f.push(\[1,"import Groq from \\"groq-sdk\\";\\n\\nconst groq = new Groq();\\n\\nconst response = await groq.chat.completions.create({\\n model: \\"moonshotai/kimi-k2-instruct-0905\\",\\n messages: \[\\n {\\n role: \\"system\\",\\n content: \\"You are an API response validation expert. Validate and structure API responses with error handling, status codes, and standardized data formats for reliable integration.\\",\\n },\\n { role: \\"user\\", content: \\"Validate this API response: {\\\\\\"user\_id\\\\\\": \\\\\\"12345\\\\\\", \\\\\\"email\\\\\\": \\\\\\"invalid-email\\\\\\", \\\\\\"created\_at\\\\\\": \\\\\\"2024-01-15T10:30:00Z\\\\\\", \\\\\\"status\\\\\\": \\\\\\"active\\\\\\", \\\\\\"profile\\\\\\": {\\\\\\"name\\\\\\": \\\\\\"John Doe\\\\\\", \\\\\\"age\\\\\\": 25}}\\" },\\n \],\\n response\_format: {\\n type: \\"json\_schema\\",\\n json\_schema: {\\n name: \\"api\_response\_validation\\",\\n schema: {\\n type: \\"object\\",\\n properties: {\\n validation\_result: {\\n type: \\"object\\",\\n properties: {\\n is\_valid: { type: \\"boolean\\" },\\n status\_code: { type: \\"integer\\" },\\n error\_count: { type: \\"integer\\" }\\n },\\n required: \[\\"is\_valid\\", \\"status\_code\\", \\"error\_count\\"\],\\n additionalProperties: false\\n },\\n field\_validations: {\\n type: \\"array\\",\\n items: {\\n type: \\"object\\",\\n properties: {\\n field\_name: { type: \\"string\\" },\\n field\_type: { type: \\"string\\" },\\n is\_valid: { type: \\"boolean\\" },\\n error\_message: { type: \\"string\\" },\\n expected\_format: { type: \\"string\\" }\\n },\\n required: \[\\"field\_name\\", \\"field\_type\\", \\"is\_valid\\", \\"error\_message\\", \\"expected\_format\\"\],\\n additionalProperties: false\\n }\\n },\\n data\_quality\_score: { \\n type: \\"number\\", \\n minimum: 0, \\n maximum: 1 \\n },\\n suggested\_fixes: {\\n type: \\"array\\",\\n items: { type: \\"string\\" }\\n },\\n compliance\_check: {\\n type: \\"object\\",\\n properties: {\\n follows\_rest\_standards: { type: \\"boolean\\" },\\n has\_proper\_error\_handling: { type: \\"boolean\\" },\\n includes\_metadata: { type: \\"boolean\\" }\\n },\\n required: \[\\"follows\_rest\_standards\\", \\"has\_proper\_error\_handling\\", \\"includes\_metadata\\"\],\\n additionalProperties: false\\n },\\n standardized\_response: {\\n type: \\"object\\",\\n properties: {\\n success: { type: \\"boolean\\" },\\n data: { type: \\"object\\" },\\n errors: {\\n type: \\"array\\",\\n items: { type: \\"string\\" }\\n },\\n metadata: {\\n type: \\"object\\",\\n properties: {\\n timestamp: { type: \\"string\\" },\\n request\_id: { type: \\"string\\" },\\n version: { type: \\"string\\" }\\n },\\n required: \[\\"timestamp\\", \\"request\_id\\", \\"version\\"\],\\n additionalProperties: false\\n }\\n },\\n required: \[\\"success\\", \\"data\\", \\"errors\\", \\"metadata\\"\],\\n additionalProperties: false\\n }\\n },\\n required: \[\\"validation\_result\\", \\"field\_validations\\", \\"data\_quality\_score\\", \\"suggested\_fixes\\", \\"compliance\_check\\", \\"standardized\_response\\"\],\\n additionalProperties: false\\n }\\n }\\n }\\n});\\n\\nconst result = JSON.parse(response.choices\[0\].message.content || \\"{}\\");\\nconsole.log(result);"\])self.\_\_next\_f.push(\[1,"1b:T77a,from groq import Groq\\nfrom pydantic import BaseModel\\nimport json\\n\\nclient = Groq()\\n\\nclass ValidationResult(BaseModel):\\n is\_valid: bool\\n status\_code: int\\n error\_count: int\\n\\nclass FieldValidation(BaseModel):\\n field\_name: str\\n field\_type: str\\n is\_valid: bool\\n error\_message: str\\n expected\_format: str\\n\\nclass ComplianceCheck(BaseModel):\\n follows\_rest\_standards: bool\\n has\_proper\_error\_handling: bool\\n includes\_metadata: bool\\n\\nclass Metadata(BaseModel):\\n timestamp: str\\n request\_id: str\\n version: str\\n\\nclass StandardizedResponse(BaseModel):\\n success: bool\\n data: dict\\n errors: list\[str\]\\n metadata: Metadata\\n\\nclass APIResponseValidation(BaseModel):\\n validation\_result: ValidationResult\\n field\_validations: list\[FieldValidation\]\\n data\_quality\_score: float\\n suggested\_fixes: list\[str\]\\n compliance\_check: ComplianceCheck\\n standardized\_response: StandardizedResponse\\n\\nresponse = client.chat.completions.create(\\n model=\\"moonshotai/kimi-k2-instruct-0905\\",\\n messages=\[\\n {\\n \\"role\\": \\"system\\",\\n \\"content\\": \\"You are an API response validation expert. Validate and structure API responses with error handling, status codes, and standardized data formats for reliable integration.\\",\\n },\\n {\\"role\\": \\"user\\", \\"content\\": \\"Validate this API response: {\\\\\\"user\_id\\\\\\": \\\\\\"12345\\\\\\", \\\\\\"email\\\\\\": \\\\\\"invalid-email\\\\\\", \\\\\\"created\_at\\\\\\": \\\\\\"2024-01-15T10:30:00Z\\\\\\", \\\\\\"status\\\\\\": \\\\\\"active\\\\\\", \\\\\\"profile\\\\\\": {\\\\\\"name\\\\\\": \\\\\\"John Doe\\\\\\", \\\\\\"age\\\\\\": 25}}\\"},\\n \],\\n response\_format={\\n \\"type\\": \\"json\_schema\\",\\n \\"json\_schema\\": {\\n \\"name\\": \\"api\_response\_validation\\",\\n \\"schema\\": APIResponseValidation.model\_json\_schema()\\n }\\n }\\n)\\n\\napi\_response\_validation = APIResponseValidation.model\_validate(json.loads(response.choices\[0\].message.content))\\nprint(json.dumps(api\_response\_validation.model\_dump(), indent=2))1c:Tede,"\])self.\_\_next\_f.push(\[1,"curl https://api.groq.com/openai/v1/chat/completions \\\\\\n -H \\"Authorization: Bearer $GROQ\_API\_KEY\\" \\\\\\n -H \\"Content-Type: application/json\\" \\\\\\n -d '{\\n \\"model\\": \\"moonshotai/kimi-k2-instruct-0905\\",\\n \\"messages\\": \[\\n {\\n \\"role\\": \\"system\\",\\n \\"content\\": \\"You are an API response validation expert. Validate and structure API responses with error handling, status codes, and standardized data formats for reliable integration.\\"\\n },\\n {\\n \\"role\\": \\"user\\",\\n \\"content\\": \\"Validate this API response: {\\\\\\"user\_id\\\\\\": \\\\\\"12345\\\\\\", \\\\\\"email\\\\\\": \\\\\\"invalid-email\\\\\\", \\\\\\"created\_at\\\\\\": \\\\\\"2024-01-15T10:30:00Z\\\\\\", \\\\\\"status\\\\\\": \\\\\\"active\\\\\\", \\\\\\"profile\\\\\\": {\\\\\\"name\\\\\\": \\\\\\"John Doe\\\\\\", \\\\\\"age\\\\\\": 25}}\\"\\n }\\n \],\\n \\"response\_format\\": {\\n \\"type\\": \\"json\_schema\\",\\n \\"json\_schema\\": {\\n \\"name\\": \\"api\_response\_validation\\",\\n \\"schema\\": {\\n \\"type\\": \\"object\\",\\n \\"properties\\": {\\n \\"validation\_result\\": {\\n \\"type\\": \\"object\\",\\n \\"properties\\": {\\n \\"is\_valid\\": { \\"type\\": \\"boolean\\" },\\n \\"status\_code\\": { \\"type\\": \\"integer\\" },\\n \\"error\_count\\": { \\"type\\": \\"integer\\" }\\n },\\n \\"required\\": \[\\"is\_valid\\", \\"status\_code\\", \\"error\_count\\"\],\\n \\"additionalProperties\\": false\\n },\\n \\"field\_validations\\": {\\n \\"type\\": \\"array\\",\\n \\"items\\": {\\n \\"type\\": \\"object\\",\\n \\"properties\\": {\\n \\"field\_name\\": { \\"type\\": \\"string\\" },\\n \\"field\_type\\": { \\"type\\": \\"string\\" },\\n \\"is\_valid\\": { \\"type\\": \\"boolean\\" },\\n \\"error\_message\\": { \\"type\\": \\"string\\" },\\n \\"expected\_format\\": { \\"type\\": \\"string\\" }\\n },\\n \\"required\\": \[\\"field\_name\\", \\"field\_type\\", \\"is\_valid\\", \\"error\_message\\", \\"expected\_format\\"\],\\n \\"additionalProperties\\": false\\n }\\n },\\n \\"data\_quality\_score\\": { \\n \\"type\\": \\"number\\", \\n \\"minimum\\": 0, \\n \\"maximum\\": 1 \\n },\\n \\"suggested\_fixes\\": {\\n \\"type\\": \\"array\\",\\n \\"items\\": { \\"type\\": \\"string\\" }\\n },\\n \\"compliance\_check\\": {\\n \\"type\\": \\"object\\",\\n \\"properties\\": {\\n \\"follows\_rest\_standards\\": { \\"type\\": \\"boolean\\" },\\n \\"has\_proper\_error\_handling\\": { \\"type\\": \\"boolean\\" },\\n \\"includes\_metadata\\": { \\"type\\": \\"boolean\\" }\\n },\\n \\"required\\": \[\\"follows\_rest\_standards\\", \\"has\_proper\_error\_handling\\", \\"includes\_metadata\\"\],\\n \\"additionalProperties\\": false\\n },\\n \\"standardized\_response\\": {\\n \\"type\\": \\"object\\",\\n \\"properties\\": {\\n \\"success\\": { \\"type\\": \\"boolean\\" },\\n \\"data\\": { \\"type\\": \\"object\\" },\\n \\"errors\\": {\\n \\"type\\": \\"array\\",\\n \\"items\\": { \\"type\\": \\"string\\" }\\n },\\n \\"metadata\\": {\\n \\"type\\": \\"object\\",\\n \\"properties\\": {\\n \\"timestamp\\": { \\"type\\": \\"string\\" },\\n \\"request\_id\\": { \\"type\\": \\"string\\" },\\n \\"version\\": { \\"type\\": \\"string\\" }\\n },\\n \\"required\\": \[\\"timestamp\\", \\"request\_id\\", \\"version\\"\],\\n \\"additionalProperties\\": false\\n }\\n },\\n \\"required\\": \[\\"success\\", \\"data\\", \\"errors\\", \\"metadata\\"\],\\n \\"additionalProperties\\": false\\n }\\n },\\n \\"required\\": \[\\"validation\_result\\", \\"field\_validations\\", \\"data\_quality\_score\\", \\"suggested\_fixes\\", \\"compliance\_check\\", \\"standardized\_response\\"\],\\n \\"additionalProperties\\": false\\n }\\n }\\n }\\n }'"\])self.\_\_next\_f.push(\[1,"1d:T81b,"\])self.\_\_next\_f.push(\[1,"import Groq from \\"groq-sdk\\";\\nimport { z } from \\"zod\\";\\n\\nconst groq = new Groq();\\n\\nconst supportTicketSchema = z.object({\\n category: z.enum(\[\\"api\\", \\"billing\\", \\"account\\", \\"bug\\", \\"feature\_request\\", \\"integration\\", \\"security\\", \\"performance\\"\]),\\n priority: z.enum(\[\\"low\\", \\"medium\\", \\"high\\", \\"critical\\"\]),\\n urgency\_score: z.number(),\\n customer\_info: z.object({\\n name: z.string(),\\n company: z.string().optional(),\\n tier: z.enum(\[\\"free\\", \\"paid\\", \\"enterprise\\", \\"trial\\"\])\\n }),\\n technical\_details: z.array(z.object({\\n component: z.string(),\\n error\_code: z.string().optional(),\\n description: z.string()\\n })),\\n keywords: z.array(z.string()),\\n requires\_escalation: z.boolean(),\\n estimated\_resolution\_hours: z.number(),\\n follow\_up\_date: z.string().datetime().optional(),\\n summary: z.string()\\n});\\n\\ntype SupportTicket = z.infer\\u003ctypeof supportTicketSchema\\u003e;\\n\\nconst response = await groq.chat.completions.create({\\n model: \\"moonshotai/kimi-k2-instruct-0905\\",\\n messages: \[\\n {\\n role: \\"system\\",\\n content: \`You are a customer support ticket classifier for SaaS companies. \\n Analyze support tickets and categorize them for efficient routing and resolution.\\n Output JSON only using the schema provided.\`,\\n },\\n { \\n role: \\"user\\", \\n content: \`Hello! I love your product and have been using it for 6 months. \\n I was wondering if you could add a dark mode feature to the dashboard? \\n Many of our team members work late hours and would really appreciate this. \\n Also, it would be great to have keyboard shortcuts for common actions. \\n Not urgent, but would be a nice enhancement! \\n Best, Mike from StartupXYZ\`\\n },\\n \],\\n response\_format: {\\n type: \\"json\_schema\\",\\n json\_schema: {\\n name: \\"support\_ticket\_classification\\",\\n schema: z.toJSONSchema(supportTicketSchema)\\n }\\n }\\n});\\n\\nconst rawResult = JSON.parse(response.choices\[0\].message.content || \\"{}\\");\\nconst result = supportTicketSchema.parse(rawResult);\\nconsole.log(result);"\])self.\_\_next\_f.push(\[1,"1e:Ta18,"\])self.\_\_next\_f.push(\[1,"from groq import Groq\\nfrom pydantic import BaseModel, Field\\nfrom typing import List, Optional, Literal\\nfrom enum import Enum\\nimport json\\n\\nclient = Groq()\\n\\nclass SupportCategory(str, Enum):\\n API = \\"api\\"\\n BILLING = \\"billing\\"\\n ACCOUNT = \\"account\\"\\n BUG = \\"bug\\"\\n FEATURE\_REQUEST = \\"feature\_request\\"\\n INTEGRATION = \\"integration\\"\\n SECURITY = \\"security\\"\\n PERFORMANCE = \\"performance\\"\\n\\nclass Priority(str, Enum):\\n LOW = \\"low\\"\\n MEDIUM = \\"medium\\"\\n HIGH = \\"high\\"\\n CRITICAL = \\"critical\\"\\n\\nclass CustomerTier(str, Enum):\\n FREE = \\"free\\"\\n PAID = \\"paid\\"\\n ENTERPRISE = \\"enterprise\\"\\n TRIAL = \\"trial\\"\\n\\nclass CustomerInfo(BaseModel):\\n name: str\\n company: Optional\[str\] = None\\n tier: CustomerTier\\n\\nclass TechnicalDetail(BaseModel):\\n component: str\\n error\_code: Optional\[str\] = None\\n description: str\\n\\nclass SupportTicket(BaseModel):\\n category: SupportCategory\\n priority: Priority\\n urgency\_score: float\\n customer\_info: CustomerInfo\\n technical\_details: List\[TechnicalDetail\]\\n keywords: List\[str\]\\n requires\_escalation: bool\\n estimated\_resolution\_hours: float\\n follow\_up\_date: Optional\[str\] = Field(None, description=\\"ISO datetime string\\")\\n summary: str\\n\\nresponse = client.chat.completions.create(\\n model=\\"moonshotai/kimi-k2-instruct-0905\\",\\n messages=\[\\n {\\n \\"role\\": \\"system\\",\\n \\"content\\": \\"\\"\\"You are a customer support ticket classifier for SaaS companies. \\n Analyze support tickets and categorize them for efficient routing and resolution.\\n Output JSON only using the schema provided.\\"\\"\\",\\n },\\n { \\n \\"role\\": \\"user\\", \\n \\"content\\": \\"\\"\\"Hello! I love your product and have been using it for 6 months. \\n I was wondering if you could add a dark mode feature to the dashboard? \\n Many of our team members work late hours and would really appreciate this. \\n Also, it would be great to have keyboard shortcuts for common actions. \\n Not urgent, but would be a nice enhancement! \\n Best, Mike from StartupXYZ\\"\\"\\"\\n },\\n \],\\n response\_format={\\n \\"type\\": \\"json\_schema\\",\\n \\"json\_schema\\": {\\n \\"name\\": \\"support\_ticket\_classification\\",\\n \\"schema\\": SupportTicket.model\_json\_schema()\\n }\\n }\\n)\\n\\nraw\_result = json.loads(response.choices\[0\].message.content or \\"{}\\")\\nresult = SupportTicket.model\_validate(raw\_result)\\nprint(result.model\_dump\_json(indent=2))"\])self.\_\_next\_f.push(\[1,"1f:T56c,from groq import Groq\\nimport json\\n\\nclient = Groq()\\n\\nresponse = client.chat.completions.create(\\n model=\\"moonshotai/kimi-k2-instruct-0905\\",\\n messages=\[\\n {\\"role\\": \\"system\\", \\"content\\": \\"You are a helpful math tutor. Guide the user through the solution step by step.\\"},\\n {\\"role\\": \\"user\\", \\"content\\": \\"how can I solve 8x + 7 = -23\\"}\\n \],\\n response\_format={\\n \\"type\\": \\"json\_schema\\",\\n \\"json\_schema\\": {\\n \\"name\\": \\"math\_response\\",\\n \\"schema\\": {\\n \\"type\\": \\"object\\",\\n \\"properties\\": {\\n \\"steps\\": {\\n \\"type\\": \\"array\\",\\n \\"items\\": {\\n \\"type\\": \\"object\\",\\n \\"properties\\": {\\n \\"explanation\\": {\\"type\\": \\"string\\"},\\n \\"output\\": {\\"type\\": \\"string\\"}\\n },\\n \\"required\\": \[\\"explanation\\", \\"output\\"\],\\n \\"additionalProperties\\": False\\n }\\n },\\n \\"final\_answer\\": {\\"type\\": \\"string\\"}\\n },\\n \\"required\\": \[\\"steps\\", \\"final\_answer\\"\],\\n \\"additionalProperties\\": False\\n }\\n }\\n }\\n)\\n\\nresult = json.loads(response.choices\[0\].message.content)\\nprint(json.dumps(result, indent=2))20:T558,import Groq from \\"groq-sdk\\";\\n\\nconst groq = new Groq();\\n\\nconst response = await groq.chat.completions.create({\\n model: \\"moonshotai/kimi-k2-instruct-0905\\",\\n messages: \[\\n { role: \\"system\\", content: \\"You are a helpful math tutor. Guide the user through the solution step by step.\\" },\\n { role: \\"user\\", content: \\"how can I solve 8x + 7 = -23\\" }\\n \],\\n response\_format: {\\n type: \\"json\_schema\\",\\n json\_schema: {\\n name: \\"math\_response\\",\\n schema: {\\n type: \\"object\\",\\n properties: {\\n steps: {\\n type: \\"array\\",\\n "\])self.\_\_next\_f.push(\[1," items: {\\n type: \\"object\\",\\n properties: {\\n explanation: { type: \\"string\\" },\\n output: { type: \\"string\\" }\\n },\\n required: \[\\"explanation\\", \\"output\\"\],\\n additionalProperties: false\\n }\\n },\\n final\_answer: { type: \\"string\\" }\\n },\\n required: \[\\"steps\\", \\"final\_answer\\"\],\\n additionalProperties: false\\n }\\n }\\n }\\n});\\n\\nconst result = JSON.parse(response.choices\[0\].message.content || \\"{}\\");\\nconsole.log(result);21:T4c3,curl https://api.groq.com/openai/v1/chat/completions \\\\\\n -H \\"Authorization: Bearer $GROQ\_API\_KEY\\" \\\\\\n -H \\"Content-Type: application/json\\" \\\\\\n -d '{\\n \\"model\\": \\"moonshotai/kimi-k2-instruct-0905\\",\\n \\"messages\\": \[\\n {\\n \\"role\\": \\"system\\",\\n \\"content\\": \\"You are a helpful math tutor. Guide the user through the solution step by step.\\"\\n },\\n {\\n \\"role\\": \\"user\\",\\n \\"content\\": \\"how can I solve 8x + 7 = -23\\"\\n }\\n \],\\n \\"response\_format\\": {\\n \\"type\\": \\"json\_schema\\",\\n \\"json\_schema\\": {\\n \\"name\\": \\"math\_response\\",\\n \\"schema\\": {\\n \\"type\\": \\"object\\",\\n \\"properties\\": {\\n \\"steps\\": {\\n \\"type\\": \\"array\\",\\n \\"items\\": {\\n \\"type\\": \\"object\\",\\n \\"properties\\": {\\n \\"explanation\\": { \\"type\\": \\"string\\" },\\n \\"output\\": { \\"type\\": \\"string\\" }\\n },\\n \\"required\\": \[\\"explanation\\", \\"output\\"\],\\n \\"additionalProperties\\": false\\n }\\n },\\n \\"final\_answer\\": { \\"type\\": \\"string\\" }\\n },\\n \\"required\\": \[\\"steps\\", \\"final\_answer\\"\],\\n \\"additionalProperties\\": false\\n }\\n }\\n }\\n }'22:T5ab,{\\n \\"type\\": \\"object\\",\\n \\"properties\\": {\\n \\"payment\_method\\": {\\n \\"anyOf\\": \[\\n "\])self.\_\_next\_f.push(\[1,"{\\n \\"type\\": \\"object\\",\\n \\"description\\": \\"Credit card payment information\\",\\n \\"properties\\": {\\n \\"card\_number\\": {\\n \\"type\\": \\"string\\",\\n \\"description\\": \\"The credit card number\\"\\n },\\n \\"expiry\_date\\": {\\n \\"type\\": \\"string\\",\\n \\"description\\": \\"Card expiration date in MM/YY format\\"\\n },\\n \\"cvv\\": {\\n \\"type\\": \\"string\\",\\n \\"description\\": \\"Card security code\\"\\n }\\n },\\n \\"additionalProperties\\": false,\\n \\"required\\": \[\\"card\_number\\", \\"expiry\_date\\", \\"cvv\\"\]\\n },\\n {\\n \\"type\\": \\"object\\",\\n \\"description\\": \\"Bank transfer payment information\\",\\n \\"properties\\": {\\n \\"account\_number\\": {\\n \\"type\\": \\"string\\",\\n \\"description\\": \\"Bank account number\\"\\n },\\n \\"routing\_number\\": {\\n \\"type\\": \\"string\\",\\n \\"description\\": \\"Bank routing number\\"\\n },\\n \\"bank\_name\\": {\\n \\"type\\": \\"string\\",\\n \\"description\\": \\"Name of the bank\\"\\n }\\n },\\n \\"additionalProperties\\": false,\\n \\"required\\": \[\\"account\_number\\", \\"routing\_number\\", \\"bank\_name\\"\]\\n }\\n \]\\n }\\n },\\n \\"additionalProperties\\": false,\\n \\"required\\": \[\\"payment\_method\\"\]\\n}\\n23:T5c7,{\\n \\"name\\": \\"organization\_chart\\",\\n \\"description\\": \\"Company organizational structure\\",\\n \\"strict\\": true,\\n \\"schema\\": {\\n \\"type\\": \\"object\\",\\n \\"properties\\": {\\n \\"employee\_id\\": {\\n \\"type\\": \\"string\\",\\n \\"description\\": \\"Unique employee identifier\\"\\n },\\n \\"name\\": {\\n \\"type\\": \\"string\\",\\n \\"description\\": \\"Employee full name\\"\\n },\\n \\"position\\": {\\n \\"type\\": \\"string\\",\\n \\"description\\": \\"Job title or position\\",\\n \\"enum\\": \[\\"CEO\\", \\"Manager\\", \\"Developer\\", \\"Designer\\", \\"Analyst\\", \\"Intern\\"\]\\n },\\n \\"direct\_reports\\": {\\n \\"type\\": \\"array\\",\\n \\"description\\": \\"Employees reporting to this person\\",\\n \\"items\\":"\])self.\_\_next\_f.push(\[1," {\\n \\"$ref\\": \\"#\\"\\n }\\n },\\n \\"contact\_info\\": {\\n \\"type\\": \\"array\\",\\n \\"description\\": \\"Contact information for the employee\\",\\n \\"items\\": {\\n \\"type\\": \\"object\\",\\n \\"properties\\": {\\n \\"type\\": {\\n \\"type\\": \\"string\\",\\n \\"description\\": \\"Type of contact info\\",\\n \\"enum\\": \[\\"email\\", \\"phone\\", \\"slack\\"\]\\n },\\n \\"value\\": {\\n \\"type\\": \\"string\\",\\n \\"description\\": \\"The contact value\\"\\n }\\n },\\n \\"additionalProperties\\": false,\\n \\"required\\": \[\\"type\\", \\"value\\"\]\\n }\\n }\\n },\\n \\"required\\": \[\\n \\"employee\_id\\",\\n \\"name\\",\\n \\"position\\",\\n \\"direct\_reports\\",\\n \\"contact\_info\\"\\n \],\\n \\"additionalProperties\\": false\\n }\\n}\\n24:T4ef,import { Groq } from \\"groq-sdk\\";\\n\\nconst groq = new Groq();\\n\\nasync function main() {\\n const response = await groq.chat.completions.create({\\n model: \\"openai/gpt-oss-20b\\",\\n messages: \[\\n {\\n role: \\"system\\",\\n content: \`You are a data analysis API that performs sentiment analysis on text.\\n Respond only with JSON using this format:\\n {\\n \\"sentiment\_analysis\\": {\\n \\"sentiment\\": \\"positive|negative|neutral\\",\\n \\"confidence\_score\\": 0.95,\\n \\"key\_phrases\\": \[\\n {\\n \\"phrase\\": \\"detected key phrase\\",\\n \\"sentiment\\": \\"positive|negative|neutral\\"\\n }\\n \],\\n \\"summary\\": \\"One sentence summary of the overall sentiment\\"\\n }\\n }\`\\n },\\n { role: \\"user\\", content: \\"Analyze the sentiment of this customer review: 'I absolutely love this product! The quality exceeded my expectations, though shipping took longer than expected.'\\" }\\n \],\\n response\_format: { type: \\"json\_object\\" }\\n });\\n\\n const result = JSON.parse(response.choices\[0\].message.content || \\"{}\\");\\n console"\])self.\_\_next\_f.push(\[1,".log(result);\\n}\\n\\nmain();25:T55f,from groq import Groq\\nimport json\\n\\nclient = Groq()\\n\\ndef main():\\n response = client.chat.completions.create(\\n model=\\"llama-3.3-70b-versatile\\",\\n messages=\[\\n {\\n \\"role\\": \\"system\\",\\n \\"content\\": \\"\\"\\"You are a data analysis API that performs sentiment analysis on text.\\n Respond only with JSON using this format:\\n {\\n \\"sentiment\_analysis\\": {\\n \\"sentiment\\": \\"positive|negative|neutral\\",\\n \\"confidence\_score\\": 0.95,\\n \\"key\_phrases\\": \[\\n {\\n \\"phrase\\": \\"detected key phrase\\",\\n \\"sentiment\\": \\"positive|negative|neutral\\"\\n }\\n \],\\n \\"summary\\": \\"One sentence summary of the overall sentiment\\"\\n }\\n }\\"\\"\\"\\n },\\n {\\n \\"role\\": \\"user\\", \\n \\"content\\": \\"Analyze the sentiment of this customer review: 'I absolutely love this product! The quality exceeded my expectations, though shipping took longer than expected.'\\"\\n }\\n \],\\n response\_format={\\"type\\": \\"json\_object\\"}\\n )\\n\\n result = json.loads(response.choices\[0\].message.content)\\n print(json.dumps(result, indent=2))\\n\\nif \_\_name\_\_ == \\"\_\_main\_\_\\":\\n main()"\])self.\_\_next\_f.push(\[1,"0:{\\"P\\":null,\\"b\\":\\"JaE-NAo4NUSHt0zfUAtYQ\\",\\"p\\":\\"\\",\\"c\\":\[\\"\\",\\"docs\\",\\"structured-outputs\\"\],\\"i\\":false,\\"f\\":\[\[\[\\"\\",{\\"children\\":\[\\"(console)\\",{\\"children\\":\[\\"docs\\",{\\"children\\":\[\\"(mdx-pages)\\",{\\"children\\":\[\\"structured-outputs\\",{\\"children\\":\[\\"\_\_PAGE\_\_\\",{}\]}\]}\]}\]}\]},\\"$undefined\\",\\"$undefined\\",true\],\[\\"\\",\[\\"$\\",\\"$1\\",\\"c\\",{\\"children\\":\[\[\[\\"$\\",\\"link\\",\\"0\\",{\\"rel\\":\\"stylesheet\\",\\"href\\":\\"/\_next/static/css/7bf466619b61d92d.css\\",\\"precedence\\":\\"next\\",\\"crossOrigin\\":\\"$undefined\\",\\"nonce\\":\\"$undefined\\"}\],\[\\"$\\",\\"link\\",\\"1\\",{\\"rel\\":\\"stylesheet\\",\\"href\\":\\"/\_next/static/css/5f71e76d6445edb3.css\\",\\"precedence\\":\\"next\\",\\"crossOrigin\\":\\"$undefined\\",\\"nonce\\":\\"$undefined\\"}\]\],\\"$L2\\"\]}\],{\\"children\\":\[\\"(console)\\",\[\\"$\\",\\"$1\\",\\"c\\",{\\"children\\":\[\[\[\\"$\\",\\"link\\",\\"0\\",{\\"rel\\":\\"stylesheet\\",\\"href\\":\\"/\_next/static/css/c145a7ada77054e8.css\\",\\"precedence\\":\\"next\\",\\"crossOrigin\\":\\"$undefined\\",\\"nonce\\":\\"$undefined\\"}\]\],\[\\"$\\",\\"$L3\\",null,{\\"Component\\":\\"$4\\",\\"slots\\":{\\"children\\":\[\\"$\\",\\"$L5\\",null,{\\"parallelRouterKey\\":\\"children\\",\\"error\\":\\"$undefined\\",\\"errorStyles\\":\\"$undefined\\",\\"errorScripts\\":\\"$undefined\\",\\"template\\":\[\\"$\\",\\"$L6\\",null,{}\],\\"templateStyles\\":\\"$undefined\\",\\"templateScripts\\":\\"$undefined\\",\\"notFound\\":\[\[\[\\"$\\",\\"title\\",null,{\\"children\\":\\"404: This page could not be found.\\"}\],\[\\"$\\",\\"div\\",null,{\\"style\\":{\\"fontFamily\\":\\"system-ui,\\\\\\"Segoe UI\\\\\\",Roboto,Helvetica,Arial,sans-serif,\\\\\\"Apple Color Emoji\\\\\\",\\\\\\"Segoe UI Emoji\\\\\\"\\",\\"height\\":\\"100vh\\",\\"textAlign\\":\\"center\\",\\"display\\":\\"flex\\",\\"flexDirection\\":\\"column\\",\\"alignItems\\":\\"center\\",\\"justifyContent\\":\\"center\\"},\\"children\\":\[\\"$\\",\\"div\\",null,{\\"children\\":\[\[\\"$\\",\\"style\\",null,{\\"dangerouslySetInnerHTML\\":{\\"\_\_html\\":\\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\\"}}\],\[\\"$\\",\\"h1\\",null,{\\"className\\":\\"next-error-h1\\",\\"style\\":{\\"display\\":\\"inline-block\\",\\"margin\\":\\"0 20px 0 0\\",\\"padding\\":\\"0 23px 0 0\\",\\"fontSize\\":24,\\"fontWeight\\":500,\\"verticalAlign\\":\\"top\\",\\"lineHeight\\":\\"49px\\"},\\"children\\":404}\],\[\\"$\\",\\"div\\",null,{\\"style\\":{\\"display\\":\\"inline-block\\"},\\"children\\":\[\\"$\\",\\"h2\\",null,{\\"style\\":{\\"fontSize\\":14,\\"fontWeight\\":400,\\"lineHeight\\":\\"49px\\",\\"margin\\":0},\\"children\\":\\"This page could not be found.\\"}\]}\]\]}\]}\]\],\[\]\],\\"forbidden\\":\\"$undefined\\",\\"unauthorized\\":\\"$undefined\\"}\]},\\"params\\":{},\\"promise\\":\\"$@7\\"}\]\]}\],{\\"children\\":\[\\"docs\\",\[\\"$\\",\\"$1\\",\\"c\\",{\\"children\\":\[\[\[\\"$\\",\\"link\\",\\"0\\",{\\"rel\\":\\"stylesheet\\",\\"href\\":\\"/\_next/static/css/0cec16494c374a65.css\\",\\"precedence\\":\\"next\\",\\"crossOrigin\\":\\"$undefined\\",\\"nonce\\":\\"$undefined\\"}\]\],\\"$L8\\"\]}\],{\\"children\\":\[\\"(mdx-pages)\\",\[\\"$\\",\\"$1\\",\\"c\\",{\\"children\\":\[null,\[\\"$\\",\\"div\\",null,{\\"children\\":\[\[\\"$\\",\\"$L5\\",null,{\\"parallelRouterKey\\":\\"children\\",\\"error\\":\\"$undefined\\",\\"errorStyles\\":\\"$undefined\\",\\"errorScripts\\":\\"$undefined\\",\\"template\\":\[\\"$\\",\\"$L6\\",null,{}\],\\"templateStyles\\":\\"$undefined\\",\\"templateScripts\\":\\"$undefined\\",\\"notFound\\":\\"$undefined\\",\\"forbidden\\":\\"$undefined\\",\\"unauthorized\\":\\"$undefined\\"}\],\[\\"$\\",\\"$L9\\",null,{}\]\]}\]\]}\],{\\"children\\":\[\\"structured-outputs\\",\[\\"$\\",\\"$1\\",\\"c\\",{\\"children\\":\[null,\[\\"$\\",\\"$L5\\",null,{\\"parallelRouterKey\\":\\"children\\",\\"error\\":\\"$undefined\\",\\"errorStyles\\":\\"$undefined\\",\\"errorScripts\\":\\"$undefined\\",\\"template\\":\[\\"$\\",\\"$L6\\",null,{}\],\\"templateStyles\\":\\"$undefined\\",\\"templateScripts\\":\\"$undefined\\",\\"notFound\\":\\"$undefined\\",\\"forbidden\\":\\"$undefined\\",\\"unauthorized\\":\\"$undefined\\"}\]\]}\],{\\"children\\":\[\\"\_\_PAGE\_\_\\",\[\\"$\\",\\"$1\\",\\"c\\",{\\"children\\":\[\[\[\\"$\\",\\"div\\",null,{\\"className\\":\\"flex flex-col sm:flex-row sm:items-center gap-2 sm:gap-4 mb-3 justify-between\\",\\"children\\":\[\[\\"$\\",\\"h1\\",null,{\\"className\\":\\"text-2xl font-semibold font-header\\",\\"children\\":\\"Structured Outputs\\"}\],\[\\"$\\",\\"$La\\",null,{}\]\]}\],\\"\\\\n\\",\[\\"$\\",\\"p\\",null,{\\"className\\":\\"text-sm my-3\\",\\"children\\":\\"Guarantee model responses strictly conform to your JSON schema for reliable, type-safe data structures.\\"}\],\\"\\\\n\\",\[\\"$\\",\\"h2\\",null,{\\"id\\":\\"introduction\\",\\"className\\":\\"\[\\u0026:not(:first-child)\]:mt-12 mb-3 text-xl w-fit font-semibold font-header hover:underline\\",\\"children\\":\[\\"$\\",\\"a\\",null,{\\"href\\":\\"#introduction\\",\\"className\\":\\"anchor-link\\",\\"children\\":\[\\"Introduction\\"\]}\]}\],\\"\\\\n\\",\[\\"$\\",\\"p\\",null,{\\"className\\":\\"text-sm my-3\\",\\"children\\":\[\\"Structured Outputs is a feature that makes your model responses strictly conform to your provided \\",\[\\"$\\",\\"$Lb\\",null,{\\"prefetch\\":true,\\"href\\":\\"https://json-schema.org/overview/what-is-jsonschema\\",\\"children\\":\\"JSON Schema\\"}\],\\" or throws an error if the model cannot produce a compliant response. The endpoint provides customers with the ability to obtain reliable data structures.\\"\]}\],\\"\\\\n\\",\[\\"$\\",\\"br\\",null,{}\],\\"\\\\n\\",\[\\"$\\",\\"p\\",null,{\\"className\\":\\"text-sm my-3\\",\\"children\\":\\"This feature's performance is dependent on the model's ability to produce a valid answer that matches your schema. If the model fails to generate a conforming response, the endpoint will return an error rather than an invalid or incomplete result.\\"}\],\\"\\\\n\\",\[\\"$\\",\\"br\\",null,{}\],\\"\\\\n\\",\[\\"$\\",\\"p\\",null,{\\"className\\":\\"text-sm my-3\\",\\"children\\":\\"Key benefits:\\"}\],\\"\\\\n\\",\[\\"$\\",\\"ol\\",null,{\\"className\\":\\"list-decimal my-2 text-sm\\",\\"children\\":\[\\"\\\\n\\",\[\\"$\\",\\"li\\",null,{\\"className\\":\\"ml-6 my-1.5 text-sm\\",\\"children\\":\[\[\\"$\\",\\"strong\\",null,{\\"children\\":\\"Binary output:\\"}\],\\" Either returns valid JSON Schema-compliant output or throws an error\\"\]}\],\\"\\\\n\\",\[\\"$\\",\\"li\\",null,{\\"className\\":\\"ml-6 my-1.5 text-sm\\",\\"children\\":\[\[\\"$\\",\\"strong\\",null,{\\"children\\":\\"Type-safe responses:\\"}\],\\" No need to validate or retry malformed outputs\\"\]}\],\\"\\\\n\\",\[\\"$\\",\\"li\\",null,{\\"className\\":\\"ml-6 my-1.5 text-sm\\",\\"children\\":\[\[\\"$\\",\\"strong\\",null,{\\"children\\":\\"Programmatic refusal detection:\\"}\],\\" Detect safety-based model refusals programmatically\\"\]}\],\\"\\\\n\\",\[\\"$\\",\\"li\\",null,{\\"className\\":\\"ml-6 my-1.5 text-sm\\",\\"children\\":\[\[\\"$\\",\\"strong\\",null,{\\"children\\":\\"Simplified prompting:\\"}\],\\" No complex prompts needed for consistent formatting\\"\]}\],\\"\\\\n\\"\]}\],\\"\\\\n\\",\[\\"$\\",\\"br\\",null,{}\],\\"\\\\n\\",\[\\"$\\",\\"p\\",null,{\\"className\\":\\"text-sm my-3\\",\\"children\\":\[\\"In addition to supporting Structured Outputs in our API, our SDKs also enable you to easily define your schemas with \\",\[\\"$\\",\\"$Lb\\",null,{\\"prefetch\\":true,\\"href\\":\\"https://docs.pydantic.dev/latest/\\",\\"children\\":\\"Pydantic\\"}\],\\" and \\",\[\\"$\\",\\"$Lb\\",null,{\\"prefetch\\":true,\\"href\\":\\"https://zod.dev/\\",\\"children\\":\\"Zod\\"}\],\\" to ensure further type safety. The examples below show how to extract structured information from unstructured text.\\"\]}\],\\"\\\\n\\",\[\\"$\\",\\"h2\\",null,{\\"id\\":\\"supported-models\\",\\"className\\":\\"\[\\u0026:not(:first-child)\]:mt-12 mb-3 text-xl w-fit font-semibold font-header hover:underline\\",\\"children\\":\[\\"$\\",\\"a\\",null,{\\"href\\":\\"#supported-models\\",\\"className\\":\\"anchor-link\\",\\"children\\":\[\\"Supported models\\"\]}\]}\],\\"\\\\n\\",\[\\"$\\",\\"p\\",null,{\\"className\\":\\"text-sm my-3\\",\\"children\\":\\"Structured Outputs is available with the following models:\\"}\],\\"\\\\n\\",\[\\"$\\",\\"div\\",null,{\\"className\\":\\"relative w-full overflow-auto py-3\\",\\"children\\":\[\\"$\\",\\"table\\",null,{\\"ref\\":\\"$undefined\\",\\"className\\":\\"w-full caption-bottom text-sm py-3\\",\\"children\\":\[\[\\"$\\",\\"thead\\",null,{\\"ref\\":\\"$undefined\\",\\"className\\":\\"\[\\u0026\_tr\]:border-b hover:none\\",\\"children\\":\[\\"$\\",\\"tr\\",null,{\\"ref\\":\\"$undefined\\",\\"className\\":\\"border-b border-nav transition-colors hover:bg-muted/50 data-\[state=selected\]:bg-muted\\",\\"children\\":\[\[\\"$\\",\\"th\\",null,{\\"ref\\":\\"$undefined\\",\\"className\\":\\"h-12 py-3 text-left align-middle font-medium uppercase tracking-wider \[\\u0026:has(\[role=checkbox\])\]:pr-0 dark:text-gray-400 text-\[10px\] text-muted-foreground pr-6\\",\\"children\\":\\"Model ID\\"}\],\[\\"$\\",\\"th\\",null,{\\"ref\\":\\"$undefined\\",\\"className\\":\\"h-12 py-3 text-left align-middle font-medium uppercase tracking-wider \[\\u0026:has(\[role=checkbox\])\]:pr-0 dark:text-gray-400 text-\[10px\] text-muted-foreground pr-6\\",\\"children\\":\\"Model\\"}\]\]}\]}\],\[\\"$\\",\\"tbody\\",null,{\\"ref\\":\\"$undefined\\",\\"className\\":\\"\[border-0\\",\\"children\\":\[\[\\"$\\",\\"tr\\",null,{\\"ref\\":\\"$undefined\\",\\"className\\":\\"border-b border-nav transition-colors hover:bg-muted/50 data-\[state=selected\]:bg-muted\\",\\"children\\":\[\[\\"$\\",\\"td\\",null,{\\"ref\\":\\"$undefined\\",\\"className\\":\\"py-2 align-middle \[\\u0026:has(\[role=checkbox\])\]:pr-0 pr-6\\",\\"children\\":\[\\"$\\",\\"$Lc\\",null,{\\"text\\":\\"openai/gpt-oss-20b\\"}\]}\],\[\\"$\\",\\"td\\",null,{\\"ref\\":\\"$undefined\\",\\"className\\":\\"py-2 align-middle \[\\u0026:has(\[role=checkbox\])\]:pr-0 pr-6\\",\\"children\\":\[\\"$\\",\\"$Lb\\",null,{\\"prefetch\\":true,\\"href\\":\\"/docs/model/openai/gpt-oss-20b\\",\\"children\\":\\"GPT-OSS 20B\\"}\]}\]\]}\],\[\\"$\\",\\"tr\\",null,{\\"ref\\":\\"$undefined\\",\\"className\\":\\"border-b border-nav transition-colors hover:bg-muted/50 data-\[state=selected\]:bg-muted\\",\\"children\\":\[\[\\"$\\",\\"td\\",null,{\\"ref\\":\\"$undefined\\",\\"className\\":\\"py-2 align-middle \[\\u0026:has(\[role=checkbox\])\]:pr-0 pr-6\\",\\"children\\":\[\\"$\\",\\"$Lc\\",null,{\\"text\\":\\"openai/gpt-oss-120b\\"}\]}\],\[\\"$\\",\\"td\\",null,{\\"ref\\":\\"$undefined\\",\\"className\\":\\"py-2 align-middle \[\\u0026:has(\[role=checkbox\])\]:pr-0 pr-6\\",\\"children\\":\[\\"$\\",\\"$Lb\\",null,{\\"prefetch\\":true,\\"href\\":\\"/docs/model/openai/gpt-oss-120b\\",\\"children\\":\\"GPT-OSS 120B\\"}\]}\]\]}\],\[\\"$\\",\\"tr\\",null,{\\"ref\\":\\"$undefined\\",\\"className\\":\\"border-b border-nav transition-colors hover:bg-muted/50 data-\[state=selected\]:bg-muted\\",\\"children\\":\[\[\\"$\\",\\"td\\",null,{\\"ref\\":\\"$undefined\\",\\"className\\":\\"py-2 align-middle \[\\u0026:has(\[role=checkbox\])\]:pr-0 pr-6\\",\\"children\\":\[\\"$\\",\\"$Lc\\",null,{\\"text\\":\\"openai/gpt-oss-safeguard-20b\\"}\]}\],\[\\"$\\",\\"td\\",null,{\\"ref\\":\\"$undefined\\",\\"className\\":\\"py-2 align-middle \[\\u0026:has(\[role=checkbox\])\]:pr-0 pr-6\\",\\"children\\":\[\\"$\\",\\"$Lb\\",null,{\\"prefetch\\":true,\\"href\\":\\"/docs/model/openai/gpt-oss-safeguard-20b\\",\\"children\\":\\"Safety GPT OSS 20B\\"}\]}\]\]}\],\[\\"$\\",\\"tr\\",null,{\\"ref\\":\\"$undefined\\",\\"className\\":\\"border-b border-nav transition-colors hover:bg-muted/50 data-\[state=selected\]:bg-muted\\",\\"children\\":\[\[\\"$\\",\\"td\\",null,{\\"ref\\":\\"$undefined\\",\\"className\\":\\"py-2 align-middle \[\\u0026:has(\[role=checkbox\])\]:pr-0 pr-6\\",\\"children\\":\[\\"$\\",\\"$Lc\\",null,{\\"text\\":\\"moonshotai/kimi-k2-instruct-0905\\"}\]}\],\[\\"$\\",\\"td\\",null,{\\"ref\\":\\"$undefined\\",\\"className\\":\\"py-2 align-middle \[\\u0026:has(\[role=checkbox\])\]:pr-0 pr-6\\",\\"children\\":\[\\"$\\",\\"$Lb\\",null,{\\"prefetch\\":true,\\"href\\":\\"/docs/model/moonshotai/kimi-k2-instruct-0905\\",\\"children\\":\\"Kimi K2 Instruct\\"}\]}\]\]}\],\[\\"$\\",\\"tr\\",null,{\\"ref\\":\\"$undefined\\",\\"className\\":\\"border-b border-nav transition-colors hover:bg-muted/50 data-\[state=selected\]:bg-muted\\",\\"children\\":\[\[\\"$\\",\\"td\\",null,{\\"ref\\":\\"$undefined\\",\\"className\\":\\"py-2 align-middle \[\\u0026:has(\[role=checkbox\])\]:pr-0 pr-6\\",\\"children\\":\[\\"$\\",\\"$Lc\\",null,{\\"text\\":\\"meta-llama/llama-4-maverick-17b-128e-instruct\\"}\]}\],\[\\"$\\",\\"td\\",null,{\\"ref\\":\\"$undefined\\",\\"className\\":\\"py-2 align-middle \[\\u0026:has(\[role=checkbox\])\]:pr-0 pr-6\\",\\"children\\":\[\\"$\\",\\"$Lb\\",null,{\\"prefetch\\":true,\\"href\\":\\"/docs/model/meta-llama/llama-4-maverick-17b-128e-instruct\\",\\"children\\":\\"Llama 4 Maverick\\"}\]}\]\]}\],\[\\"$\\",\\"tr\\",null,{\\"ref\\":\\"$undefined\\",\\"className\\":\\"border-b border-nav transition-colors hover:bg-muted/50 data-\[state=selected\]:bg-muted\\",\\"children\\":\[\[\\"$\\",\\"td\\",null,{\\"ref\\":\\"$undefined\\",\\"className\\":\\"py-2 align-middle \[\\u0026:has(\[role=checkbox\])\]:pr-0 pr-6\\",\\"children\\":\[\\"$\\",\\"$Lc\\",null,{\\"text\\":\\"meta-llama/llama-4-scout-17b-16e-instruct\\"}\]}\],\[\\"$\\",\\"td\\",null,{\\"ref\\":\\"$undefined\\",\\"className\\":\\"py-2 align-middle \[\\u0026:has(\[role=checkbox\])\]:pr-0 pr-6\\",\\"children\\":\[\\"$\\",\\"$Lb\\",null,{\\"prefetch\\":true,\\"href\\":\\"/docs/model/meta-llama/llama-4-scout-17b-16e-instruct\\",\\"children\\":\\"Llama 4 Scout\\"}\]}\]\]}\]\]}\]\]}\]}\],\\"\\\\n\\",\[\\"$\\",\\"br\\",null,{}\],\\"\\\\n\\",\[\\"$\\",\\"p\\",null,{\\"className\\":\\"text-sm my-3\\",\\"children\\":\[\\"For all other models, you can use \\",\[\\"$\\",\\"$Lb\\",null,{\\"prefetch\\":true,\\"href\\":\\"#json-object-mode\\",\\"children\\":\\"JSON Object Mode\\"}\],\\" to get a valid JSON object, though it may not match your schema.\\"\]}\],\\"\\\\n\\",\[\\"$\\",\\"br\\",null,{}\],\\"\\\\n\\",\[\\"$\\",\\"p\\",null,{\\"className\\":\\"text-sm my-3\\",\\"children\\":\[\[\\"$\\",\\"strong\\",null,{\\"children\\":\\"Note:\\"}\],\\" \\",\[\\"$\\",\\"$Lb\\",null,{\\"prefetch\\":true,\\"href\\":\\"/docs/text-chat#streaming-a-chat-completion\\",\\"children\\":\\"streaming\\"}\],\\" and \\",\[\\"$\\",\\"$Lb\\",null,{\\"prefetch\\":true,\\"href\\":\\"/docs/tool-use\\",\\"children\\":\\"tool use\\"}\],\\" are not currently supported with Structured Outputs.\\"\]}\],\\"\\\\n\\",\[\\"$\\",\\"h3\\",null,{\\"id\\":\\"getting-a-structured-response-from-unstructured-text\\",\\"className\\":\\"mt-8 mb-3 text-base w-fit font-semibold font-header hover:underline\\",\\"children\\":\[\\"$\\",\\"a\\",null,{\\"href\\":\\"#getting-a-structured-response-from-unstructured-text\\",\\"className\\":\\"anchor-link\\",\\"children\\":\[\\"Getting a structured response from unstructured text\\"\]}\]}\],\\"\\\\n\\",\[\\"$\\",\\"$Ld\\",null,{\\"languageExamples\\":\[{\\"language\\":\\"js\\",\\"example\\":\\"$e\\"},{\\"language\\":\\"py\\",\\"example\\":\\"$f\\"},{\\"language\\":\\"curl\\",\\"example\\":\\"$10\\"}\]}\],\\"\\\\n\\",\[\\"$\\",\\"$L11\\",null,{\\"summary\\":\\"Example Output\\",\\"details\\":\\"\\\\n\`\`\`json\\\\n{\\\\n product\_name: 'UltraSound Headphones',\\\\n rating: 4.5,\\\\n sentiment: 'positive',\\\\n key\_features: \[\\\\n 'amazing noise cancellation',\\\\n 'all-day battery life',\\\\n 'crisp and clear sound quality'\\\\n \]\\\\n}\\\\n\`\`\`\\\\n\\"}\],\\"\\\\n\\",\[\\"$\\",\\"h3\\",null,{\\"id\\":\\"structured-outputs-vs-json-mode\\",\\"className\\":\\"mt-8 mb-3 text-base w-fit font-semibold font-header hover:underline\\",\\"children\\":\[\\"$\\",\\"a\\",null,{\\"href\\":\\"#structured-outputs-vs-json-mode\\",\\"className\\":\\"anchor-link\\",\\"children\\":\[\\"Structured Outputs vs JSON mode\\"\]}\]}\],\\"\\\\n\\",\[\\"$\\",\\"p\\",null,{\\"className\\":\\"text-sm my-3\\",\\"children\\":\[\\"Structured Outputs builds on \\",\[\\"$\\",\\"$Lb\\",null,{\\"prefetch\\":true,\\"href\\":\\"#json-object-mode\\",\\"children\\":\\"JSON Object Mode\\"}\],\\" with enhanced capabilities. Both produce valid JSON, but Structured Outputs goes further by matching your response to your schema exactly or throws an error if the model cannot produce a conforming response.\\"\]}\],\\"\\\\n\\",\[\\"$\\",\\"br\\",null,{}\],\\"\\\\n\\",\[\\"$\\",\\"p\\",null,{\\"className\\":\\"text-sm my-3\\",\\"children\\":\[\[\\"$\\",\\"strong\\",null,{\\"children\\":\\"Note:\\"}\],\\" Constrained decoding (which is designed to output JSON Schema compliance without errors) is currently only available on a limited-access Llama 3.1 8B model. For all other models, the endpoint attempts validation that may return errors if the model cannot produce a conforming response.\\"\]}\],\\"\\\\n\\",\[\\"$\\",\\"br\\",null,{}\],\\"\\\\n\\",\[\\"$\\",\\"p\\",null,{\\"className\\":\\"text-sm my-3\\",\\"children\\":\\"We recommend using Structured Outputs instead of JSON Object Mode whenever possible.\\"}\],\\"\\\\n\\",\[\\"$\\",\\"h2\\",null,{\\"id\\":\\"examples\\",\\"className\\":\\"\[\\u0026:not(:first-child)\]:mt-12 mb-3 text-xl w-fit font-semibold font-header hover:underline\\",\\"children\\":\[\\"$\\",\\"a\\",null,{\\"href\\":\\"#examples\\",\\"className\\":\\"anchor-link\\",\\"children\\":\[\\"Examples\\"\]}\]}\],\\"\\\\n\\",\[\\"$\\",\\"$L12\\",null,{\\"selectedContents\\":\[\\"SQL Query Generation\\",\\"Email Classification\\",\\"API Response Validation\\"\],\\"children\\":\[\[\\"$\\",\\"$L13\\",null,{\\"value\\":\\"SQL Query Generation\\",\\"children\\":\[\[\\"$\\",\\"h3\\",null,{\\"id\\":\\"sql-query-generation\\",\\"className\\":\\"mt-8 mb-3 text-base w-fit font-semibold font-header hover:underline\\",\\"children\\":\[\\"$\\",\\"a\\",null,{\\"href\\":\\"#sql-query-generation\\",\\"className\\":\\"anchor-link\\",\\"children\\":\[\\"SQL Query Generation\\"\]}\]}\],\[\\"$\\",\\"p\\",null,{\\"className\\":\\"text-sm my-3\\",\\"children\\":\\"You can generate structured SQL queries from natural language descriptions, helping ensure proper syntax and including metadata about the query structure.\\"}\],\[\\"$\\",\\"br\\",null,{}\],\[\\"$\\",\\"$Ld\\",null,{\\"languageExamples\\":\[{\\"language\\":\\"js\\",\\"example\\":\\"$14\\"},{\\"language\\":\\"py\\",\\"example\\":\\"$15\\"},{\\"language\\":\\"curl\\",\\"example\\":\\"$16\\"}\]}\],\[\\"$\\",\\"$L11\\",null,{\\"summary\\":\\"Example Output\\",\\"details\\":\\"\\\\n\`\`\`json\\\\n{\\\\n \\\\\\"query\\\\\\": \\\\\\"SELECT c.name, c.email, SUM(o.total\_amount) as total\_order\_amount FROM customers c JOIN orders o ON c.customer\_id = o.customer\_id WHERE o.order\_date \\u003e= DATE\_SUB(NOW(), INTERVAL 30 DAY) AND o.total\_amount \\u003e 500 GROUP BY c.customer\_id, c.name, c.email ORDER BY total\_order\_amount DESC\\\\\\",\\\\n \\\\\\"query\_type\\\\\\": \\\\\\"SELECT\\\\\\",\\\\n \\\\\\"tables\_used\\\\\\": \[\\\\\\"customers\\\\\\", \\\\\\"orders\\\\\\"\],\\\\n \\\\\\"estimated\_complexity\\\\\\": \\\\\\"medium\\\\\\",\\\\n \\\\\\"execution\_notes\\\\\\": \[\\\\n \\\\\\"Query uses JOIN to connect customers and orders tables\\\\\\",\\\\n \\\\\\"DATE\_SUB function calculates 30 days ago from current date\\\\\\",\\\\n \\\\\\"GROUP BY aggregates orders per customer\\\\\\",\\\\n \\\\\\"Results ordered by total order amount descending\\\\\\"\\\\n \],\\\\n \\\\\\"validation\_status\\\\\\": {\\\\n \\\\\\"is\_valid\\\\\\": true,\\\\n \\\\\\"syntax\_errors\\\\\\": \[\]\\\\n }\\\\n}\\\\n\`\`\`\\\\n\\"}\]\]}\],\[\\"$\\",\\"$L13\\",null,{\\"value\\":\\"Email Classification\\",\\"children\\":\[\[\\"$\\",\\"h3\\",null,{\\"id\\":\\"email-classification\\",\\"className\\":\\"mt-8 mb-3 text-base w-fit font-semibold font-header hover:underline\\",\\"children\\":\[\\"$\\",\\"a\\",null,{\\"href\\":\\"#email-classification\\",\\"className\\":\\"anchor-link\\",\\"children\\":\[\\"Email Classification\\"\]}\]}\],\[\\"$\\",\\"p\\",null,{\\"className\\":\\"text-sm my-3\\",\\"children\\":\\"You can classify emails into structured categories with confidence scores, priority levels, and suggested actions.\\"}\],\[\\"$\\",\\"br\\",null,{}\],\[\\"$\\",\\"$Ld\\",null,{\\"languageExamples\\":\[{\\"language\\":\\"js\\",\\"example\\":\\"$17\\"},{\\"language\\":\\"py\\",\\"example\\":\\"$18\\"},{\\"language\\":\\"curl\\",\\"example\\":\\"$19\\"}\]}\],\[\\"$\\",\\"$L11\\",null,{\\"summary\\":\\"Example Output\\",\\"details\\":\\"\\\\n\`\`\`json\\\\n{\\\\n \\\\\\"category\\\\\\": \\\\\\"urgent\\\\\\",\\\\n \\\\\\"priority\\\\\\": \\\\\\"critical\\\\\\",\\\\n \\\\\\"confidence\_score\\\\\\": 0.95,\\\\n \\\\\\"sentiment\\\\\\": \\\\\\"negative\\\\\\",\\\\n \\\\\\"key\_entities\\\\\\": \[\\\\n {\\\\n \\\\\\"entity\\\\\\": \\\\\\"production server\\\\\\",\\\\n \\\\\\"type\\\\\\": \\\\\\"system\\\\\\"\\\\n },\\\\n {\\\\n \\\\\\"entity\\\\\\": \\\\\\"2:30 PM EST\\\\\\",\\\\n \\\\\\"type\\\\\\": \\\\\\"datetime\\\\\\"\\\\n },\\\\n {\\\\n \\\\\\"entity\\\\\\": \\\\\\"DevOps Team\\\\\\",\\\\n \\\\\\"type\\\\\\": \\\\\\"organization\\\\\\"\\\\n },\\\\n {\\\\n \\\\\\"entity\\\\\\": \\\\\\"customer-facing services\\\\\\",\\\\n \\\\\\"type\\\\\\": \\\\\\"system\\\\\\"\\\\n }\\\\n \],\\\\n \\\\\\"suggested\_actions\\\\\\": \[\\\\n \\\\\\"Join emergency call immediately\\\\\\",\\\\n \\\\\\"Escalate to senior DevOps team\\\\\\",\\\\n \\\\\\"Activate incident response protocol\\\\\\",\\\\n \\\\\\"Prepare customer communication\\\\\\",\\\\n \\\\\\"Monitor service restoration progress\\\\\\"\\\\n \],\\\\n \\\\\\"requires\_immediate\_attention\\\\\\": true,\\\\n \\\\\\"estimated\_response\_time\\\\\\": \\\\\\"immediate\\\\\\"\\\\n}\\\\n\`\`\`\\\\n\\"}\]\]}\],\[\\"$\\",\\"$L13\\",null,{\\"value\\":\\"API Response Validation\\",\\"children\\":\[\[\\"$\\",\\"h3\\",null,{\\"id\\":\\"api-response-validation\\",\\"className\\":\\"mt-8 mb-3 text-base w-fit font-semibold font-header hover:underline\\",\\"children\\":\[\\"$\\",\\"a\\",null,{\\"href\\":\\"#api-response-validation\\",\\"className\\":\\"anchor-link\\",\\"children\\":\[\\"API Response Validation\\"\]}\]}\],\[\\"$\\",\\"p\\",null,{\\"className\\":\\"text-sm my-3\\",\\"children\\":\\"You can validate and structure API responses with error handling, status codes, and standardized data formats for reliable integration.\\"}\],\[\\"$\\",\\"br\\",null,{}\],\[\\"$\\",\\"$Ld\\",null,{\\"languageExamples\\":\[{\\"language\\":\\"js\\",\\"example\\":\\"$1a\\"},{\\"language\\":\\"py\\",\\"example\\":\\"$1b\\"},{\\"language\\":\\"curl\\",\\"example\\":\\"$1c\\"}\]}\],\[\\"$\\",\\"$L11\\",null,{\\"summary\\":\\"Example Output\\",\\"details\\":\\"\\\\n\`\`\`json\\\\n{\\\\n \\\\\\"validation\_result\\\\\\": {\\\\n \\\\\\"is\_valid\\\\\\": false,\\\\n \\\\\\"status\_code\\\\\\": 400,\\\\n \\\\\\"error\_count\\\\\\": 2\\\\n },\\\\n \\\\\\"field\_validations\\\\\\": \[\\\\n {\\\\n \\\\\\"field\_name\\\\\\": \\\\\\"user\_id\\\\\\",\\\\n \\\\\\"field\_type\\\\\\": \\\\\\"string\\\\\\",\\\\n \\\\\\"is\_valid\\\\\\": true,\\\\n \\\\\\"error\_message\\\\\\": \\\\\\"\\\\\\",\\\\n \\\\\\"expected\_format\\\\\\": \\\\\\"string\\\\\\"\\\\n },\\\\n {\\\\n \\\\\\"field\_name\\\\\\": \\\\\\"email\\\\\\",\\\\n \\\\\\"field\_type\\\\\\": \\\\\\"string\\\\\\",\\\\n \\\\\\"is\_valid\\\\\\": false,\\\\n \\\\\\"error\_message\\\\\\": \\\\\\"Invalid email format\\\\\\",\\\\n \\\\\\"expected\_format\\\\\\": \\\\\\"valid email address (e.g., user@example.com)\\\\\\"\\\\n }\\\\n \],\\\\n \\\\\\"data\_quality\_score\\\\\\": 0.7,\\\\n \\\\\\"suggested\_fixes\\\\\\": \[\\\\n \\\\\\"Fix email format validation to ensure proper email structure\\\\\\",\\\\n \\\\\\"Add proper error handling structure to response\\\\\\"\\\\n \],\\\\n \\\\\\"compliance\_check\\\\\\": {\\\\n \\\\\\"follows\_rest\_standards\\\\\\": false,\\\\n \\\\\\"has\_proper\_error\_handling\\\\\\": false,\\\\n \\\\\\"includes\_metadata\\\\\\": false\\\\n }\\\\n}\\\\n\`\`\`\\\\n\\"}\]\]}\]\]}\],\\"\\\\n\\",\[\\"$\\",\\"h2\\",null,{\\"id\\":\\"schema-validation-libraries\\",\\"className\\":\\"\[\\u0026:not(:first-child)\]:mt-12 mb-3 text-xl w-fit font-semibold font-header hover:underline\\",\\"children\\":\[\\"$\\",\\"a\\",null,{\\"href\\":\\"#schema-validation-libraries\\",\\"className\\":\\"anchor-link\\",\\"children\\":\[\\"Schema Validation Libraries\\"\]}\]}\],\\"\\\\n\\",\[\\"$\\",\\"p\\",null,{\\"className\\":\\"text-sm my-3\\",\\"children\\":\[\\"When working with Structured Outputs, you can use popular schema validation libraries like \\",\[\\"$\\",\\"$Lb\\",null,{\\"prefetch\\":true,\\"href\\":\\"https://zod.dev/\\",\\"children\\":\\"Zod\\"}\],\\" for TypeScript and \\",\[\\"$\\",\\"$Lb\\",null,{\\"prefetch\\":true,\\"href\\":\\"https://docs.pydantic.dev/latest/\\",\\"children\\":\\"Pydantic\\"}\],\\" for Python. These libraries provide type safety, runtime validation, and seamless integration with JSON Schema generation.\\"\]}\],\\"\\\\n\\",\[\\"$\\",\\"h3\\",null,{\\"id\\":\\"support-ticket-classification\\",\\"className\\":\\"mt-8 mb-3 text-base w-fit font-semibold font-header hover:underline\\",\\"children\\":\[\\"$\\",\\"a\\",null,{\\"href\\":\\"#support-ticket-classification\\",\\"className\\":\\"anchor-link\\",\\"children\\":\[\\"Support Ticket Classification\\"\]}\]}\],\\"\\\\n\\",\[\\"$\\",\\"p\\",null,{\\"className\\":\\"text-sm my-3\\",\\"children\\":\\"This example demonstrates how to classify customer support tickets using structured schemas with both Zod and Pydantic, ensuring consistent categorization and routing.\\"}\],\\"\\\\n\\",\[\\"$\\",\\"$L12\\",null,{\\"selectedContents\\":\[\\"Zod (TypeScript)\\",\\"Pydantic (Python)\\"\],\\"children\\":\[\[\\"$\\",\\"$L13\\",null,{\\"value\\":\\"Zod (TypeScript)\\",\\"children\\":\[\\"$\\",\\"$Ld\\",null,{\\"languageExamples\\":\[{\\"language\\":\\"typescript\\",\\"example\\":\\"$1d\\"}\]}\]}\],\[\\"$\\",\\"$L13\\",null,{\\"value\\":\\"Pydantic (Python)\\",\\"children\\":\[\\"$\\",\\"$Ld\\",null,{\\"languageExamples\\":\[{\\"language\\":\\"python\\",\\"example\\":\\"$1e\\"}\]}\]}\]\]}\],\\"\\\\n\\",\[\\"$\\",\\"$L11\\",null,{\\"summary\\":\\"Example Output\\",\\"details\\":\\"\\\\n\`\`\`json\\\\n{\\\\n \\\\\\"category\\\\\\": \\\\\\"feature\_request\\\\\\",\\\\n \\\\\\"priority\\\\\\": \\\\\\"low\\\\\\",\\\\n \\\\\\"urgency\_score\\\\\\": 2.5,\\\\n \\\\\\"customer\_info\\\\\\": {\\\\n \\\\\\"name\\\\\\": \\\\\\"Mike\\\\\\",\\\\n \\\\\\"company\\\\\\": \\\\\\"StartupXYZ\\\\\\",\\\\n \\\\\\"tier\\\\\\": \\\\\\"paid\\\\\\"\\\\n },\\\\n \\\\\\"technical\_details\\\\\\": \[\\\\n {\\\\n \\\\\\"component\\\\\\": \\\\\\"dashboard\\\\\\",\\\\n \\\\\\"description\\\\\\": \\\\\\"Request for dark mode feature\\\\\\"\\\\n },\\\\n {\\\\n \\\\\\"component\\\\\\": \\\\\\"user\_interface\\\\\\",\\\\n \\\\\\"description\\\\\\": \\\\\\"Request for keyboard shortcuts\\\\\\"\\\\n }\\\\n \],\\\\n \\\\\\"keywords\\\\\\": \[\\\\\\"dark mode\\\\\\", \\\\\\"dashboard\\\\\\", \\\\\\"keyboard shortcuts\\\\\\", \\\\\\"enhancement\\\\\\"\],\\\\n \\\\\\"requires\_escalation\\\\\\": false,\\\\n \\\\\\"estimated\_resolution\_hours\\\\\\": 40,\\\\n \\\\\\"summary\\\\\\": \\\\\\"Feature request for dark mode and keyboard shortcuts from paying customer\\\\\\"\\\\n}\\\\n\`\`\`\\\\n\\"}\],\\"\\\\n\\",\[\\"$\\",\\"h2\\",null,{\\"id\\":\\"implementation-guide\\",\\"className\\":\\"\[\\u0026:not(:first-child)\]:mt-12 mb-3 text-xl w-fit font-semibold font-header hover:underline\\",\\"children\\":\[\\"$\\",\\"a\\",null,{\\"href\\":\\"#implementation-guide\\",\\"className\\":\\"anchor-link\\",\\"children\\":\[\\"Implementation Guide\\"\]}\]}\],\\"\\\\n\\",\[\\"$\\",\\"h3\\",null,{\\"id\\":\\"schema-definition\\",\\"className\\":\\"mt-8 mb-3 text-base w-fit font-semibold font-header hover:underline\\",\\"children\\":\[\\"$\\",\\"a\\",null,{\\"href\\":\\"#schema-definition\\",\\"className\\":\\"anchor-link\\",\\"children\\":\[\\"Schema Definition\\"\]}\]}\],\\"\\\\n\\",\[\\"$\\",\\"p\\",null,{\\"className\\":\\"text-sm my-3\\",\\"children\\":\[\\"Design your JSON Schema to constrain model responses. Reference the \\",\[\\"$\\",\\"$Lb\\",null,{\\"prefetch\\":true,\\"href\\":\\"#examples\\",\\"children\\":\\"examples\\"}\],\\" above and see \\",\[\\"$\\",\\"$Lb\\",null,{\\"prefetch\\":true,\\"href\\":\\"#schema-requirements\\",\\"children\\":\\"supported schema features\\"}\],\\" for technical limitations.\\"\]}\],\\"\\\\n\\",\[\\"$\\",\\"br\\",null,{}\],\\"\\\\n\\",\[\\"$\\",\\"p\\",null,{\\"className\\":\\"text-sm my-3\\",\\"children\\":\[\\"$\\",\\"strong\\",null,{\\"children\\":\\"Schema optimization tips:\\"}\]}\],\\"\\\\n\\",\[\\"$\\",\\"ul\\",null,{\\"className\\":\\"list-disc my-1 text-sm\\",\\"children\\":\[\\"\\\\n\\",\[\\"$\\",\\"li\\",null,{\\"className\\":\\"ml-6 my-1.5 text-sm\\",\\"children\\":\\"Use descriptive property names and clear descriptions for complex fields\\"}\],\\"\\\\n\\",\[\\"$\\",\\"li\\",null,{\\"className\\":\\"ml-6 my-1.5 text-sm\\",\\"children\\":\\"Create evaluation sets to test schema effectiveness\\"}\],\\"\\\\n\\",\[\\"$\\",\\"li\\",null,{\\"className\\":\\"ml-6 my-1.5 text-sm\\",\\"children\\":\\"Include titles for important structural elements\\"}\],\\"\\\\n\\"\]}\],\\"\\\\n\\",\[\\"$\\",\\"h3\\",null,{\\"id\\":\\"api-integration\\",\\"className\\":\\"mt-8 mb-3 text-base w-fit font-semibold font-header hover:underline\\",\\"children\\":\[\\"$\\",\\"a\\",null,{\\"href\\":\\"#api-integration\\",\\"className\\":\\"anchor-link\\",\\"children\\":\[\\"API Integration\\"\]}\]}\],\\"\\\\n\\",\[\\"$\\",\\"p\\",null,{\\"className\\":\\"text-sm my-3\\",\\"children\\":\[\\"Include the schema in your API request using the \\",\[\\"$\\",\\"code\\",null,{\\"className\\":\\"bg-gray-100 dark:bg-gray-800 py-0.5 px-\[0.5em\] rounded-\[4px\]\\",\\"children\\":\\"response\_format\\"}\],\\" parameter:\\"\]}\],\\"\\\\n\\",\[\\"$\\",\\"$Ld\\",null,{\\"languageExamples\\":\[{\\"language\\":\\"json\\",\\"example\\":\\"response\_format: { type: \\\\\\"json\_schema\\\\\\", json\_schema: { name: \\\\\\"schema\_name\\\\\\", schema:  } }\\"}\]}\],\\"\\\\n\\",\[\\"$\\",\\"br\\",null,{}\],\\"\\\\n\\",\[\\"$\\",\\"p\\",null,{\\"className\\":\\"text-sm my-3\\",\\"children\\":\\"Complete implementation example:\\"}\],\\"\\\\n\\",\[\\"$\\",\\"$Ld\\",null,{\\"languageExamples\\":\[{\\"language\\":\\"py\\",\\"example\\":\\"$1f\\"},{\\"language\\":\\"js\\",\\"example\\":\\"$20\\"},{\\"language\\":\\"curl\\",\\"example\\":\\"$21\\"}\]}\],\\"\\\\n\\",\[\\"$\\",\\"h3\\",null,{\\"id\\":\\"error-handling\\",\\"className\\":\\"mt-8 mb-3 text-base w-fit font-semibold font-header hover:underline\\",\\"children\\":\[\\"$\\",\\"a\\",null,{\\"href\\":\\"#error-handling\\",\\"className\\":\\"anchor-link\\",\\"children\\":\[\\"Error Handling\\"\]}\]}\],\\"\\\\n\\",\[\\"$\\",\\"p\\",null,{\\"className\\":\\"text-sm my-3\\",\\"children\\":\[\\"Schema validation failures return HTTP 400 errors with the message \\",\[\\"$\\",\\"code\\",null,{\\"className\\":\\"bg-gray-100 dark:bg-gray-800 py-0.5 px-\[0.5em\] rounded-\[4px\]\\",\\"children\\":\\"Generated JSON does not match the expected schema. Please adjust your prompt.\\"}\]\]}\],\\"\\\\n\\",\[\\"$\\",\\"br\\",null,{}\],\\"\\\\n\\",\[\\"$\\",\\"p\\",null,{\\"className\\":\\"text-sm my-3\\",\\"children\\":\[\\"$\\",\\"strong\\",null,{\\"children\\":\\"Resolution strategies:\\"}\]}\],\\"\\\\n\\",\[\\"$\\",\\"ul\\",null,{\\"className\\":\\"list-disc my-1 text-sm\\",\\"children\\":\[\\"\\\\n\\",\[\\"$\\",\\"li\\",null,{\\"className\\":\\"ml-6 my-1.5 text-sm\\",\\"children\\":\\"Retry requests for transient failures\\"}\],\\"\\\\n\\",\[\\"$\\",\\"li\\",null,{\\"className\\":\\"ml-6 my-1.5 text-sm\\",\\"children\\":\\"Refine prompts for recurring schema mismatches\\"}\],\\"\\\\n\\",\[\\"$\\",\\"li\\",null,{\\"className\\":\\"ml-6 my-1.5 text-sm\\",\\"children\\":\\"Simplify complex schemas if validation consistently fails\\"}\],\\"\\\\n\\"\]}\],\\"\\\\n\\",\[\\"$\\",\\"h3\\",null,{\\"id\\":\\"best-practices\\",\\"className\\":\\"mt-8 mb-3 text-base w-fit font-semibold font-header hover:underline\\",\\"children\\":\[\\"$\\",\\"a\\",null,{\\"href\\":\\"#best-practices\\",\\"className\\":\\"anchor-link\\",\\"children\\":\[\\"Best Practices\\"\]}\]}\],\\"\\\\n\\",\[\\"$\\",\\"p\\",null,{\\"className\\":\\"text-sm my-3\\",\\"children\\":\[\[\\"$\\",\\"strong\\",null,{\\"children\\":\\"User input handling:\\"}\],\\" Include explicit instructions for invalid or incompatible inputs. Models attempt schema adherence even with unrelated data, potentially causing hallucinations. Specify fallback responses (empty fields, error messages) for incompatible inputs.\\"\]}\],\\"\\\\n\\",\[\\"$\\",\\"br\\",null,{}\],\\"\\\\n\\",\[\\"$\\",\\"p\\",null,{\\"className\\":\\"text-sm my-3\\",\\"children\\":\[\[\\"$\\",\\"strong\\",null,{\\"children\\":\\"Output quality:\\"}\],\\" Structured outputs are designed to output schema compliance but not semantic accuracy. For persistent errors, refine instructions, add system message examples, or decompose complex tasks. See the \\",\[\\"$\\",\\"$Lb\\",null,{\\"prefetch\\":true,\\"href\\":\\"/docs/prompting\\",\\"children\\":\\"prompt engineering guide\\"}\],\\" for optimization techniques.\\"\]}\],\\"\\\\n\\",\[\\"$\\",\\"h2\\",null,{\\"id\\":\\"schema-requirements\\",\\"className\\":\\"\[\\u0026:not(:first-child)\]:mt-12 mb-3 text-xl w-fit font-semibold font-header hover:underline\\",\\"children\\":\[\\"$\\",\\"a\\",null,{\\"href\\":\\"#schema-requirements\\",\\"className\\":\\"anchor-link\\",\\"children\\":\[\\"Schema Requirements\\"\]}\]}\],\\"\\\\n\\",\[\\"$\\",\\"p\\",null,{\\"className\\":\\"text-sm my-3\\",\\"children\\":\[\\"Structured Outputs supports a \\",\[\\"$\\",\\"$Lb\\",null,{\\"prefetch\\":true,\\"href\\":\\"https://json-schema.org/docs\\",\\"children\\":\\"JSON Schema\\"}\],\\" subset with specific constraints for performance and reliability.\\"\]}\],\\"\\\\n\\",\[\\"$\\",\\"h3\\",null,{\\"id\\":\\"supported-data-types\\",\\"className\\":\\"mt-8 mb-3 text-base w-fit font-semibold font-header hover:underline\\",\\"children\\":\[\\"$\\",\\"a\\",null,{\\"href\\":\\"#supported-data-types\\",\\"className\\":\\"anchor-link\\",\\"children\\":\[\\"Supported Data Types\\"\]}\]}\],\\"\\\\n\\",\[\\"$\\",\\"ul\\",null,{\\"className\\":\\"list-disc my-1 text-sm\\",\\"children\\":\[\\"\\\\n\\",\[\\"$\\",\\"li\\",null,{\\"className\\":\\"ml-6 my-1.5 text-sm\\",\\"children\\":\[\[\\"$\\",\\"strong\\",null,{\\"children\\":\\"Primitives:\\"}\],\\" String, Number, Boolean, Integer\\"\]}\],\\"\\\\n\\",\[\\"$\\",\\"li\\",null,{\\"className\\":\\"ml-6 my-1.5 text-sm\\",\\"children\\":\[\[\\"$\\",\\"strong\\",null,{\\"children\\":\\"Complex:\\"}\],\\" Object, Array, Enum\\"\]}\],\\"\\\\n\\",\[\\"$\\",\\"li\\",null,{\\"className\\":\\"ml-6 my-1.5 text-sm\\",\\"children\\":\[\[\\"$\\",\\"strong\\",null,{\\"children\\":\\"Composition:\\"}\],\\" anyOf (union types)\\"\]}\],\\"\\\\n\\"\]}\],\\"\\\\n\\",\[\\"$\\",\\"h3\\",null,{\\"id\\":\\"mandatory-constraints\\",\\"className\\":\\"mt-8 mb-3 text-base w-fit font-semibold font-header hover:underline\\",\\"children\\":\[\\"$\\",\\"a\\",null,{\\"href\\":\\"#mandatory-constraints\\",\\"className\\":\\"anchor-link\\",\\"children\\":\[\\"Mandatory Constraints\\"\]}\]}\],\\"\\\\n\\",\[\\"$\\",\\"p\\",null,{\\"className\\":\\"text-sm my-3\\",\\"children\\":\[\[\\"$\\",\\"strong\\",null,{\\"children\\":\\"Required fields:\\"}\],\\" All schema properties must be marked as \\",\[\\"$\\",\\"code\\",null,{\\"className\\":\\"bg-gray-100 dark:bg-gray-800 py-0.5 px-\[0.5em\] rounded-\[4px\]\\",\\"children\\":\\"required\\"}\],\\". Optional fields are not supported.\\"\]}\],\\"\\\\n\\",\[\\"$\\",\\"br\\",null,{}\],\\"\\\\n\\",\[\\"$\\",\\"$Ld\\",null,{\\"languageExamples\\":\[{\\"language\\":\\"json\\",\\"example\\":\\"{\\\\n \\\\\\"name\\\\\\": \\\\\\"create\_task\\\\\\",\\\\n \\\\\\"description\\\\\\": \\\\\\"Creates a new task in the project management system\\\\\\",\\\\n \\\\\\"strict\\\\\\": true,\\\\n \\\\\\"parameters\\\\\\": {\\\\n \\\\\\"type\\\\\\": \\\\\\"object\\\\\\",\\\\n \\\\\\"properties\\\\\\": {\\\\n \\\\\\"title\\\\\\": {\\\\n \\\\\\"type\\\\\\": \\\\\\"string\\\\\\",\\\\n \\\\\\"description\\\\\\": \\\\\\"The task title or summary\\\\\\"\\\\n },\\\\n \\\\\\"priority\\\\\\": {\\\\n \\\\\\"type\\\\\\": \\\\\\"string\\\\\\",\\\\n \\\\\\"description\\\\\\": \\\\\\"Task priority level\\\\\\",\\\\n \\\\\\"enum\\\\\\": \[\\\\\\"low\\\\\\", \\\\\\"medium\\\\\\", \\\\\\"high\\\\\\", \\\\\\"urgent\\\\\\"\]\\\\n }\\\\n },\\\\n \\\\\\"additionalProperties\\\\\\": false,\\\\n \\\\\\"required\\\\\\": \[\\\\\\"title\\\\\\", \\\\\\"priority\\\\\\"\]\\\\n }\\\\n}\\\\n\\"}\]}\],\\"\\\\n\\",\[\\"$\\",\\"br\\",null,{}\],\\"\\\\n\\",\[\\"$\\",\\"p\\",null,{\\"className\\":\\"text-sm my-3\\",\\"children\\":\[\[\\"$\\",\\"strong\\",null,{\\"children\\":\\"Closed objects:\\"}\],\\" All objects must set \\",\[\\"$\\",\\"code\\",null,{\\"className\\":\\"bg-gray-100 dark:bg-gray-800 py-0.5 px-\[0.5em\] rounded-\[4px\]\\",\\"children\\":\\"additionalProperties: false\\"}\],\\" to prevent undefined properties. This ensures strict schema adherence.\\"\]}\],\\"\\\\n\\",\[\\"$\\",\\"br\\",null,{}\],\\"\\\\n\\",\[\\"$\\",\\"$Ld\\",null,{\\"languageExamples\\":\[{\\"language\\":\\"json\\",\\"example\\":\\"{\\\\n \\\\\\"name\\\\\\": \\\\\\"book\_appointment\\\\\\",\\\\n \\\\\\"description\\\\\\": \\\\\\"Books a medical appointment\\\\\\",\\\\n \\\\\\"strict\\\\\\": true,\\\\n \\\\\\"schema\\\\\\": {\\\\n \\\\\\"type\\\\\\": \\\\\\"object\\\\\\",\\\\n \\\\\\"properties\\\\\\": {\\\\n \\\\\\"patient\_name\\\\\\": {\\\\n \\\\\\"type\\\\\\": \\\\\\"string\\\\\\",\\\\n \\\\\\"description\\\\\\": \\\\\\"Full name of the patient\\\\\\"\\\\n },\\\\n \\\\\\"appointment\_type\\\\\\": {\\\\n \\\\\\"type\\\\\\": \\\\\\"string\\\\\\",\\\\n \\\\\\"description\\\\\\": \\\\\\"Type of medical appointment\\\\\\",\\\\n \\\\\\"enum\\\\\\": \[\\\\\\"consultation\\\\\\", \\\\\\"checkup\\\\\\", \\\\\\"surgery\\\\\\", \\\\\\"emergency\\\\\\"\]\\\\n }\\\\n },\\\\n \\\\\\"additionalProperties\\\\\\": false,\\\\n \\\\\\"required\\\\\\": \[\\\\\\"patient\_name\\\\\\", \\\\\\"appointment\_type\\\\\\"\]\\\\n }\\\\n}\\\\n\\"}\]}\],\\"\\\\n\\",\[\\"$\\",\\"br\\",null,{}\],\\"\\\\n\\",\[\\"$\\",\\"p\\",null,{\\"className\\":\\"text-sm my-3\\",\\"children\\":\[\[\\"$\\",\\"strong\\",null,{\\"children\\":\\"Union types:\\"}\],\\" Each schema within \\",\[\\"$\\",\\"code\\",null,{\\"className\\":\\"bg-gray-100 dark:bg-gray-800 py-0.5 px-\[0.5em\] rounded-\[4px\]\\",\\"children\\":\\"anyOf\\"}\],\\" must comply with all subset restrictions:\\"\]}\],\\"\\\\n\\",\[\\"$\\",\\"br\\",null,{}\],\\"\\\\n\\",\[\\"$\\",\\"$Ld\\",null,{\\"languageExamples\\":\[{\\"language\\":\\"json\\",\\"example\\":\\"$22\\"}\]}\],\\"\\\\n\\",\[\\"$\\",\\"br\\",null,{}\],\\"\\\\n\\",\[\\"$\\",\\"p\\",null,{\\"className\\":\\"text-sm my-3\\",\\"children\\":\[\[\\"$\\",\\"strong\\",null,{\\"children\\":\\"Reusable subschemas:\\"}\],\\" Define reusable components with \\",\[\\"$\\",\\"code\\",null,{\\"className\\":\\"bg-gray-100 dark:bg-gray-800 py-0.5 px-\[0.5em\] rounded-\[4px\]\\",\\"children\\":\\"$$defs\\"}\],\\" and reference them using \\",\[\\"$\\",\\"code\\",null,{\\"className\\":\\"bg-gray-100 dark:bg-gray-800 py-0.5 px-\[0.5em\] rounded-\[4px\]\\",\\"children\\":\\"$$ref\\"}\],\\":\\"\]}\],\\"\\\\n\\",\[\\"$\\",\\"br\\",null,{}\],\\"\\\\n\\",\[\\"$\\",\\"$Ld\\",null,{\\"languageExamples\\":\[{\\"language\\":\\"json\\",\\"example\\":\\"{\\\\n \\\\\\"type\\\\\\": \\\\\\"object\\\\\\",\\\\n \\\\\\"properties\\\\\\": {\\\\n \\\\\\"milestones\\\\\\": {\\\\n \\\\\\"type\\\\\\": \\\\\\"array\\\\\\",\\\\n \\\\\\"items\\\\\\": {\\\\n \\\\\\"$ref\\\\\\": \\\\\\"#/$defs/milestone\\\\\\"\\\\n }\\\\n },\\\\n \\\\\\"project\_status\\\\\\": {\\\\n \\\\\\"type\\\\\\": \\\\\\"string\\\\\\",\\\\n \\\\\\"enum\\\\\\": \[\\\\\\"planning\\\\\\", \\\\\\"in\_progress\\\\\\", \\\\\\"completed\\\\\\", \\\\\\"on\_hold\\\\\\"\]\\\\n }\\\\n },\\\\n \\\\\\"$defs\\\\\\": {\\\\n \\\\\\"milestone\\\\\\": {\\\\n \\\\\\"type\\\\\\": \\\\\\"object\\\\\\",\\\\n \\\\\\"properties\\\\\\": {\\\\n \\\\\\"title\\\\\\": {\\\\n \\\\\\"type\\\\\\": \\\\\\"string\\\\\\",\\\\n \\\\\\"description\\\\\\": \\\\\\"Milestone name\\\\\\"\\\\n },\\\\n \\\\\\"deadline\\\\\\": {\\\\n \\\\\\"type\\\\\\": \\\\\\"string\\\\\\",\\\\n \\\\\\"description\\\\\\": \\\\\\"Due date in ISO format\\\\\\"\\\\n },\\\\n \\\\\\"completed\\\\\\": {\\\\n \\\\\\"type\\\\\\": \\\\\\"boolean\\\\\\"\\\\n }\\\\n },\\\\n \\\\\\"required\\\\\\": \[\\\\\\"title\\\\\\", \\\\\\"deadline\\\\\\", \\\\\\"completed\\\\\\"\],\\\\n \\\\\\"additionalProperties\\\\\\": false\\\\n }\\\\n },\\\\n \\\\\\"required\\\\\\": \[\\\\\\"milestones\\\\\\", \\\\\\"project\_status\\\\\\"\],\\\\n \\\\\\"additionalProperties\\\\\\": false\\\\n}\\\\n\\"}\]}\],\\"\\\\n\\",\[\\"$\\",\\"br\\",null,{}\],\\"\\\\n\\",\[\\"$\\",\\"p\\",null,{\\"className\\":\\"text-sm my-3\\",\\"children\\":\[\[\\"$\\",\\"strong\\",null,{\\"children\\":\\"Root recursion:\\"}\],\\" Use \\",\[\\"$\\",\\"code\\",null,{\\"className\\":\\"bg-gray-100 dark:bg-gray-800 py-0.5 px-\[0.5em\] rounded-\[4px\]\\",\\"children\\":\\"#\\"}\],\\" to reference the root schema:\\"\]}\],\\"\\\\n\\",\[\\"$\\",\\"br\\",null,{}\],\\"\\\\n\\",\[\\"$\\",\\"$Ld\\",null,{\\"languageExamples\\":\[{\\"language\\":\\"json\\",\\"example\\":\\"$23\\"}\]}\],\\"\\\\n\\",\[\\"$\\",\\"br\\",null,{}\],\\"\\\\n\\",\[\\"$\\",\\"p\\",null,{\\"className\\":\\"text-sm my-3\\",\\"children\\":\[\[\\"$\\",\\"strong\\",null,{\\"children\\":\\"Explicit recursion\\"}\],\\" through definition references:\\"\]}\],\\"\\\\n\\",\[\\"$\\",\\"br\\",null,{}\],\\"\\\\n\\",\[\\"$\\",\\"$Ld\\",null,{\\"languageExamples\\":\[{\\"language\\":\\"json\\",\\"example\\":\\"{\\\\n \\\\\\"type\\\\\\": \\\\\\"object\\\\\\",\\\\n \\\\\\"properties\\\\\\": {\\\\n \\\\\\"file\_system\\\\\\": {\\\\n \\\\\\"$ref\\\\\\": \\\\\\"#/$defs/file\_node\\\\\\"\\\\n }\\\\n },\\\\n \\\\\\"$defs\\\\\\": {\\\\n \\\\\\"file\_node\\\\\\": {\\\\n \\\\\\"type\\\\\\": \\\\\\"object\\\\\\",\\\\n \\\\\\"properties\\\\\\": {\\\\n \\\\\\"name\\\\\\": {\\\\n \\\\\\"type\\\\\\": \\\\\\"string\\\\\\",\\\\n \\\\\\"description\\\\\\": \\\\\\"File or directory name\\\\\\"\\\\n },\\\\n \\\\\\"type\\\\\\": {\\\\n \\\\\\"type\\\\\\": \\\\\\"string\\\\\\",\\\\n \\\\\\"enum\\\\\\": \[\\\\\\"file\\\\\\", \\\\\\"directory\\\\\\"\]\\\\n },\\\\n \\\\\\"size\\\\\\": {\\\\n \\\\\\"type\\\\\\": \\\\\\"number\\\\\\",\\\\n \\\\\\"description\\\\\\": \\\\\\"Size in bytes (0 for directories)\\\\\\"\\\\n },\\\\n \\\\\\"children\\\\\\": {\\\\n \\\\\\"anyOf\\\\\\": \[\\\\n {\\\\n \\\\\\"type\\\\\\": \\\\\\"array\\\\\\",\\\\n \\\\\\"items\\\\\\": {\\\\n \\\\\\"$ref\\\\\\": \\\\\\"#/$defs/file\_node\\\\\\"\\\\n }\\\\n },\\\\n {\\\\n \\\\\\"type\\\\\\": \\\\\\"null\\\\\\"\\\\n }\\\\n \]\\\\n }\\\\n },\\\\n \\\\\\"additionalProperties\\\\\\": false,\\\\n \\\\\\"required\\\\\\": \[\\\\\\"name\\\\\\", \\\\\\"type\\\\\\", \\\\\\"size\\\\\\", \\\\\\"children\\\\\\"\]\\\\n }\\\\n },\\\\n \\\\\\"additionalProperties\\\\\\": false,\\\\n \\\\\\"required\\\\\\": \[\\\\\\"file\_system\\\\\\"\]\\\\n}\\\\n\\"}\]}\],\\"\\\\n\\",\[\\"$\\",\\"h2\\",null,{\\"id\\":\\"json-object-mode\\",\\"className\\":\\"\[\\u0026:not(:first-child)\]:mt-12 mb-3 text-xl w-fit font-semibold font-header hover:underline\\",\\"children\\":\[\\"$\\",\\"a\\",null,{\\"href\\":\\"#json-object-mode\\",\\"className\\":\\"anchor-link\\",\\"children\\":\[\\"JSON Object Mode\\"\]}\]}\],\\"\\\\n\\",\[\\"$\\",\\"p\\",null,{\\"className\\":\\"text-sm my-3\\",\\"children\\":\[\\"JSON Object Mode provides basic JSON output validation without schema enforcement. Unlike Structured Outputs with \\",\[\\"$\\",\\"code\\",null,{\\"className\\":\\"bg-gray-100 dark:bg-gray-800 py-0.5 px-\[0.5em\] rounded-\[4px\]\\",\\"children\\":\\"json\_schema\\"}\],\\" mode, it is designed to output valid JSON syntax but not schema compliance. The endpoint will either return valid JSON or throw an error if the model cannot produce valid JSON syntax. Use \\",\[\\"$\\",\\"$Lb\\",null,{\\"prefetch\\":true,\\"href\\":\\"#introduction\\",\\"children\\":\\"Structured Outputs\\"}\],\\" when available for your use case.\\"\]}\],\\"\\\\n\\",\[\\"$\\",\\"br\\",null,{}\],\\"\\\\n\\",\[\\"$\\",\\"p\\",null,{\\"className\\":\\"text-sm my-3\\",\\"children\\":\[\\"Enable JSON Object Mode by setting \\",\[\\"$\\",\\"code\\",null,{\\"className\\":\\"bg-gray-100 dark:bg-gray-800 py-0.5 px-\[0.5em\] rounded-\[4px\]\\",\\"children\\":\\"response\_format\\"}\],\\" to \\",\[\\"$\\",\\"code\\",null,{\\"className\\":\\"bg-gray-100 dark:bg-gray-800 py-0.5 px-\[0.5em\] rounded-\[4px\]\\",\\"children\\":\\"{ \\\\\\"type\\\\\\": \\\\\\"json\_object\\\\\\" }\\"}\],\\".\\"\]}\],\\"\\\\n\\",\[\\"$\\",\\"br\\",null,{}\],\\"\\\\n\\",\[\\"$\\",\\"p\\",null,{\\"className\\":\\"text-sm my-3\\",\\"children\\":\[\\"$\\",\\"strong\\",null,{\\"children\\":\\"Requirements and limitations:\\"}\]}\],\\"\\\\n\\",\[\\"$\\",\\"ul\\",null,{\\"className\\":\\"list-disc my-1 text-sm\\",\\"children\\":\[\\"\\\\n\\",\[\\"$\\",\\"li\\",null,{\\"className\\":\\"ml-6 my-1.5 text-sm\\",\\"children\\":\\"Include explicit JSON instructions in your prompt (system message or user input)\\"}\],\\"\\\\n\\",\[\\"$\\",\\"li\\",null,{\\"className\\":\\"ml-6 my-1.5 text-sm\\",\\"children\\":\\"Outputs are syntactically valid JSON but may not match your intended schema\\"}\],\\"\\\\n\\",\[\\"$\\",\\"li\\",null,{\\"className\\":\\"ml-6 my-1.5 text-sm\\",\\"children\\":\\"Combine with validation libraries and retry logic for schema compliance\\"}\],\\"\\\\n\\"\]}\],\\"\\\\n\\",\[\\"$\\",\\"h3\\",null,{\\"id\\":\\"sentiment-analysis-example\\",\\"className\\":\\"mt-8 mb-3 text-base w-fit font-semibold font-header hover:underline\\",\\"children\\":\[\\"$\\",\\"a\\",null,{\\"href\\":\\"#sentiment-analysis-example\\",\\"className\\":\\"anchor-link\\",\\"children\\":\[\\"Sentiment Analysis Example\\"\]}\]}\],\\"\\\\n\\",\[\\"$\\",\\"p\\",null,{\\"className\\":\\"text-sm my-3\\",\\"children\\":\\"This example shows prompt-guided JSON generation for sentiment analysis, adaptable to classification, extraction, or summarization tasks:\\"}\],\\"\\\\n\\",\[\\"$\\",\\"$Ld\\",null,{\\"languageExamples\\":\[{\\"language\\":\\"js\\",\\"example\\":\\"$24\\"},{\\"language\\":\\"py\\",\\"example\\":\\"$25\\"},{\\"language\\":\\"curl\\",\\"example\\":\\"curl https://api.groq.com/openai/v1/chat/completions \\\\\\\\\\\\n -H \\\\\\"Authorization: Bearer $GROQ\_API\_KEY\\\\\\" \\\\\\\\\\\\n -H \\\\\\"Content-Type: application/json\\\\\\" \\\\\\\\\\\\n -d '{\\\\n \\\\\\"model\\\\\\": \\\\\\"llama-3.3-70b-versatile\\\\\\",\\\\n \\\\\\"messages\\\\\\": \[\\\\n {\\\\n \\\\\\"role\\\\\\": \\\\\\"system\\\\\\",\\\\n \\\\\\"content\\\\\\": \\\\\\"You are a data analysis API that performs sentiment analysis on text. Respond only with JSON using this format: { \\\\\\\\\\\\\\"sentiment\_analysis\\\\\\\\\\\\\\": { \\\\\\\\\\\\\\"sentiment\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"positive|negative|neutral\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"confidence\_score\\\\\\\\\\\\\\": 0.95, \\\\\\\\\\\\\\"key\_phrases\\\\\\\\\\\\\\": \[ { \\\\\\\\\\\\\\"phrase\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"detected key phrase\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"sentiment\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"positive|negative|neutral\\\\\\\\\\\\\\" } \], \\\\\\\\\\\\\\"summary\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"One sentence summary of the overall sentiment\\\\\\\\\\\\\\" } }\\\\\\"\\\\n },\\\\n {\\\\n \\\\\\"role\\\\\\": \\\\\\"user\\\\\\",\\\\n \\\\\\"content\\\\\\": \\\\\\"Analyze the sentiment of this customer review: '\\\\\\\\''I absolutely love this product! The quality exceeded my expectations, though shipping took longer than expected.'\\\\\\\\''\\\\\\"\\\\n }\\\\n \],\\\\n \\\\\\"response\_format\\\\\\": { \\\\\\"type\\\\\\": \\\\\\"json\_object\\\\\\" }\\\\n }'\\"}\]}\],\\"\\\\n\\",\[\\"$\\",\\"p\\",null,{\\"className\\":\\"text-sm my-3\\",\\"children\\":\\"System prompts structure the output format while maintaining JSON validity. However, keep in mind that the JSON object output may not match your schema.\\"}\],\\"\\\\n\\",\[\\"$\\",\\"br\\",null,{}\],\\"\\\\n\\",\[\\"$\\",\\"$L11\\",null,{\\"summary\\":\\"Example Output\\",\\"details\\":\\"\\\\n\`\`\`json\\\\n{\\\\n \\\\\\"sentiment\_analysis\\\\\\": {\\\\n \\\\\\"sentiment\\\\\\": \\\\\\"positive\\\\\\",\\\\n \\\\\\"confidence\_score\\\\\\": 0.84,\\\\n \\\\\\"key\_phrases\\\\\\": \[\\\\n {\\\\n \\\\\\"phrase\\\\\\": \\\\\\"absolutely love this product\\\\\\",\\\\n \\\\\\"sentiment\\\\\\": \\\\\\"positive\\\\\\"\\\\n },\\\\n {\\\\n \\\\\\"phrase\\\\\\": \\\\\\"quality exceeded my expectations\\\\\\",\\\\n \\\\\\"sentiment\\\\\\": \\\\\\"positive\\\\\\"\\\\n }\\\\n \],\\\\n \\\\\\"summary\\\\\\": \\\\\\"The reviewer loves the product's quality, but was slightly disappointed with the shipping time.\\\\\\"\\\\n }\\\\n}\\\\n\`\`\`\\\\n\\"}\],\\"\\\\n\\",\[\\"$\\",\\"br\\",null,{}\],\\"\\\\n\\",\[\\"$\\",\\"p\\",null,{\\"className\\":\\"text-sm my-3\\",\\"children\\":\[\\"$\\",\\"strong\\",null,{\\"children\\":\\"Response structure:\\"}\]}\],\\"\\\\n\\",\[\\"$\\",\\"ul\\",null,{\\"className\\":\\"list-disc my-1 text-sm\\",\\"children\\":\[\\"\\\\n\\",\[\\"$\\",\\"li\\",null,{\\"className\\":\\"ml-6 my-1.5 text-sm\\",\\"children\\":\[\[\\"$\\",\\"strong\\",null,{\\"children\\":\\"sentiment\\"}\],\\": Classification (positive/negative/neutral)\\"\]}\],\\"\\\\n\\",\[\\"$\\",\\"li\\",null,{\\"className\\":\\"ml-6 my-1.5 text-sm\\",\\"children\\":\[\[\\"$\\",\\"strong\\",null,{\\"children\\":\\"confidence\_score\\"}\],\\": Confidence level (0-1 scale)\\"\]}\],\\"\\\\n\\",\[\\"$\\",\\"li\\",null,{\\"className\\":\\"ml-6 my-1.5 text-sm\\",\\"children\\":\[\[\\"$\\",\\"strong\\",null,{\\"children\\":\\"key\_phrases\\"}\],\\": Extracted phrases with individual sentiment scores\\"\]}\],\\"\\\\n\\",\[\\"$\\",\\"li\\",null,{\\"className\\":\\"ml-6 my-1.5 text-sm\\",\\"children\\":\[\[\\"$\\",\\"strong\\",null,{\\"children\\":\\"summary\\"}\],\\": Analysis overview and main findings\\"\]}\],\\"\\\\n\\"\]}\]\],\[\[\\"$\\",\\"link\\",\\"0\\",{\\"rel\\":\\"stylesheet\\",\\"href\\":\\"/\_next/static/css/b1dbd2d25ec6d91f.css\\",\\"precedence\\":\\"next\\",\\"crossOrigin\\":\\"$undefined\\",\\"nonce\\":\\"$undefined\\"}\]\],\[\\"$\\",\\"$L26\\",null,{\\"children\\":\[\\"$L27\\",\\"$L28\\",null\]}\]\]}\],{},null,false\]},null,false\]},null,false\]},null,false\]},null,false\]},null,false\],\[\\"$\\",\\"$1\\",\\"h\\",{\\"children\\":\[null,\[\\"$\\",\\"$1\\",\\"ge7kQ725sXv2edWJUkleNv\\",{\\"children\\":\[\[\\"$\\",\\"$L29\\",null,{\\"children\\":\\"$L2a\\"}\],\[\\"$\\",\\"meta\\",null,{\\"name\\":\\"next-size-adjust\\",\\"content\\":\\"\\"}\]\]}\],\[\\"$\\",\\"$L2b\\",null,{\\"children\\":\\"$L2c\\"}\]\]}\],false\]\],\\"m\\":\\"$undefined\\",\\"G\\":\[\\"$2d\\",\[\]\],\\"s\\":false,\\"S\\":true}\\n"\])self.\_\_next\_f.push(\[1,"30:I\[95037,\[\\"8779\\",\\"static/chunks/8285d696-4c2af9547952b91b.js\\",\\"7487\\",\\"static/chunks/b3b06311-fa77c49096c4cc97.js\\",\\"7539\\",\\"static/chunks/1f447996-8974f1b7e13f2cb9.js\\",\\"8455\\",\\"static/chunks/d611311c-7b5735a4c92c90d9.js\\",\\"3596\\",\\"static/chunks/3596-81e8162c1dd9940f.js\\",\\"888\\",\\"static/chunks/888-7cd7f38e76441637.js\\",\\"1466\\",\\"static/chunks/1466-ba3c67344a908bbe.js\\",\\"1727\\",\\"static/chunks/1727-8cb7c763d81e3223.js\\",\\"7213\\",\\"static/chunks/7213-443f51519115da15.js\\",\\"7177\\",\\"static/chunks/app/layout-a8184e653bbd672b.js\\"\],\\"GoogleAnalytics\\"\]\\n31:I\[43717,\[\\"8779\\",\\"static/chunks/8285d696-4c2af9547952b91b.js\\",\\"7487\\",\\"static/chunks/b3b06311-fa77c49096c4cc97.js\\",\\"7539\\",\\"static/chunks/1f447996-8974f1b7e13f2cb9.js\\",\\"8455\\",\\"static/chunks/d611311c-7b5735a4c92c90d9.js\\",\\"3596\\",\\"static/chunks/3596-81e8162c1dd9940f.js\\",\\"888\\",\\"static/chunks/888-7cd7f38e76441637.js\\",\\"1466\\",\\"static/chunks/1466-ba3c67344a908bbe.js\\",\\"1727\\",\\"static/chunks/1727-8cb7c763d81e3223.js\\",\\"7213\\",\\"static/chunks/7213-443f51519115da15.js\\",\\"7177\\",\\"static/chunks/app/layout-a8184e653bbd672b.js\\"\],\\"GoogleTagManager\\"\]\\n32:I\[67986,\[\\"8779\\",\\"static/chunks/8285d696-4c2af9547952b91b.js\\",\\"7487\\",\\"static/chunks/b3b06311-fa77c49096c4cc97.js\\",\\"7539\\",\\"static/chunks/1f447996-8974f1b7e13f2cb9.js\\",\\"8455\\",\\"static/chunks/d611311c-7b5735a4c92c90d9.js\\",\\"3596\\",\\"static/chunks/3596-81e8162c1dd9940f.js\\",\\"888\\",\\"static/chunks/888-7cd7f38e76441637.js\\",\\"1466\\",\\"static/chunks/1466-ba3c67344a908bbe.js\\",\\"1727\\",\\"static/chunks/1727-8cb7c763d81e3223.js\\",\\"7213\\",\\"static/chunks/7213-443f51519115da15.js\\",\\"7177\\",\\"static/chunks/app/layout-a8184e653bbd672b.js\\"\],\\"SpeedInsights\\"\]\\n7:{}\\n2e:T12b5,"\])self.\_\_next\_f.push(\[1,"/\* For our datagrail consent banner \*/\\n/\* https://docs.datagrail.io/docs/consent/banner/css-customization/ \*/\\n\\n:host(.dg-consent-banner) {\\n /\* Fonts - matching Groq Console system \*/\\n --dg-primary-font: Inter, -apple-system, BlinkMacSystemFont, \\"Segoe UI\\",\\n Roboto, \\"Helvetica Neue\\", Arial, sans-serif;\\n --dg-secondary-font: Montserrat, -apple-system, BlinkMacSystemFont, \\"Segoe UI\\",\\n Roboto, \\"Helvetica Neue\\", Arial, sans-serif;\\n\\n /\* General banner styling \*/\\n --dg-consent-background-color: rgb(255, 255, 255);\\n --dg-consent-background-border: rgb(231, 229, 228);\\n --consent-border-radius: 12px;\\n\\n /\* Body text styling \*/\\n --dg-body-font-size: 14px;\\n --dg-body-font-weight: 400;\\n --dg-body-font-color: rgb(118, 111, 107);\\n --dg-body-line-height: 1.5;\\n\\n /\* Heading styling \*/\\n --dg-heading-font-size: 18px;\\n --dg-heading-font-weight: 600;\\n --dg-heading-font-color: rgb(12, 10, 9);\\n --dg-heading-line-height: 1.4;\\n\\n /\* Title styling \*/\\n --dg-title-font-size: 16px;\\n --dg-title-font-weight: 500;\\n --dg-title-font-color: rgb(30, 30, 30);\\n --dg-title-line-height: 1.4;\\n\\n /\* Button styling \*/\\n --dg-button-border: rgb(231, 229, 228) 1px solid;\\n --dg-button-primary-background: rgb(30, 30, 30);\\n --dg-button-primary-color: rgb(248, 248, 247);\\n --dg-button-secondary-background: rgb(243, 243, 242);\\n --dg-button-secondary-color: rgb(28, 25, 23);\\n\\n /\* Category styling \*/\\n --dg-policy-option-heading-size: 15px;\\n --dg-policy-option-heading-weight: 500;\\n --dg-policy-option-heading-color: rgb(30, 30, 30);\\n --dg-policy-option-heading-enabled-color: rgb(245, 80, 54);\\n --dg-policy-option-chevron-size: 16;\\n\\n /\* Category description \*/\\n --dg-policy-option-description-font-size: 13px;\\n --dg-policy-option-description-font-weight: 400;\\n --dg-policy-option-description-font-color: rgb(118, 111, 107);\\n\\n /\* Essential categories \*/\\n --dg-policy-option-essential-label-font-size: 12px;\\n --dg-policy-option-essential-label-font-weight: 500;\\n --dg-policy-option-essential-label-font-color: rgb(118, 111, 107);\\n\\n /\* Slider styling - inspired by switch component \*/\\n --dg-slider-primary: rgb(231, 229, 228);\\n --dg-slider-secondary: rgb(255, 255, 255);\\n\\n --dg-slider-enabled-primary: rgb(30, 30, 30);\\n --dg-slider-enabled-secondary: rgb(255, 255, 255);\\n\\n /\* For Enabled Categories \*/\\n --dg-policy-option-heading-enabled-color: rgb(245, 80, 54);\\n}\\n\\n:host(.dg-consent-banner) strong {\\n font-weight: 500;\\n}\\n\\n/\* Slider styling for checked enabled categories \*/\\n:host(.dg-consent-banner)\\n input\[type=\\"checkbox\\"\]:not(:disabled):checked\\n + label\\n .dg-slider {\\n background: rgb(30, 30, 30) !important;\\n}\\n\\n/\* Advanced button styling to match Groq Console \*/\\n:host(.dg-consent-banner) .dg-button {\\n border-radius: 8px !important;\\n padding: 8px 16px !important;\\n font-weight: 500 !important;\\n font-size: 14px !important;\\n transition: all 0.2s ease !important;\\n}\\n\\n:host(.dg-consent-banner) .dg-button.accept\_all,\\n:host(.dg-consent-banner) .dg-button.accept\_some,\\n:host(.dg-consent-banner) .dg-button.reject\_all,\\n:host(.dg-consent-banner) .dg-button.open\_layer,\\n:host(.dg-consent-banner) .dg-button.custom {\\n background: rgb(243, 243, 242) !important;\\n color: rgb(28, 25, 23) !important;\\n border: 1px solid rgb(231, 229, 228) !important;\\n}\\n\\n:host(.dg-consent-banner) .dg-button.accept\_all:hover,\\n:host(.dg-consent-banner) .dg-button.accept\_some:hover,\\n:host(.dg-consent-banner) .dg-button.reject\_all:hover,\\n:host(.dg-consent-banner) .dg-button.open\_layer:hover,\\n:host(.dg-consent-banner) .dg-button.custom:hover {\\n background: rgb(231, 229, 228) !important;\\n}\\n\\n/\* Link styling to match Groq Console \*/\\n:host(.dg-consent-banner) .dg-link {\\n color: rgb(245, 80, 54) !important;\\n text-decoration: none !important;\\n font-weight: 500 !important;\\n}\\n\\n:host(.dg-consent-banner) .dg-link:hover {\\n text-decoration: underline !important;\\n}\\n\\n:host(.dg-consent-banner) .dg-main-content-policy-option-description p {\\n margin-top: 0 !important;\\n margin-bottom: 16px;\\n}\\n\\n/\* Dark mode support \*/\\n:host(.dg-consent-banner) .dark {\\n --dg-consent-background-color: rgb(18, 20, 24);\\n --dg-consent-background-border: rgba(153, 153, 153, 0.161);\\n --dg-body-font-color: rgb(165, 160, 156);\\n --dg-heading-font-color: rgb(248, 248, 247);\\n --dg-title-font-color: rgb(248, 248, 247);\\n --dg-policy-option-heading-color: rgb(248, 248, 247);\\n --dg-button-secondary-background: rgb(38, 38, 38);\\n --dg-button-secondary-color: rgb(248, 248, 247);\\n --dg-slider-primary: rgba(153, 153, 153, 0.35);\\n --dg-slider-background: rgb(107, 114, 128);\\n}\\n\\n/\* Overall banner container styling \*/\\n:host(.dg-consent-banner) .dg-app {\\n box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -2px\\n rgba(0, 0, 0, 0.1) !important;\\n border: 1px solid rgb(231, 229, 228) !important;\\n}\\n"\])self.\_\_next\_f.push(\[1,"2:\[\\"$\\",\\"html\\",null,{\\"lang\\":\\"en\\",\\"className\\":\\"\_\_variable\_f367f3 \_\_variable\_dd5b2f\\",\\"suppressHydrationWarning\\":true,\\"children\\":\[\[\\"$\\",\\"head\\",null,{\\"children\\":\[\[\\"$\\",\\"style\\",null,{\\"id\\":\\"dg-consent-custom-style\\",\\"dangerouslySetInnerHTML\\":{\\"\_\_html\\":\\"$2e\\"}}\],\[\\"$\\",\\"link\\",null,{\\"rel\\":\\"icon\\",\\"href\\":\\"/favicon.ico?cache=rounded-bolt\\",\\"sizes\\":\\"32x32\\"}\]\]}\],\[\\"$\\",\\"script\\",null,{\\"async\\":true,\\"src\\":\\"/g.js\\"}\],\[\\"$\\",\\"script\\",null,{\\"async\\":true,\\"src\\":\\"https://js.stripe.com/v3/\\"}\],\[\\"$\\",\\"body\\",null,{\\"className\\":\\"font-inter\\",\\"children\\":\[\\"$L2f\\",\[\\"$\\",\\"$L30\\",null,{\\"gaId\\":\\"G-CQ9K0VPEEQ\\"}\],\[\\"$\\",\\"$L31\\",null,{\\"gtmId\\":\\"GTM-WWK828JN\\"}\],\[\\"$\\",\\"$L32\\",null,{\\"sampleRate\\":0.01}\]\]}\]\]}\]\\n"\])self.\_\_next\_f.push(\[1,"2a:\[\[\\"$\\",\\"meta\\",\\"0\\",{\\"charSet\\":\\"utf-8\\"}\],\[\\"$\\",\\"meta\\",\\"1\\",{\\"name\\":\\"viewport\\",\\"content\\":\\"width=device-width, initial-scale=1, maximum-scale=1\\"}\]\]\\n27:null\\n"\])self.\_\_next\_f.push(\[1,"28:null\\n2c:\[\[\\"$\\",\\"title\\",\\"0\\",{\\"children\\":\\"Structured Outputs - GroqDocs\\"}\],\[\\"$\\",\\"meta\\",\\"1\\",{\\"name\\":\\"description\\",\\"content\\":\\"Guarantee model responses strictly conform to your JSON schema for reliable, type-safe data structures.\\"}\],\[\\"$\\",\\"meta\\",\\"2\\",{\\"property\\":\\"og:title\\",\\"content\\":\\"Structured Outputs - GroqDocs\\"}\],\[\\"$\\",\\"meta\\",\\"3\\",{\\"property\\":\\"og:description\\",\\"content\\":\\"Guarantee model responses strictly conform to your JSON schema for reliable, type-safe data structures.\\"}\],\[\\"$\\",\\"meta\\",\\"4\\",{\\"property\\":\\"og:url\\",\\"content\\":\\"https://console.groq.com/docs\\"}\],\[\\"$\\",\\"meta\\",\\"5\\",{\\"property\\":\\"og:site\_name\\",\\"content\\":\\"GroqDocs\\"}\],\[\\"$\\",\\"meta\\",\\"6\\",{\\"property\\":\\"og:image\\",\\"content\\":\\"https://console.groq.com/og\_cloudv5.jpg\\"}\],\[\\"$\\",\\"meta\\",\\"7\\",{\\"property\\":\\"og:type\\",\\"content\\":\\"website\\"}\],\[\\"$\\",\\"meta\\",\\"8\\",{\\"name\\":\\"twitter:card\\",\\"content\\":\\"summary\_large\_image\\"}\],\[\\"$\\",\\"meta\\",\\"9\\",{\\"name\\":\\"twitter:title\\",\\"content\\":\\"Structured Outputs - GroqDocs\\"}\],\[\\"$\\",\\"meta\\",\\"10\\",{\\"name\\":\\"twitter:description\\",\\"content\\":\\"Guarantee model responses strictly conform to your JSON schema for reliable, type-safe data structures.\\"}\],\[\\"$\\",\\"meta\\",\\"11\\",{\\"name\\":\\"twitter:image\\",\\"content\\":\\"https://console.groq.com/og\_cloudv5.jpg\\"}\],\[\\"$\\",\\"link\\",\\"12\\",{\\"rel\\":\\"icon\\",\\"href\\":\\"/favicon.ico?cache=rounded-bolt\\",\\"sizes\\":\\"32x32\\"}\]\]\\n"\])self.\_\_next\_f.push(\[1,"33:I\[29135,\[\\"8779\\",\\"static/chunks/8285d696-4c2af9547952b91b.js\\",\\"3596\\",\\"static/chunks/3596-81e8162c1dd9940f.js\\",\\"9170\\",\\"static/chunks/9170-d2c224567d46ff41.js\\",\\"1874\\",\\"static/chunks/1874-1af85b5fe730b1d1.js\\",\\"5193\\",\\"static/chunks/5193-5a50519070c43274.js\\",\\"888\\",\\"static/chunks/888-7cd7f38e76441637.js\\",\\"1466\\",\\"static/chunks/1466-ba3c67344a908bbe.js\\",\\"1727\\",\\"static/chunks/1727-8cb7c763d81e3223.js\\",\\"4215\\",\\"static/chunks/4215-210105fc188a4582.js\\",\\"8285\\",\\"static/chunks/8285-cf692dbe291dd0a9.js\\",\\"5674\\",\\"static/chunks/5674-883f5bd3e8483206.js\\",\\"8256\\",\\"static/chunks/8256-7af1a3383dec9c4d.js\\",\\"5789\\",\\"static/chunks/5789-d4359a1055e0aacd.js\\",\\"7860\\",\\"static/chunks/7860-a6cd4bd13b0a2513.js\\",\\"4209\\",\\"static/chunks/4209-19ded76058a94842.js\\",\\"7001\\",\\"static/chunks/app/(console)/docs/layout-d061ddcc54588b7f.js\\"\],\\"default\\"\]\\n34:Tfb0,"\])self.\_\_next\_f.push(\[1,"{\\n \\"id\\": \\"chatcmpl-f51b2cd2-bef7-417e-964e-a08f0b513c22\\",\\n \\"object\\": \\"chat.completion\\",\\n \\"created\\": 1730241104,\\n \\"model\\": \\"openai/gpt-oss-20b\\",\\n \\"choices\\": \[\\n {\\n \\"index\\": 0,\\n \\"message\\": {\\n \\"role\\": \\"assistant\\",\\n \\"content\\": \\"Fast language models have gained significant attention in recent years due to their ability to process and generate human-like text quickly and efficiently. The importance of fast language models can be understood from their potential applications and benefits:\\\\n\\\\n1. \*\*Real-time Chatbots and Conversational Interfaces\*\*: Fast language models enable the development of chatbots and conversational interfaces that can respond promptly to user queries, making them more engaging and useful.\\\\n2. \*\*Sentiment Analysis and Opinion Mining\*\*: Fast language models can quickly analyze text data to identify sentiments, opinions, and emotions, allowing for improved customer service, market research, and opinion mining.\\\\n3. \*\*Language Translation and Localization\*\*: Fast language models can quickly translate text between languages, facilitating global communication and enabling businesses to reach a broader audience.\\\\n4. \*\*Text Summarization and Generation\*\*: Fast language models can summarize long documents or even generate new text on a given topic, improving information retrieval and processing efficiency.\\\\n5. \*\*Named Entity Recognition and Information Extraction\*\*: Fast language models can rapidly recognize and extract specific entities, such as names, locations, and organizations, from unstructured text data.\\\\n6. \*\*Recommendation Systems\*\*: Fast language models can analyze large amounts of text data to personalize product recommendations, improve customer experience, and increase sales.\\\\n7. \*\*Content Generation for Social Media\*\*: Fast language models can quickly generate engaging content for social media platforms, helping businesses maintain a consistent online presence and increasing their online visibility.\\\\n8. \*\*Sentiment Analysis for Stock Market Analysis\*\*: Fast language models can quickly analyze social media posts, news articles, and other text data to identify sentiment trends, enabling financial analysts to make more informed investment decisions.\\\\n9. \*\*Language Learning and Education\*\*: Fast language models can provide instant feedback and adaptive language learning, making language education more effective and engaging.\\\\n10. \*\*Domain-Specific Knowledge Extraction\*\*: Fast language models can quickly extract relevant information from vast amounts of text data, enabling domain experts to focus on high-level decision-making rather than manual information gathering.\\\\n\\\\nThe benefits of fast language models include:\\\\n\\\\n\* \*\*Increased Efficiency\*\*: Fast language models can process large amounts of text data quickly, reducing the time and effort required for tasks such as sentiment analysis, entity recognition, and text summarization.\\\\n\* \*\*Improved Accuracy\*\*: Fast language models can analyze and learn from large datasets, leading to more accurate results and more informed decision-making.\\\\n\* \*\*Enhanced User Experience\*\*: Fast language models can enable real-time interactions, personalized recommendations, and timely responses, improving the overall user experience.\\\\n\* \*\*Cost Savings\*\*: Fast language models can automate many tasks, reducing the need for manual labor and minimizing costs associated with data processing and analysis.\\\\n\\\\nIn summary, fast language models have the potential to transform various industries and applications by providing fast, accurate, and efficient language processing capabilities.\\"\\n },\\n \\"logprobs\\": null,\\n \\"finish\_reason\\": \\"stop\\"\\n }\\n \],\\n \\"usage\\": {\\n \\"queue\_time\\": 0.037493756,\\n \\"prompt\_tokens\\": 18,\\n \\"prompt\_time\\": 0.000680594,\\n \\"completion\_tokens\\": 556,\\n \\"completion\_time\\": 0.463333333,\\n \\"total\_tokens\\": 574,\\n \\"total\_time\\": 0.464013927\\n },\\n \\"system\_fingerprint\\": \\"fp\_179b0f92c9\\",\\n \\"x\_groq\\": { \\"id\\": \\"req\_01jbd6g2qdfw2adyrt2az8hz4w\\" }\\n}\\n"\])self.\_\_next\_f.push(\[1,"35:T699,{\\n \\"object\\": \\"list\\",\\n \\"data\\": \[\\n {\\n \\"id\\": \\"gemma2-9b-it\\",\\n \\"object\\": \\"model\\",\\n \\"created\\": 1693721698,\\n \\"owned\_by\\": \\"Google\\",\\n \\"active\\": true,\\n \\"context\_window\\": 8192,\\n \\"public\_apps\\": null\\n },\\n {\\n \\"id\\": \\"llama3-8b-8192\\",\\n \\"object\\": \\"model\\",\\n \\"created\\": 1693721698,\\n \\"owned\_by\\": \\"Meta\\",\\n \\"active\\": true,\\n \\"context\_window\\": 8192,\\n \\"public\_apps\\": null\\n },\\n {\\n \\"id\\": \\"llama3-70b-8192\\",\\n \\"object\\": \\"model\\",\\n \\"created\\": 1693721698,\\n \\"owned\_by\\": \\"Meta\\",\\n \\"active\\": true,\\n \\"context\_window\\": 8192,\\n \\"public\_apps\\": null\\n },\\n {\\n \\"id\\": \\"whisper-large-v3-turbo\\",\\n \\"object\\": \\"model\\",\\n \\"created\\": 1728413088,\\n \\"owned\_by\\": \\"OpenAI\\",\\n \\"active\\": true,\\n \\"context\_window\\": 448,\\n \\"public\_apps\\": null\\n },\\n {\\n \\"id\\": \\"whisper-large-v3\\",\\n \\"object\\": \\"model\\",\\n \\"created\\": 1693721698,\\n \\"owned\_by\\": \\"OpenAI\\",\\n \\"active\\": true,\\n \\"context\_window\\": 448,\\n \\"public\_apps\\": null\\n },\\n {\\n \\"id\\": \\"llama-guard-3-8b\\",\\n \\"object\\": \\"model\\",\\n \\"created\\": 1693721698,\\n \\"owned\_by\\": \\"Meta\\",\\n \\"active\\": true,\\n \\"context\_window\\": 8192,\\n \\"public\_apps\\": null\\n },\\n {\\n \\"id\\": \\"distil-whisper-large-v3-en\\",\\n \\"object\\": \\"model\\",\\n \\"created\\": 1693721698,\\n \\"owned\_by\\": \\"Hugging Face\\",\\n \\"active\\": true,\\n \\"context\_window\\": 448,\\n \\"public\_apps\\": null\\n },\\n {\\n \\"id\\": \\"llama-3.1-8b-instant\\",\\n \\"object\\": \\"model\\",\\n \\"created\\": 1693721698,\\n \\"owned\_by\\": \\"Meta\\",\\n \\"active\\": true,\\n \\"context\_window\\": 131072,\\n \\"public\_apps\\": null\\n }\\n \]\\n}\\n36:T5c5,{\\n \\"id\\": \\"resp\_01k1x6w9ane6d8rfxm05cb45yk\\",\\n \\"object\\": \\"response\\",\\n \\"status\\": \\"completed\\",\\n \\"created\_at\\": 1754400695,\\n \\"output\\": \[\\n {\\n \\"type\\": \\"message\\",\\n \\"id\\": \\"msg\_01k1x6w9ane6eb0650crhawwyy\\",\\n \\"status\\": \\"completed\\",\\n \\"role\\": \\"assistant\\",\\n \\"content\\": \[\\n {\\n \\"type\\": \\"output\_text\\",\\n \\"t"\])self.\_\_next\_f.push(\[1,"ext\\": \\"When the stars blinked awake, Luna the unicorn curled her mane and whispered wishes to the sleeping pine trees. She galloped through a field of moonlit daisies, gathering dew like tiny silver pearls. With a gentle sigh, she tucked her hooves beneath a silver cloud so the world slept softly, dreaming of her gentle hooves until the morning.\\",\\n \\"annotations\\": \[\]\\n }\\n \]\\n }\\n \],\\n \\"previous\_response\_id\\": null,\\n \\"model\\": \\"llama-3.3-70b-versatile\\",\\n \\"reasoning\\": {\\n \\"effort\\": null,\\n \\"summary\\": null\\n },\\n \\"max\_output\_tokens\\": null,\\n \\"instructions\\": null,\\n \\"text\\": {\\n \\"format\\": {\\n \\"type\\": \\"text\\"\\n }\\n },\\n \\"tools\\": \[\],\\n \\"tool\_choice\\": \\"auto\\",\\n \\"truncation\\": \\"disabled\\",\\n \\"metadata\\": {},\\n \\"temperature\\": 1,\\n \\"top\_p\\": 1,\\n \\"user\\": null,\\n \\"service\_tier\\": \\"default\\",\\n \\"error\\": null,\\n \\"incomplete\_details\\": null,\\n \\"usage\\": {\\n \\"input\_tokens\\": 82,\\n \\"input\_tokens\_details\\": {\\n \\"cached\_tokens\\": 0\\n },\\n \\"output\_tokens\\": 266,\\n \\"output\_tokens\_details\\": {\\n \\"reasoning\_tokens\\": 0\\n },\\n \\"total\_tokens\\": 348\\n },\\n \\"parallel\_tool\_calls\\": true,\\n \\"store\\": false\\n}\\n"\])self.\_\_next\_f.push(\[1,"8:\[\\"$\\",\\"$L33\\",null,{\\"openapiSpec\\":{\\"components\\":{\\"schemas\\":{\\"Annotation\\":{\\"description\\":\\"An annotation that provides citations or references for content in a message.\\",\\"properties\\":{\\"document\_citation\\":{\\"$ref\\":\\"#/components/schemas/DocumentCitation\\"},\\"function\_citation\\":{\\"$ref\\":\\"#/components/schemas/FunctionCitation\\"},\\"type\\":{\\"description\\":\\"The type of annotation.\\",\\"enum\\":\[\\"document\_citation\\",\\"function\_citation\\"\],\\"type\\":\\"string\\"}},\\"required\\":\[\\"type\\"\],\\"type\\":\\"object\\"},\\"Batch\\":{\\"properties\\":{\\"cancelled\_at\\":{\\"description\\":\\"The Unix timestamp (in seconds) for when the batch was cancelled.\\",\\"type\\":\\"integer\\"},\\"cancelling\_at\\":{\\"description\\":\\"The Unix timestamp (in seconds) for when the batch started cancelling.\\",\\"type\\":\\"integer\\"},\\"completed\_at\\":{\\"description\\":\\"The Unix timestamp (in seconds) for when the batch was completed.\\",\\"type\\":\\"integer\\"},\\"completion\_window\\":{\\"description\\":\\"The time frame within which the batch should be processed.\\",\\"type\\":\\"string\\"},\\"created\_at\\":{\\"description\\":\\"The Unix timestamp (in seconds) for when the batch was created.\\",\\"type\\":\\"integer\\"},\\"endpoint\\":{\\"description\\":\\"The API endpoint used by the batch.\\",\\"type\\":\\"string\\"},\\"error\_file\_id\\":{\\"description\\":\\"The ID of the file containing the outputs of requests with errors.\\",\\"type\\":\\"string\\"},\\"errors\\":{\\"properties\\":{\\"data\\":{\\"items\\":{\\"properties\\":{\\"code\\":{\\"description\\":\\"An error code identifying the error type.\\",\\"type\\":\\"string\\"},\\"line\\":{\\"description\\":\\"The line number of the input file where the error occurred, if applicable.\\",\\"nullable\\":true,\\"type\\":\\"integer\\"},\\"message\\":{\\"description\\":\\"A human-readable message providing more details about the error.\\",\\"type\\":\\"string\\"},\\"param\\":{\\"description\\":\\"The name of the parameter that caused the error, if applicable.\\",\\"nullable\\":true,\\"type\\":\\"string\\"}},\\"type\\":\\"object\\"},\\"type\\":\\"array\\"},\\"object\\":{\\"description\\":\\"The object type, which is always \`list\`.\\",\\"type\\":\\"string\\"}},\\"type\\":\\"object\\"},\\"expired\_at\\":{\\"description\\":\\"The Unix timestamp (in seconds) for when the batch expired.\\",\\"type\\":\\"integer\\"},\\"expires\_at\\":{\\"description\\":\\"The Unix timestamp (in seconds) for when the batch will expire.\\",\\"type\\":\\"integer\\"},\\"failed\_at\\":{\\"description\\":\\"The Unix timestamp (in seconds) for when the batch failed.\\",\\"type\\":\\"integer\\"},\\"finalizing\_at\\":{\\"description\\":\\"The Unix timestamp (in seconds) for when the batch started finalizing.\\",\\"type\\":\\"integer\\"},\\"id\\":{\\"type\\":\\"string\\"},\\"in\_progress\_at\\":{\\"description\\":\\"The Unix timestamp (in seconds) for when the batch started processing.\\",\\"type\\":\\"integer\\"},\\"input\_file\_id\\":{\\"description\\":\\"The ID of the input file for the batch.\\",\\"type\\":\\"string\\"},\\"metadata\\":{\\"description\\":\\"Set of key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format.\\\\n\\",\\"nullable\\":true,\\"type\\":\\"object\\"},\\"object\\":{\\"description\\":\\"The object type, which is always \`batch\`.\\",\\"enum\\":\[\\"batch\\"\],\\"type\\":\\"string\\",\\"x-stainless-const\\":true},\\"output\_file\_id\\":{\\"description\\":\\"The ID of the file containing the outputs of successfully executed requests.\\",\\"type\\":\\"string\\"},\\"request\_counts\\":{\\"description\\":\\"The request counts for different statuses within the batch.\\",\\"properties\\":{\\"completed\\":{\\"description\\":\\"Number of requests that have been completed successfully.\\",\\"type\\":\\"integer\\"},\\"failed\\":{\\"description\\":\\"Number of requests that have failed.\\",\\"type\\":\\"integer\\"},\\"total\\":{\\"description\\":\\"Total number of requests in the batch.\\",\\"type\\":\\"integer\\"}},\\"required\\":\[\\"total\\",\\"completed\\",\\"failed\\"\],\\"type\\":\\"object\\"},\\"status\\":{\\"description\\":\\"The current status of the batch.\\",\\"enum\\":\[\\"validating\\",\\"failed\\",\\"in\_progress\\",\\"finalizing\\",\\"completed\\",\\"expired\\",\\"cancelling\\",\\"cancelled\\"\],\\"type\\":\\"string\\"}},\\"required\\":\[\\"id\\",\\"object\\",\\"endpoint\\",\\"input\_file\_id\\",\\"completion\_window\\",\\"status\\",\\"created\_at\\"\],\\"type\\":\\"object\\"},\\"BatchRequestInput\\":{\\"description\\":\\"The per-line object of the batch input file\\",\\"properties\\":{\\"custom\_id\\":{\\"description\\":\\"A developer-provided per-request id that will be used to match outputs to inputs. Must be unique for each request in a batch.\\",\\"type\\":\\"string\\"},\\"method\\":{\\"description\\":\\"The HTTP method to be used for the request. Currently only \`POST\` is supported.\\",\\"enum\\":\[\\"POST\\"\],\\"type\\":\\"string\\",\\"x-stainless-const\\":true},\\"url\\":{\\"description\\":\\"The OpenAI API relative URL to be used for the request. Currently \`/v1/chat/completions\` is supported.\\",\\"type\\":\\"string\\"}},\\"type\\":\\"object\\"},\\"BatchRequestOutput\\":{\\"description\\":\\"The per-line object of the batch output and error files\\",\\"properties\\":{\\"custom\_id\\":{\\"description\\":\\"A developer-provided per-request id that will be used to match outputs to inputs.\\",\\"type\\":\\"string\\"},\\"error\\":{\\"description\\":\\"For requests that failed with a non-HTTP error, this will contain more information on the cause of the failure.\\",\\"nullable\\":true,\\"properties\\":{\\"code\\":{\\"description\\":\\"A machine-readable error code.\\",\\"type\\":\\"string\\"},\\"message\\":{\\"description\\":\\"A human-readable error message.\\",\\"type\\":\\"string\\"}},\\"type\\":\\"object\\"},\\"id\\":{\\"type\\":\\"string\\"},\\"response\\":{\\"nullable\\":true,\\"properties\\":{\\"body\\":{\\"description\\":\\"The JSON body of the response\\",\\"type\\":\\"object\\"},\\"request\_id\\":{\\"description\\":\\"An unique identifier for the OpenAI API request. Please include this request ID when contacting support.\\",\\"type\\":\\"string\\"},\\"status\_code\\":{\\"description\\":\\"The HTTP status code of the response\\",\\"type\\":\\"integer\\"}},\\"type\\":\\"object\\"}},\\"type\\":\\"object\\"},\\"BrowserResult\\":{\\"additionalProperties\\":false,\\"properties\\":{\\"content\\":{\\"description\\":\\"The content of the browser result\\",\\"type\\":\\"string\\"},\\"live\_view\_url\\":{\\"description\\":\\"The live view URL for the browser window\\",\\"type\\":\\"string\\"},\\"title\\":{\\"description\\":\\"The title of the browser window\\",\\"type\\":\\"string\\"},\\"url\\":{\\"description\\":\\"The URL of the browser window\\",\\"type\\":\\"string\\"}},\\"required\\":\[\\"url\\",\\"title\\"\],\\"type\\":\\"object\\"},\\"Chart\\":{\\"properties\\":{\\"elements\\":{\\"description\\":\\"The chart elements (data series, points, etc.)\\",\\"items\\":{\\"$ref\\":\\"#/components/schemas/ChartElement\\"},\\"type\\":\\"array\\"},\\"title\\":{\\"description\\":\\"The title of the chart\\",\\"type\\":\\"string\\"},\\"type\\":{\\"description\\":\\"The type of chart\\",\\"enum\\":\[\\"bar\\",\\"box\_and\_whisker\\",\\"line\\",\\"pie\\",\\"scatter\\",\\"superchart\\",\\"unknown\\"\],\\"type\\":\\"string\\"},\\"x\_label\\":{\\"description\\":\\"The label for the x-axis\\",\\"type\\":\\"string\\"},\\"x\_scale\\":{\\"description\\":\\"The scale type for the x-axis\\",\\"type\\":\\"string\\"},\\"x\_tick\_labels\\":{\\"description\\":\\"The labels for the x-axis ticks\\",\\"items\\":{\\"type\\":\\"string\\"},\\"type\\":\\"array\\"},\\"x\_ticks\\":{\\"description\\":\\"The tick values for the x-axis\\",\\"items\\":{\\"type\\":\\"number\\"},\\"type\\":\\"array\\"},\\"x\_unit\\":{\\"description\\":\\"The unit for the x-axis\\",\\"type\\":\\"string\\"},\\"y\_label\\":{\\"description\\":\\"The label for the y-axis\\",\\"type\\":\\"string\\"},\\"y\_scale\\":{\\"description\\":\\"The scale type for the y-axis\\",\\"type\\":\\"string\\"},\\"y\_tick\_labels\\":{\\"description\\":\\"The labels for the y-axis ticks\\",\\"items\\":{\\"type\\":\\"string\\"},\\"type\\":\\"array\\"},\\"y\_ticks\\":{\\"description\\":\\"The tick values for the y-axis\\",\\"items\\":{\\"type\\":\\"number\\"},\\"type\\":\\"array\\"},\\"y\_unit\\":{\\"description\\":\\"The unit for the y-axis\\",\\"type\\":\\"string\\"}},\\"required\\":\[\\"type\\",\\"elements\\"\],\\"type\\":\\"object\\"},\\"ChartElement\\":{\\"properties\\":{\\"angle\\":{\\"description\\":\\"The angle for this element\\",\\"type\\":\\"number\\"},\\"first\_quartile\\":{\\"description\\":\\"The first quartile value for this element\\",\\"type\\":\\"number\\"},\\"group\\":{\\"description\\":\\"The group this element belongs to\\",\\"type\\":\\"string\\"},\\"label\\":{\\"description\\":\\"The label for this chart element\\",\\"type\\":\\"string\\"},\\"max\\":{\\"type\\":\\"number\\"},\\"median\\":{\\"description\\":\\"The median value for this element\\",\\"type\\":\\"number\\"},\\"min\\":{\\"description\\":\\"The minimum value for this element\\",\\"type\\":\\"number\\"},\\"outliers\\":{\\"description\\":\\"The outliers for this element\\",\\"items\\":{\\"type\\":\\"number\\"},\\"type\\":\\"array\\"},\\"points\\":{\\"description\\":\\"The points for this element\\",\\"items\\":{\\"items\\":{\\"type\\":\\"number\\"},\\"type\\":\\"array\\"},\\"type\\":\\"array\\"},\\"radius\\":{\\"description\\":\\"The radius for this element\\",\\"type\\":\\"number\\"},\\"third\_quartile\\":{\\"description\\":\\"The third quartile value for this element\\",\\"type\\":\\"number\\"},\\"value\\":{\\"description\\":\\"The value for this element\\",\\"type\\":\\"number\\"}},\\"required\\":\[\\"label\\"\],\\"type\\":\\"object\\"},\\"ChatCompletionDocument\\":{\\"additionalProperties\\":false,\\"description\\":\\"A document that can be referenced by the model while generating responses.\\",\\"properties\\":{\\"id\\":{\\"description\\":\\"Optional unique identifier that can be used for citations in responses.\\",\\"nullable\\":true,\\"type\\":\\"string\\"},\\"source\\":{\\"$ref\\":\\"#/components/schemas/ChatCompletionDocumentSource\\"}},\\"required\\":\[\\"source\\"\],\\"title\\":\\"Document\\",\\"type\\":\\"object\\"},\\"ChatCompletionDocumentSource\\":{\\"description\\":\\"The source of the document. Only text and JSON sources are currently supported.\\",\\"discriminator\\":{\\"mapping\\":{\\"json\\":\\"#/components/schemas/ChatCompletionDocumentSourceJSON\\",\\"text\\":\\"#/components/schemas/ChatCompletionDocumentSourceText\\"},\\"propertyName\\":\\"type\\"},\\"oneOf\\":\[{\\"$ref\\":\\"#/components/schemas/ChatCompletionDocumentSourceText\\"},{\\"$ref\\":\\"#/components/schemas/ChatCompletionDocumentSourceJSON\\"}\],\\"title\\":\\"Document source\\"},\\"ChatCompletionDocumentSourceJSON\\":{\\"additionalProperties\\":false,\\"description\\":\\"A document whose contents are provided inline as JSON data.\\",\\"properties\\":{\\"data\\":{\\"additionalProperties\\":true,\\"description\\":\\"The JSON payload associated with the document.\\",\\"type\\":\\"object\\"},\\"type\\":{\\"description\\":\\"Identifies this document source as JSON data.\\",\\"enum\\":\[\\"json\\"\],\\"type\\":\\"string\\"}},\\"required\\":\[\\"type\\",\\"data\\"\],\\"title\\":\\"JSON document source\\",\\"type\\":\\"object\\"},\\"ChatCompletionDocumentSourceText\\":{\\"additionalProperties\\":false,\\"description\\":\\"A document whose contents are provided inline as text.\\",\\"properties\\":{\\"text\\":{\\"description\\":\\"The document contents.\\",\\"type\\":\\"string\\"},\\"type\\":{\\"description\\":\\"Identifies this document source as inline text.\\",\\"enum\\":\[\\"text\\"\],\\"type\\":\\"string\\"}},\\"required\\":\[\\"type\\",\\"text\\"\],\\"title\\":\\"Text document source\\",\\"type\\":\\"object\\"},\\"ChatCompletionFunctionCallOption\\":{\\"description\\":\\"Specifying a particular function via \`{\\\\\\"name\\\\\\": \\\\\\"my\_function\\\\\\"}\` forces the model to call that function.\\\\n\\",\\"properties\\":{\\"name\\":{\\"description\\":\\"The name of the function to call.\\",\\"type\\":\\"string\\"}},\\"required\\":\[\\"name\\"\],\\"type\\":\\"object\\"},\\"ChatCompletionFunctions\\":{\\"deprecated\\":true,\\"properties\\":{\\"description\\":{\\"description\\":\\"A description of what the function does, used by the model to choose when and how to call the function.\\",\\"type\\":\\"string\\"},\\"name\\":{\\"description\\":\\"The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.\\",\\"type\\":\\"string\\"},\\"parameters\\":{\\"$ref\\":\\"#/components/schemas/FunctionParameters\\"}},\\"required\\":\[\\"name\\"\],\\"type\\":\\"object\\"},\\"ChatCompletionMessageExecutedTools\\":{\\"description\\":\\"A list of tools that were executed during the chat completion for compound AI systems.\\",\\"items\\":{\\"properties\\":{\\"arguments\\":{\\"description\\":\\"The arguments passed to the tool in JSON format.\\",\\"type\\":\\"string\\"},\\"browser\_results\\":{\\"description\\":\\"Array of browser results\\",\\"items\\":{\\"$ref\\":\\"#/components/schemas/BrowserResult\\"},\\"type\\":\\"array\\"},\\"code\_results\\":{\\"description\\":\\"Array of code execution results\\",\\"items\\":{\\"$ref\\":\\"#/components/schemas/CodeExecutionResult\\"},\\"type\\":\\"array\\"},\\"index\\":{\\"description\\":\\"The index of the executed tool.\\",\\"type\\":\\"integer\\"},\\"output\\":{\\"description\\":\\"The output returned by the tool.\\",\\"nullable\\":true,\\"type\\":\\"string\\"},\\"search\_results\\":{\\"description\\":\\"The search results returned by the tool, if applicable.\\",\\"nullable\\":true,\\"properties\\":{\\"images\\":{\\"description\\":\\"List of image URLs returned by the search\\",\\"items\\":{\\"type\\":\\"string\\"},\\"type\\":\\"array\\"},\\"results\\":{\\"description\\":\\"List of search results\\",\\"items\\":{\\"properties\\":{\\"content\\":{\\"description\\":\\"The content of the search result\\",\\"type\\":\\"string\\"},\\"score\\":{\\"description\\":\\"The relevance score of the search result\\",\\"format\\":\\"float\\",\\"type\\":\\"number\\"},\\"title\\":{\\"description\\":\\"The title of the search result\\",\\"type\\":\\"string\\"},\\"url\\":{\\"description\\":\\"The URL of the search result\\",\\"type\\":\\"string\\"}},\\"type\\":\\"object\\"},\\"type\\":\\"array\\"}},\\"type\\":\\"object\\"},\\"type\\":{\\"description\\":\\"The type of tool that was executed.\\",\\"type\\":\\"string\\"}},\\"required\\":\[\\"index\\",\\"type\\",\\"arguments\\"\],\\"type\\":\\"object\\"},\\"type\\":\\"array\\"},\\"ChatCompletionMessageToolCall\\":{\\"properties\\":{\\"function\\":{\\"description\\":\\"The function that the model called.\\",\\"properties\\":{\\"arguments\\":{\\"description\\":\\"The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.\\",\\"type\\":\\"string\\"},\\"name\\":{\\"description\\":\\"The name of the function to call.\\",\\"type\\":\\"string\\"}},\\"required\\":\[\\"name\\",\\"arguments\\"\],\\"type\\":\\"object\\"},\\"id\\":{\\"description\\":\\"The ID of the tool call.\\",\\"type\\":\\"string\\"},\\"type\\":{\\"description\\":\\"The type of the tool. Currently, only \`function\` is supported.\\",\\"enum\\":\[\\"function\\"\],\\"type\\":\\"string\\"}},\\"required\\":\[\\"id\\",\\"type\\",\\"function\\"\],\\"type\\":\\"object\\"},\\"ChatCompletionMessageToolCallChunk\\":{\\"properties\\":{\\"function\\":{\\"properties\\":{\\"arguments\\":{\\"description\\":\\"The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.\\",\\"type\\":\\"string\\"},\\"name\\":{\\"description\\":\\"The name of the function to call.\\",\\"type\\":\\"string\\"}},\\"type\\":\\"object\\"},\\"id\\":{\\"description\\":\\"The ID of the tool call.\\",\\"type\\":\\"string\\"},\\"index\\":{\\"type\\":\\"integer\\"},\\"type\\":{\\"description\\":\\"The type of the tool. Currently, only \`function\` is supported.\\",\\"enum\\":\[\\"function\\"\],\\"type\\":\\"string\\"}},\\"required\\":\[\\"index\\"\],\\"type\\":\\"object\\"},\\"ChatCompletionMessageToolCalls\\":{\\"description\\":\\"The tool calls generated by the model, such as function calls.\\",\\"items\\":{\\"$ref\\":\\"#/components/schemas/ChatCompletionMessageToolCall\\"},\\"type\\":\\"array\\"},\\"ChatCompletionNamedToolChoice\\":{\\"description\\":\\"Specifies a tool the model should use. Use to force the model to call a specific function.\\",\\"properties\\":{\\"function\\":{\\"properties\\":{\\"name\\":{\\"description\\":\\"The name of the function to call.\\",\\"type\\":\\"string\\"}},\\"required\\":\[\\"name\\"\],\\"type\\":\\"object\\"},\\"type\\":{\\"description\\":\\"The type of the tool. Currently, only \`function\` is supported.\\",\\"enum\\":\[\\"function\\"\],\\"type\\":\\"string\\"}},\\"required\\":\[\\"type\\",\\"function\\"\],\\"type\\":\\"object\\"},\\"ChatCompletionRequestAssistantMessage\\":{\\"additionalProperties\\":false,\\"properties\\":{\\"content\\":{\\"description\\":\\"The contents of the assistant message. Required unless \`tool\_calls\` or \`function\_call\` is specified.\\\\n\\",\\"nullable\\":true,\\"oneOf\\":\[{\\"description\\":\\"The text contents of the message.\\",\\"title\\":\\"Text content\\",\\"type\\":\\"string\\"},{\\"description\\":\\"An array of content parts with a defined type, only \`text\` is supported for this message type.\\",\\"items\\":{\\"$ref\\":\\"#/components/schemas/ChatCompletionRequestMessageContentPartText\\"},\\"title\\":\\"Array of content parts\\",\\"type\\":\\"array\\"}\],\\"title\\":\\"Assistant message content\\"},\\"function\_call\\":{\\"deprecated\\":true,\\"description\\":\\"Deprecated and replaced by \`tool\_calls\`. The name and arguments of a function that should be called, as generated by the model.\\",\\"properties\\":{\\"arguments\\":{\\"description\\":\\"The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.\\",\\"type\\":\\"string\\"},\\"name\\":{\\"description\\":\\"The name of the function to call.\\",\\"type\\":\\"string\\"}},\\"type\\":\\"object\\"},\\"name\\":{\\"description\\":\\"An optional name for the participant. Provides the model information to differentiate between participants of the same role.\\",\\"type\\":\\"string\\"},\\"reasoning\\":{\\"description\\":\\"The reasoning output by the assistant if reasoning\_format was set to 'parsed'.\\\\nThis field is only useable with qwen3 models.\\\\n\\",\\"nullable\\":true,\\"type\\":\\"string\\"},\\"role\\":{\\"description\\":\\"The role of the messages author, in this case \`assistant\`.\\",\\"enum\\":\[\\"assistant\\"\],\\"type\\":\\"string\\"},\\"tool\_call\_id\\":{\\"description\\":\\"DO NOT USE. This field is present because OpenAI allows it and users send it.\\",\\"nullable\\":true,\\"required\\":\[\\"arguments\\",\\"name\\"\],\\"type\\":\\"string\\",\\"x-groq-meta\\":{\\"hidden\\":true}},\\"tool\_calls\\":{\\"$ref\\":\\"#/components/schemas/ChatCompletionMessageToolCalls\\"}},\\"required\\":\[\\"role\\"\],\\"title\\":\\"Assistant message\\",\\"type\\":\\"object\\"},\\"ChatCompletionRequestFunctionMessage\\":{\\"additionalProperties\\":false,\\"deprecated\\":true,\\"properties\\":{\\"content\\":{\\"description\\":\\"The contents of the function message.\\",\\"nullable\\":true,\\"title\\":\\"Function message content\\",\\"type\\":\\"string\\"},\\"name\\":{\\"description\\":\\"The name of the function to call.\\",\\"type\\":\\"string\\"},\\"role\\":{\\"description\\":\\"The role of the messages author, in this case \`function\`.\\",\\"enum\\":\[\\"function\\"\],\\"type\\":\\"string\\"},\\"tool\_call\_id\\":{\\"description\\":\\"DO NOT USE. This field is present because OpenAI allows it and users send it.\\",\\"nullable\\":true,\\"type\\":\\"string\\",\\"x-groq-meta\\":{\\"hidden\\":true}}},\\"required\\":\[\\"role\\",\\"content\\",\\"name\\"\],\\"title\\":\\"Function message\\",\\"type\\":\\"object\\"},\\"ChatCompletionRequestMessage\\":{\\"discriminator\\":{\\"mapping\\":{\\"assistant\\":\\"#/components/schemas/ChatCompletionRequestAssistantMessage\\",\\"developer\\":\\"#/components/schemas/ChatCompletionRequestSystemMessage\\",\\"function\\":\\"#/components/schemas/ChatCompletionRequestFunctionMessage\\",\\"system\\":\\"#/components/schemas/ChatCompletionRequestSystemMessage\\",\\"tool\\":\\"#/components/schemas/ChatCompletionRequestToolMessage\\",\\"user\\":\\"#/components/schemas/ChatCompletionRequestUserMessage\\"},\\"propertyName\\":\\"role\\"},\\"oneOf\\":\[{\\"$ref\\":\\"#/components/schemas/ChatCompletionRequestSystemMessage\\"},{\\"$ref\\":\\"#/components/schemas/ChatCompletionRequestUserMessage\\"},{\\"$ref\\":\\"#/components/schemas/ChatCompletionRequestAssistantMessage\\"},{\\"$ref\\":\\"#/components/schemas/ChatCompletionRequestToolMessage\\"},{\\"$ref\\":\\"#/components/schemas/ChatCompletionRequestFunctionMessage\\"}\]},\\"ChatCompletionRequestMessageContentPart\\":{\\"oneOf\\":\[{\\"$ref\\":\\"#/components/schemas/ChatCompletionRequestMessageContentPartText\\"},{\\"$ref\\":\\"#/components/schemas/ChatCompletionRequestMessageContentPartImage\\"}\]},\\"ChatCompletionRequestMessageContentPartImage\\":{\\"properties\\":{\\"image\_url\\":{\\"properties\\":{\\"detail\\":{\\"default\\":\\"auto\\",\\"description\\":\\"Specifies the detail level of the image.\\",\\"enum\\":\[\\"auto\\",\\"low\\",\\"high\\"\],\\"type\\":\\"string\\"},\\"url\\":{\\"description\\":\\"Either a URL of the image or the base64 encoded image data.\\",\\"format\\":\\"uri\\",\\"type\\":\\"string\\"}},\\"required\\":\[\\"url\\"\],\\"type\\":\\"object\\"},\\"type\\":{\\"description\\":\\"The type of the content part.\\",\\"enum\\":\[\\"image\_url\\"\],\\"type\\":\\"string\\"}},\\"required\\":\[\\"type\\",\\"image\_url\\"\],\\"title\\":\\"Image content part\\",\\"type\\":\\"object\\"},\\"ChatCompletionRequestMessageContentPartText\\":{\\"properties\\":{\\"text\\":{\\"description\\":\\"The text content.\\",\\"type\\":\\"string\\"},\\"type\\":{\\"description\\":\\"The type of the content part.\\",\\"enum\\":\[\\"text\\"\],\\"type\\":\\"string\\"}},\\"required\\":\[\\"type\\",\\"text\\"\],\\"title\\":\\"Text content part\\",\\"type\\":\\"object\\"},\\"ChatCompletionRequestSystemMessage\\":{\\"additionalProperties\\":false,\\"properties\\":{\\"content\\":{\\"description\\":\\"The contents of the system message.\\",\\"oneOf\\":\[{\\"description\\":\\"The text contents of the message.\\",\\"title\\":\\"Text content\\",\\"type\\":\\"string\\"},{\\"description\\":\\"An array of content parts with a defined type, only \`text\` is supported for this message type.\\",\\"items\\":{\\"$ref\\":\\"#/components/schemas/ChatCompletionRequestMessageContentPartText\\"},\\"minItems\\":1,\\"title\\":\\"Array of content parts\\",\\"type\\":\\"array\\"}\],\\"title\\":\\"System message content\\"},\\"name\\":{\\"description\\":\\"An optional name for the participant. Provides the model information to differentiate between participants of the same role.\\",\\"type\\":\\"string\\"},\\"role\\":{\\"description\\":\\"The role of the messages author, in this case \`system\`.\\",\\"enum\\":\[\\"system\\",\\"developer\\"\],\\"type\\":\\"string\\"},\\"tool\_call\_id\\":{\\"description\\":\\"DO NOT USE. This field is present because OpenAI allows it and users send it.\\",\\"nullable\\":true,\\"type\\":\\"string\\",\\"x-groq-meta\\":{\\"hidden\\":true}}},\\"required\\":\[\\"content\\",\\"role\\"\],\\"title\\":\\"System message\\",\\"type\\":\\"object\\"},\\"ChatCompletionRequestToolMessage\\":{\\"additionalProperties\\":false,\\"properties\\":{\\"content\\":{\\"description\\":\\"The contents of the tool message.\\",\\"oneOf\\":\[{\\"description\\":\\"The text contents of the message.\\",\\"title\\":\\"Text content\\",\\"type\\":\\"string\\"},{\\"description\\":\\"An array of content parts with a defined type, each can be of type \`text\` or \`image\_url\` when passing in images. You can pass multiple images by adding multiple \`image\_url\` content parts. Image input is only supported when using the \`gpt-4-visual-preview\` model.\\",\\"items\\":{\\"$ref\\":\\"#/components/schemas/ChatCompletionRequestMessageContentPart\\"},\\"minItems\\":1,\\"title\\":\\"Array of content parts\\",\\"type\\":\\"array\\"}\],\\"title\\":\\"Tool message content\\"},\\"name\\":{\\"description\\":\\"DO NOT USE. This field is present because OpenAI allows it and users send it.\\",\\"type\\":\\"string\\",\\"x-groq-meta\\":{\\"hidden\\":true}},\\"role\\":{\\"description\\":\\"The role of the messages author, in this case \`tool\`.\\",\\"enum\\":\[\\"tool\\"\],\\"type\\":\\"string\\"},\\"tool\_call\_id\\":{\\"description\\":\\"Tool call that this message is responding to.\\",\\"type\\":\\"string\\"}},\\"required\\":\[\\"role\\",\\"content\\",\\"tool\_call\_id\\"\],\\"title\\":\\"Tool message\\",\\"type\\":\\"object\\"},\\"ChatCompletionRequestUserMessage\\":{\\"additionalProperties\\":false,\\"properties\\":{\\"content\\":{\\"description\\":\\"The contents of the user message.\\\\n\\",\\"oneOf\\":\[{\\"description\\":\\"The text contents of the message.\\",\\"title\\":\\"Text content\\",\\"type\\":\\"string\\"},{\\"description\\":\\"An array of content parts with a defined type, each can be of type \`text\` or \`image\_url\` when passing in images. You can pass multiple images by adding multiple \`image\_url\` content parts. Image input is only supported when using the \`gpt-4-visual-preview\` model.\\",\\"items\\":{\\"$ref\\":\\"#/components/schemas/ChatCompletionRequestMessageContentPart\\"},\\"minItems\\":1,\\"title\\":\\"Array of content parts\\",\\"type\\":\\"array\\"}\],\\"title\\":\\"User message content\\"},\\"name\\":{\\"description\\":\\"An optional name for the participant. Provides the model information to differentiate between participants of the same role.\\",\\"type\\":\\"string\\"},\\"role\\":{\\"description\\":\\"The role of the messages author, in this case \`user\`.\\",\\"enum\\":\[\\"user\\"\],\\"type\\":\\"string\\"},\\"tool\_call\_id\\":{\\"description\\":\\"DO NOT USE. This field is present because OpenAI allows it and users send it.\\",\\"nullable\\":true,\\"type\\":\\"string\\",\\"x-groq-meta\\":{\\"hidden\\":true}}},\\"required\\":\[\\"content\\",\\"role\\"\],\\"title\\":\\"User message\\",\\"type\\":\\"object\\"},\\"ChatCompletionResponseMessage\\":{\\"description\\":\\"A chat completion message generated by the model.\\",\\"properties\\":{\\"annotations\\":{\\"description\\":\\"A list of annotations providing citations and references for the content in the message.\\",\\"items\\":{\\"$ref\\":\\"#/components/schemas/Annotation\\"},\\"type\\":\\"array\\"},\\"content\\":{\\"description\\":\\"The contents of the message.\\",\\"nullable\\":true,\\"type\\":\\"string\\"},\\"executed\_tools\\":{\\"$ref\\":\\"#/components/schemas/ChatCompletionMessageExecutedTools\\"},\\"function\_call\\":{\\"deprecated\\":true,\\"description\\":\\"Deprecated and replaced by \`tool\_calls\`. The name and arguments of a function that should be called, as generated by the model.\\",\\"properties\\":{\\"arguments\\":{\\"description\\":\\"The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.\\",\\"type\\":\\"string\\"},\\"name\\":{\\"description\\":\\"The name of the function to call.\\",\\"type\\":\\"string\\"}},\\"required\\":\[\\"name\\",\\"arguments\\"\],\\"type\\":\\"object\\"},\\"reasoning\\":{\\"description\\":\\"The model's reasoning for a response. Only available for reasoning models when requests parameter reasoning\_format has value \`parsed.\\",\\"nullable\\":true,\\"type\\":\\"string\\"},\\"role\\":{\\"description\\":\\"The role of the author of this message.\\",\\"enum\\":\[\\"assistant\\"\],\\"type\\":\\"string\\"},\\"tool\_calls\\":{\\"$ref\\":\\"#/components/schemas/ChatCompletionMessageToolCalls\\"}},\\"required\\":\[\\"role\\",\\"content\\"\],\\"type\\":\\"object\\"},\\"ChatCompletionRole\\":{\\"description\\":\\"The role of the author of a message\\",\\"enum\\":\[\\"system\\",\\"user\\",\\"assistant\\",\\"tool\\",\\"function\\"\],\\"type\\":\\"string\\"},\\"ChatCompletionStreamOptions\\":{\\"description\\":\\"Options for streaming response. Only set this when you set \`stream: true\`.\\\\n\\",\\"nullable\\":true,\\"properties\\":{\\"include\_usage\\":{\\"description\\":\\"If set, an additional chunk will be streamed before the \`data: \[DONE\]\` message. The \`usage\` field on this chunk shows the token usage statistics for the entire request, and the \`choices\` field will always be an empty array. All other chunks will also include a \`usage\` field, but with a null value.\\\\n\\",\\"nullable\\":true,\\"type\\":\\"boolean\\"}},\\"type\\":\\"object\\"},\\"ChatCompletionStreamResponseDelta\\":{\\"description\\":\\"A chat completion delta generated by streamed model responses.\\",\\"properties\\":{\\"annotations\\":{\\"description\\":\\"A list of annotations providing citations and references for the content in the message.\\",\\"items\\":{\\"$ref\\":\\"#/components/schemas/Annotation\\"},\\"type\\":\\"array\\"},\\"content\\":{\\"description\\":\\"The contents of the chunk message.\\",\\"nullable\\":true,\\"type\\":\\"string\\"},\\"executed\_tools\\":{\\"$ref\\":\\"#/components/schemas/ChatCompletionMessageExecutedTools\\"},\\"function\_call\\":{\\"deprecated\\":true,\\"description\\":\\"Deprecated and replaced by \`tool\_calls\`. The name and arguments of a function that should be called, as generated by the model.\\",\\"properties\\":{\\"arguments\\":{\\"description\\":\\"The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.\\",\\"type\\":\\"string\\"},\\"name\\":{\\"description\\":\\"The name of the function to call.\\",\\"type\\":\\"string\\"}},\\"type\\":\\"object\\"},\\"reasoning\\":{\\"description\\":\\"The model's reasoning for a response. Only available for reasoning models when requests parameter reasoning\_format has value \`parsed.\\",\\"nullable\\":true,\\"type\\":\\"string\\"},\\"role\\":{\\"description\\":\\"The role of the author of this message.\\",\\"enum\\":\[\\"system\\",\\"user\\",\\"assistant\\",\\"tool\\"\],\\"type\\":\\"string\\"},\\"tool\_calls\\":{\\"items\\":{\\"$ref\\":\\"#/components/schemas/ChatCompletionMessageToolCallChunk\\"},\\"type\\":\\"array\\"}},\\"type\\":\\"object\\"},\\"ChatCompletionTokenLogprob\\":{\\"properties\\":{\\"bytes\\":{\\"description\\":\\"A list of integers representing the UTF-8 bytes representation of the token. Useful in instances where characters are represented by multiple tokens and their byte representations must be combined to generate the correct text representation. Can be \`null\` if there is no bytes representation for the token.\\",\\"items\\":{\\"type\\":\\"integer\\"},\\"nullable\\":true,\\"type\\":\\"array\\"},\\"logprob\\":{\\"description\\":\\"The log probability of this token, if it is within the top 20 most likely tokens. Otherwise, the value \`-9999.0\` is used to signify that the token is very unlikely.\\",\\"type\\":\\"number\\"},\\"token\\":{\\"description\\":\\"The token.\\",\\"type\\":\\"string\\"},\\"top\_logprobs\\":{\\"description\\":\\"List of the most likely tokens and their log probability, at this token position. In rare cases, there may be fewer than the number of requested \`top\_logprobs\` returned.\\",\\"items\\":{\\"properties\\":{\\"bytes\\":{\\"description\\":\\"A list of integers representing the UTF-8 bytes representation of the token. Useful in instances where characters are represented by multiple tokens and their byte representations must be combined to generate the correct text representation. Can be \`null\` if there is no bytes representation for the token.\\",\\"items\\":{\\"type\\":\\"integer\\"},\\"nullable\\":true,\\"type\\":\\"array\\"},\\"logprob\\":{\\"description\\":\\"The log probability of this token, if it is within the top 20 most likely tokens. Otherwise, the value \`-9999.0\` is used to signify that the token is very unlikely.\\",\\"type\\":\\"number\\"},\\"token\\":{\\"description\\":\\"The token.\\",\\"type\\":\\"string\\"}},\\"required\\":\[\\"token\\",\\"logprob\\",\\"bytes\\"\],\\"type\\":\\"object\\"},\\"type\\":\\"array\\"}},\\"required\\":\[\\"token\\",\\"logprob\\",\\"bytes\\",\\"top\_logprobs\\"\],\\"type\\":\\"object\\"},\\"ChatCompletionTool\\":{\\"properties\\":{\\"allowed\_tools\\":{\\"description\\":\\"A list of tool names to allow from the MCP server. If specified, only these tools will be exposed to the model. If empty or not specified, all discovered tools will be available.\\",\\"items\\":{\\"type\\":\\"string\\"},\\"type\\":\\"array\\",\\"x-groq-meta\\":{\\"hidden\\":true}},\\"function\\":{\\"$ref\\":\\"#/components/schemas/FunctionObject\\"},\\"headers\\":{\\"additionalProperties\\":{\\"type\\":\\"string\\"},\\"description\\":\\"HTTP headers to send with requests to the MCP server (optional for MCP tools).\\",\\"type\\":\\"object\\",\\"x-groq-meta\\":{\\"hidden\\":true}},\\"server\_label\\":{\\"description\\":\\"A human-readable label for the MCP server (optional for MCP tools).\\",\\"type\\":\\"string\\",\\"x-groq-meta\\":{\\"hidden\\":true}},\\"server\_url\\":{\\"description\\":\\"The URL of the MCP server to connect to (required for MCP tools).\\",\\"type\\":\\"string\\",\\"x-groq-meta\\":{\\"hidden\\":true}},\\"type\\":{\\"anyOf\\":\[{\\"description\\":\\"The type of the tool. \`function\`, \`browser\_search\`, and \`code\_interpreter\` are supported.\\",\\"enum\\":\[\\"function\\",\\"browser\_search\\",\\"code\_interpreter\\"\],\\"type\\":\\"string\\"},{\\"type\\":\\"string\\"}\]}},\\"required\\":\[\\"type\\"\],\\"type\\":\\"object\\"},\\"ChatCompletionToolChoiceOption\\":{\\"description\\":\\"Controls which (if any) tool is called by the model.\\\\n\`none\` means the model will not call any tool and instead generates a message.\\\\n\`auto\` means the model can pick between generating a message or calling one or more tools.\\\\n\`required\` means the model must call one or more tools.\\\\nSpecifying a particular tool via \`{\\\\\\"type\\\\\\": \\\\\\"function\\\\\\", \\\\\\"function\\\\\\": {\\\\\\"name\\\\\\": \\\\\\"my\_function\\\\\\"}}\` forces the model to call that tool.\\\\n\\\\n\`none\` is the default when no tools are present. \`auto\` is the default if tools are present.\\\\n\\",\\"nullable\\":true,\\"oneOf\\":\[{\\"description\\":\\"\`none\` means the model will not call any tool and instead generates a message. \`auto\` means the model can pick between generating a message or calling one or more tools.\\\\n\\",\\"enum\\":\[\\"none\\",\\"auto\\",\\"required\\"\],\\"type\\":\\"string\\"},{\\"$ref\\":\\"#/components/schemas/ChatCompletionNamedToolChoice\\"}\],\\"x-groq-meta\\":{\\"validator\\":\\"ChatCompletionToolChoiceOption\\"}},\\"ChatCompletionUsageBreakdown\\":{\\"description\\":\\"Usage statistics for compound AI completion requests.\\",\\"properties\\":{\\"models\\":{\\"description\\":\\"List of models used in the request and their individual usage statistics\\",\\"items\\":{\\"properties\\":{\\"model\\":{\\"description\\":\\"The name/identifier of the model used\\",\\"type\\":\\"string\\"},\\"usage\\":{\\"$ref\\":\\"#/components/schemas/CompletionUsage\\"}},\\"required\\":\[\\"model\\",\\"usage\\"\],\\"type\\":\\"object\\"},\\"type\\":\\"array\\"}},\\"required\\":\[\\"models\\"\],\\"type\\":\\"object\\"},\\"CodeExecutionOutput\\":{\\"additionalProperties\\":false,\\"properties\\":{\\"results\\":{\\"description\\":\\"Array of code execution results\\",\\"items\\":{\\"$ref\\":\\"#/components/schemas/CodeExecutionResult\\"},\\"type\\":\\"array\\"},\\"stdout\\":{\\"description\\":\\"Standard output from code execution\\",\\"type\\":\\"string\\"}},\\"required\\":\[\\"stdout\\"\],\\"type\\":\\"object\\"},\\"CodeExecutionResult\\":{\\"additionalProperties\\":false,\\"properties\\":{\\"chart\\":{\\"$ref\\":\\"#/components/schemas/Chart\\"},\\"charts\\":{\\"description\\":\\"Array of charts from a superchart\\",\\"items\\":{\\"$ref\\":\\"#/components/schemas/Chart\\"},\\"type\\":\\"array\\"},\\"png\\":{\\"description\\":\\"Base64 encoded PNG image output from code execution\\",\\"type\\":\\"string\\"},\\"text\\":{\\"description\\":\\"The text version of the code execution result\\",\\"type\\":\\"string\\"}},\\"type\\":\\"object\\"},\\"CompletionUsage\\":{\\"description\\":\\"Usage statistics for the completion request.\\",\\"properties\\":{\\"completion\_time\\":{\\"description\\":\\"Time spent generating tokens\\",\\"type\\":\\"number\\"},\\"completion\_tokens\\":{\\"description\\":\\"Number of tokens in the generated completion.\\",\\"type\\":\\"integer\\"},\\"prompt\_time\\":{\\"description\\":\\"Time spent processing input tokens\\",\\"type\\":\\"number\\"},\\"prompt\_tokens\\":{\\"description\\":\\"Number of tokens in the prompt.\\",\\"type\\":\\"integer\\"},\\"queue\_time\\":{\\"description\\":\\"Time the requests was spent queued\\",\\"type\\":\\"number\\"},\\"total\_time\\":{\\"description\\":\\"completion time and prompt time combined\\",\\"type\\":\\"number\\"},\\"total\_tokens\\":{\\"description\\":\\"Total number of tokens used in the request (prompt + completion).\\",\\"type\\":\\"integer\\"}},\\"required\\":\[\\"prompt\_tokens\\",\\"completion\_tokens\\",\\"total\_tokens\\"\],\\"type\\":\\"object\\"},\\"CreateChatCompletionRequest\\":{\\"additionalProperties\\":false,\\"properties\\":{\\"citation\_options\\":{\\"default\\":\\"enabled\\",\\"description\\":\\"Whether to enable citations in the response. When enabled, the model will include citations for information retrieved from provided documents or web searches.\\",\\"enum\\":\[\\"enabled\\",\\"disabled\\"\],\\"nullable\\":true,\\"type\\":\\"string\\"},\\"compound\_custom\\":{\\"description\\":\\"Custom configuration of models and tools for Compound.\\",\\"nullable\\":true,\\"properties\\":{\\"models\\":{\\"nullable\\":true,\\"properties\\":{\\"answering\_model\\":{\\"description\\":\\"Custom model to use for answering.\\",\\"nullable\\":true,\\"type\\":\\"string\\"},\\"reasoning\_model\\":{\\"description\\":\\"Custom model to use for reasoning.\\",\\"nullable\\":true,\\"type\\":\\"string\\"}},\\"type\\":\\"object\\"},\\"tools\\":{\\"description\\":\\"Configuration options for tools available to Compound.\\",\\"nullable\\":true,\\"properties\\":{\\"enabled\_tools\\":{\\"description\\":\\"A list of tool names that are enabled for the request.\\",\\"items\\":{\\"type\\":\\"string\\"},\\"nullable\\":true,\\"type\\":\\"array\\"},\\"wolfram\_settings\\":{\\"description\\":\\"Configuration for the Wolfram tool integration.\\",\\"nullable\\":true,\\"properties\\":{\\"authorization\\":{\\"description\\":\\"API key used to authorize requests to Wolfram services.\\",\\"nullable\\":true,\\"type\\":\\"string\\"}},\\"type\\":\\"object\\"}},\\"type\\":\\"object\\"}},\\"type\\":\\"object\\"},\\"disable\_tool\_validation\\":{\\"default\\":false,\\"description\\":\\"If set to true, groq will return called tools without validating that the tool is present in request.tools. tool\_choice=required/none will still be enforced, but the request cannot require a specific tool be used.\\\\n\\",\\"type\\":\\"boolean\\"},\\"documents\\":{\\"description\\":\\"A list of documents to provide context for the conversation. Each document contains text that can be referenced by the model.\\",\\"items\\":{\\"$ref\\":\\"#/components/schemas/ChatCompletionDocument\\"},\\"nullable\\":true,\\"type\\":\\"array\\"},\\"exclude\_domains\\":{\\"deprecated\\":true,\\"description\\":\\"Deprecated: Use search\_settings.exclude\_domains instead.\\\\nA list of domains to exclude from the search results when the model uses a web search tool.\\\\n\\",\\"items\\":{\\"type\\":\\"string\\"},\\"nullable\\":true,\\"type\\":\\"array\\"},\\"exclude\_instance\_ids\\":{\\"description\\":\\"For internal use only\\\\n\\",\\"items\\":{\\"type\\":\\"string\\"},\\"nullable\\":true,\\"type\\":\\"array\\",\\"x-groq-meta\\":{\\"hidden\\":true}},\\"frequency\_penalty\\":{\\"default\\":0,\\"description\\":\\"This is not yet supported by any of our models. Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.\\",\\"maximum\\":2,\\"minimum\\":-2,\\"nullable\\":true,\\"type\\":\\"number\\"},\\"function\_call\\":{\\"deprecated\\":true,\\"description\\":\\"Deprecated in favor of \`tool\_choice\`.\\\\n\\\\nControls which (if any) function is called by the model.\\\\n\`none\` means the model will not call a function and instead generates a message.\\\\n\`auto\` means the model can pick between generating a message or calling a function.\\\\nSpecifying a particular function via \`{\\\\\\"name\\\\\\": \\\\\\"my\_function\\\\\\"}\` forces the model to call that function.\\\\n\\\\n\`none\` is the default when no functions are present. \`auto\` is the default if functions are present.\\\\n\\",\\"nullable\\":true,\\"oneOf\\":\[{\\"description\\":\\"\`none\` means the model will not call a function and instead generates a message. \`auto\` means the model can pick between generating a message or calling a function.\\\\n\\",\\"enum\\":\[\\"none\\",\\"auto\\",\\"required\\"\],\\"type\\":\\"string\\"},{\\"$ref\\":\\"#/components/schemas/ChatCompletionFunctionCallOption\\"}\]},\\"functions\\":{\\"deprecated\\":true,\\"description\\":\\"Deprecated in favor of \`tools\`.\\\\n\\\\nA list of functions the model may generate JSON inputs for.\\\\n\\",\\"items\\":{\\"$ref\\":\\"#/components/schemas/ChatCompletionFunctions\\"},\\"maxItems\\":128,\\"nullable\\":true,\\"type\\":\\"array\\"},\\"include\_domains\\":{\\"deprecated\\":true,\\"description\\":\\"Deprecated: Use search\_settings.include\_domains instead.\\\\nA list of domains to include in the search results when the model uses a web search tool.\\\\n\\",\\"items\\":{\\"type\\":\\"string\\"},\\"nullable\\":true,\\"type\\":\\"array\\"},\\"include\_reasoning\\":{\\"description\\":\\"Whether to include reasoning in the response. If true, the response will include a \`reasoning\` field. If false, the model's reasoning will not be included in the response.\\\\nThis field is mutually exclusive with \`reasoning\_format\`.\\\\n\\",\\"nullable\\":true,\\"type\\":\\"boolean\\"},\\"logit\_bias\\":{\\"additionalProperties\\":{\\"type\\":\\"integer\\"},\\"description\\":\\"This is not yet supported by any of our models.\\\\nModify the likelihood of specified tokens appearing in the completion.\\\\n\\",\\"nullable\\":true,\\"type\\":\\"object\\"},\\"logprobs\\":{\\"default\\":false,\\"description\\":\\"This is not yet supported by any of our models.\\\\nWhether to return log probabilities of the output tokens or not. If true, returns the log probabilities of each output token returned in the \`content\` of \`message\`.\\\\n\\",\\"nullable\\":true,\\"type\\":\\"boolean\\"},\\"max\_completion\_tokens\\":{\\"description\\":\\"The maximum number of tokens that can be generated in the chat completion. The total length of input tokens and generated tokens is limited by the model's context length.\\",\\"nullable\\":true,\\"type\\":\\"integer\\"},\\"max\_tokens\\":{\\"deprecated\\":true,\\"description\\":\\"Deprecated in favor of \`max\_completion\_tokens\`.\\\\nThe maximum number of tokens that can be generated in the chat completion. The total length of input tokens and generated tokens is limited by the model's context length.\\\\n\\",\\"nullable\\":true,\\"type\\":\\"integer\\"},\\"messages\\":{\\"description\\":\\"A list of messages comprising the conversation so far.\\",\\"items\\":{\\"$ref\\":\\"#/components/schemas/ChatCompletionRequestMessage\\"},\\"minItems\\":1,\\"type\\":\\"array\\"},\\"metadata\\":{\\"additionalProperties\\":{\\"type\\":\\"string\\"},\\"description\\":\\"This parameter is not currently supported.\\\\n\\",\\"nullable\\":true,\\"type\\":\\"object\\"},\\"model\\":{\\"anyOf\\":\[{\\"type\\":\\"string\\"},{\\"enum\\":\[\\"compound-beta\\",\\"compound-beta-mini\\",\\"gemma2-9b-it\\",\\"llama-3.1-8b-instant\\",\\"llama-3.3-70b-versatile\\",\\"meta-llama/llama-4-maverick-17b-128e-instruct\\",\\"meta-llama/llama-4-scout-17b-16e-instruct\\",\\"meta-llama/llama-guard-4-12b\\",\\"moonshotai/kimi-k2-instruct\\",\\"openai/gpt-oss-120b\\",\\"openai/gpt-oss-20b\\",\\"qwen/qwen3-32b\\"\],\\"type\\":\\"string\\"}\],\\"description\\":\\"ID of the model to use. For details on which models are compatible with the Chat API, see available \[models\](https://console.groq.com/docs/models)\\",\\"example\\":\\"meta-llama/llama-4-scout-17b-16e-instruct\\"},\\"n\\":{\\"default\\":1,\\"description\\":\\"How many chat completion choices to generate for each input message. Note that the current moment, only n=1 is supported. Other values will result in a 400 response.\\",\\"example\\":1,\\"maximum\\":1,\\"minimum\\":1,\\"nullable\\":true,\\"type\\":\\"integer\\"},\\"parallel\_tool\_calls\\":{\\"default\\":true,\\"description\\":\\"Whether to enable parallel function calling during tool use.\\\\n\\",\\"nullable\\":true,\\"type\\":\\"boolean\\"},\\"presence\_penalty\\":{\\"default\\":0,\\"description\\":\\"This is not yet supported by any of our models. Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.\\",\\"maximum\\":2,\\"minimum\\":-2,\\"nullable\\":true,\\"type\\":\\"number\\"},\\"raw\\":{\\"default\\":false,\\"description\\":\\"Skip all post processing such as stop sequences, reasoning parsing, tool parsing, json validation, etc\\",\\"nullable\\":true,\\"type\\":\\"boolean\\",\\"x-groq-meta\\":{\\"hidden\\":true}},\\"reasoning\_effort\\":{\\"description\\":\\"qwen3 models support the following values\\\\nSet to 'none' to disable reasoning.\\\\nSet to 'default' or null to let Qwen reason.\\\\n\\\\nopenai/gpt-oss-20b and openai/gpt-oss-120b support 'low', 'medium', or 'high'.\\\\n'medium' is the default value.\\\\n\\",\\"enum\\":\[\\"none\\",\\"default\\",\\"low\\",\\"medium\\",\\"high\\"\],\\"nullable\\":true,\\"type\\":\\"string\\"},\\"reasoning\_format\\":{\\"description\\":\\"Specifies how to output reasoning tokens\\\\nThis field is mutually exclusive with \`include\_reasoning\`.\\\\n\\",\\"enum\\":\[\\"hidden\\",\\"raw\\",\\"parsed\\"\],\\"nullable\\":true,\\"type\\":\\"string\\"},\\"response\_format\\":{\\"description\\":\\"An object specifying the format that the model must output. Setting to \`{ \\\\\\"type\\\\\\": \\\\\\"json\_schema\\\\\\", \\\\\\"json\_schema\\\\\\": {...} }\` enables Structured Outputs which ensures the model will match your supplied JSON schema. \`json\_schema\` response format is only available on \[supported models\](https://console.groq.com/docs/structured-outputs#supported-models). Setting to \`{ \\\\\\"type\\\\\\": \\\\\\"json\_object\\\\\\" }\` enables the older JSON mode, which ensures the message the model generates is valid JSON. Using \`json\_schema\` is preferred for models that support it.\\\\n\\",\\"nullable\\":true,\\"oneOf\\":\[{\\"$ref\\":\\"#/components/schemas/ResponseFormatText\\"},{\\"$ref\\":\\"#/components/schemas/ResponseFormatJsonSchema\\"},{\\"$ref\\":\\"#/components/schemas/ResponseFormatJsonObject\\"}\]},\\"search\_settings\\":{\\"description\\":\\"Settings for web search functionality when the model uses a web search tool.\\\\n\\",\\"nullable\\":true,\\"properties\\":{\\"country\\":{\\"description\\":\\"Name of country to prioritize search results from (e.g., \\\\\\"united states\\\\\\", \\\\\\"germany\\\\\\", \\\\\\"france\\\\\\").\\",\\"nullable\\":true,\\"type\\":\\"string\\"},\\"exclude\_domains\\":{\\"description\\":\\"A list of domains to exclude from the search results.\\",\\"items\\":{\\"type\\":\\"string\\"},\\"nullable\\":true,\\"type\\":\\"array\\"},\\"include\_domains\\":{\\"description\\":\\"A list of domains to include in the search results.\\",\\"items\\":{\\"type\\":\\"string\\"},\\"nullable\\":true,\\"type\\":\\"array\\"},\\"include\_images\\":{\\"description\\":\\"Whether to include images in the search results.\\",\\"nullable\\":true,\\"type\\":\\"boolean\\"}},\\"type\\":\\"object\\"},\\"seed\\":{\\"description\\":\\"If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same \`seed\` and parameters should return the same result.\\\\nDeterminism is not guaranteed, and you should refer to the \`system\_fingerprint\` response parameter to monitor changes in the backend.\\\\n\\",\\"nullable\\":true,\\"type\\":\\"integer\\"},\\"service\_tier\\":{\\"description\\":\\"The service tier to use for the request. Defaults to \`on\_demand\`.\\\\n- \`auto\` will automatically select the highest tier available within the rate limits of your organization.\\\\n- \`flex\` uses the flex tier, which will succeed or fail quickly.\\\\n\\",\\"enum\\":\[\\"auto\\",\\"on\_demand\\",\\"flex\\",\\"performance\\",null\],\\"nullable\\":true,\\"type\\":\\"string\\"},\\"stop\\":{\\"description\\":\\"Up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.\\\\n\\",\\"nullable\\":true,\\"oneOf\\":\[{\\"example\\":\\"\\\\n\\",\\"nullable\\":true,\\"type\\":\\"string\\"},{\\"items\\":{\\"example\\":\\"\[\\\\\\"\\\\\\\\n\\\\\\"\]\\",\\"type\\":\\"string\\"},\\"maxItems\\":4,\\"type\\":\\"array\\"}\]},\\"store\\":{\\"description\\":\\"This parameter is not currently supported.\\\\n\\",\\"nullable\\":true,\\"type\\":\\"boolean\\"},\\"stream\\":{\\"default\\":false,\\"description\\":\\"If set, partial message deltas will be sent. Tokens will be sent as data-only \[server-sent events\](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent\_events/Using\_server-sent\_events#Event\_stream\_format) as they become available, with the stream terminated by a \`data: \[DONE\]\` message. \[Example code\](/docs/text-chat#streaming-a-chat-completion).\\\\n\\",\\"nullable\\":true,\\"type\\":\\"boolean\\"},\\"stream\_options\\":{\\"$ref\\":\\"#/components/schemas/ChatCompletionStreamOptions\\"},\\"temperature\\":{\\"default\\":1,\\"description\\":\\"What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. We generally recommend altering this or top\_p but not both.\\",\\"example\\":1,\\"maximum\\":2,\\"minimum\\":0,\\"nullable\\":true,\\"type\\":\\"number\\"},\\"tool\_choice\\":{\\"$ref\\":\\"#/components/schemas/ChatCompletionToolChoiceOption\\"},\\"tools\\":{\\"description\\":\\"A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported.\\\\n\\",\\"items\\":{\\"$ref\\":\\"#/components/schemas/ChatCompletionTool\\"},\\"maxItems\\":128,\\"nullable\\":true,\\"type\\":\\"array\\"},\\"top\_logprobs\\":{\\"description\\":\\"This is not yet supported by any of our models.\\\\nAn integer between 0 and 20 specifying the number of most likely tokens to return at each token position, each with an associated log probability. \`logprobs\` must be set to \`true\` if this parameter is used.\\\\n\\",\\"maximum\\":20,\\"minimum\\":0,\\"nullable\\":true,\\"type\\":\\"integer\\"},\\"top\_p\\":{\\"default\\":1,\\"description\\":\\"An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. We generally recommend altering this or temperature but not both.\\",\\"example\\":1,\\"maximum\\":1,\\"minimum\\":0,\\"nullable\\":true,\\"type\\":\\"number\\"},\\"user\\":{\\"description\\":\\"A unique identifier representing your end-user, which can help us monitor and detect abuse.\\",\\"nullable\\":true,\\"type\\":\\"string\\"}},\\"required\\":\[\\"model\\",\\"messages\\"\],\\"type\\":\\"object\\"},\\"CreateChatCompletionResponse\\":{\\"description\\":\\"Represents a chat completion response returned by model, based on the provided input.\\",\\"properties\\":{\\"choices\\":{\\"description\\":\\"A list of chat completion choices. Can be more than one if \`n\` is greater than 1.\\",\\"items\\":{\\"properties\\":{\\"finish\_reason\\":{\\"description\\":\\"The reason the model stopped generating tokens. This will be \`stop\` if the model hit a natural stop point or a provided stop sequence,\\\\n\`length\` if the maximum number of tokens specified in the request was reached,\\\\n\`tool\_calls\` if the model called a tool, or \`function\_call\` (deprecated) if the model called a function.\\\\n\\",\\"enum\\":\[\\"stop\\",\\"length\\",\\"tool\_calls\\",\\"function\_call\\"\],\\"type\\":\\"string\\"},\\"index\\":{\\"description\\":\\"The index of the choice in the list of choices.\\",\\"type\\":\\"integer\\"},\\"logprobs\\":{\\"description\\":\\"Log probability information for the choice.\\",\\"nullable\\":true,\\"properties\\":{\\"content\\":{\\"description\\":\\"A list of message content tokens with log probability information.\\",\\"items\\":{\\"$ref\\":\\"#/components/schemas/ChatCompletionTokenLogprob\\"},\\"nullable\\":true,\\"type\\":\\"array\\"}},\\"required\\":\[\\"content\\"\],\\"type\\":\\"object\\"},\\"message\\":{\\"$ref\\":\\"#/components/schemas/ChatCompletionResponseMessage\\"}},\\"required\\":\[\\"finish\_reason\\",\\"index\\",\\"message\\",\\"logprobs\\"\],\\"type\\":\\"object\\"},\\"type\\":\\"array\\"},\\"created\\":{\\"description\\":\\"The Unix timestamp (in seconds) of when the chat completion was created.\\",\\"type\\":\\"integer\\"},\\"id\\":{\\"description\\":\\"A unique identifier for the chat completion.\\",\\"type\\":\\"string\\"},\\"model\\":{\\"description\\":\\"The model used for the chat completion.\\",\\"type\\":\\"string\\"},\\"object\\":{\\"description\\":\\"The object type, which is always \`chat.completion\`.\\",\\"enum\\":\[\\"chat.completion\\"\],\\"type\\":\\"string\\"},\\"system\_fingerprint\\":{\\"description\\":\\"This fingerprint represents the backend configuration that the model runs with.\\\\n\\\\nCan be used in conjunction with the \`seed\` request parameter to understand when backend changes have been made that might impact determinism.\\\\n\\",\\"type\\":\\"string\\"},\\"usage\\":{\\"$ref\\":\\"#/components/schemas/CompletionUsage\\"},\\"usage\_breakdown\\":{\\"$ref\\":\\"#/components/schemas/ChatCompletionUsageBreakdown\\"}},\\"required\\":\[\\"choices\\",\\"created\\",\\"id\\",\\"model\\",\\"object\\"\],\\"type\\":\\"object\\"},\\"CreateChatCompletionStreamResponse\\":{\\"description\\":\\"Represents a streamed chunk of a chat completion response returned by model, based on the provided input.\\",\\"properties\\":{\\"choices\\":{\\"description\\":\\"A list of chat completion choices. Can contain more than one elements if \`n\` is greater than 1.\\\\n\\",\\"items\\":{\\"properties\\":{\\"delta\\":{\\"$ref\\":\\"#/components/schemas/ChatCompletionStreamResponseDelta\\"},\\"finish\_reason\\":{\\"description\\":\\"The reason the model stopped generating tokens. This will be \`stop\` if the model hit a natural stop point or a provided stop sequence,\\\\n\`length\` if the maximum number of tokens specified in the request was reached,\\\\n\`tool\_calls\` if the model called a tool, or \`function\_call\` (deprecated) if the model called a function.\\\\n\\",\\"enum\\":\[\\"stop\\",\\"length\\",\\"tool\_calls\\",\\"function\_call\\"\],\\"nullable\\":true,\\"type\\":\\"string\\"},\\"index\\":{\\"description\\":\\"The index of the choice in the list of choices.\\",\\"type\\":\\"integer\\"},\\"logprobs\\":{\\"description\\":\\"Log probability information for the choice.\\",\\"nullable\\":true,\\"properties\\":{\\"content\\":{\\"description\\":\\"A list of message content tokens with log probability information.\\",\\"items\\":{\\"$ref\\":\\"#/components/schemas/ChatCompletionTokenLogprob\\"},\\"nullable\\":true,\\"type\\":\\"array\\"}},\\"required\\":\[\\"content\\"\],\\"type\\":\\"object\\"}},\\"required\\":\[\\"delta\\",\\"finish\_reason\\",\\"index\\"\],\\"type\\":\\"object\\"},\\"type\\":\\"array\\"},\\"created\\":{\\"description\\":\\"The Unix timestamp (in seconds) of when the chat completion was created. Each chunk has the same timestamp.\\",\\"type\\":\\"integer\\"},\\"id\\":{\\"description\\":\\"A unique identifier for the chat completion. Each chunk has the same ID.\\",\\"type\\":\\"string\\"},\\"model\\":{\\"description\\":\\"The model to generate the completion.\\",\\"type\\":\\"string\\"},\\"object\\":{\\"description\\":\\"The object type, which is always \`chat.completion.chunk\`.\\",\\"enum\\":\[\\"chat.completion.chunk\\"\],\\"type\\":\\"string\\"},\\"system\_fingerprint\\":{\\"description\\":\\"This fingerprint represents the backend configuration that the model runs with.\\\\nCan be used in conjunction with the \`seed\` request parameter to understand when backend changes have been made that might impact determinism.\\\\n\\",\\"type\\":\\"string\\"},\\"x\_groq\\":{\\"$ref\\":\\"#/components/schemas/XGroq\\"}},\\"required\\":\[\\"choices\\",\\"created\\",\\"id\\",\\"model\\",\\"object\\"\],\\"type\\":\\"object\\"},\\"CreateEmbeddingRequest\\":{\\"additionalProperties\\":false,\\"properties\\":{\\"encoding\_format\\":{\\"default\\":\\"float\\",\\"description\\":\\"The format to return the embeddings in. Can only be \`float\` or \`base64\`.\\",\\"enum\\":\[\\"float\\",\\"base64\\"\],\\"example\\":\\"float\\",\\"type\\":\\"string\\"},\\"input\\":{\\"description\\":\\"Input text to embed, encoded as a string or array of tokens. To embed multiple inputs in a single request, pass an array of strings or array of token arrays. The input must not exceed the max input tokens for the model, cannot be an empty string, and any array must be 2048 dimensions or less.\\\\n\\",\\"example\\":\\"The quick brown fox jumped over the lazy dog\\",\\"oneOf\\":\[{\\"default\\":\\"\\",\\"description\\":\\"The string that will be turned into an embedding.\\",\\"example\\":\\"This is a test.\\",\\"title\\":\\"string\\",\\"type\\":\\"string\\"},{\\"description\\":\\"The array of strings that will be turned into an embeddings.\\",\\"items\\":{\\"default\\":\\"\\",\\"example\\":\\"\['This is a test.'\]\\",\\"type\\":\\"string\\"},\\"maxItems\\":2048,\\"minItems\\":1,\\"title\\":\\"array\\",\\"type\\":\\"array\\"}\],\\"x-groq-meta\\":{\\"validator\\":\\"EmbeddingInput\\"}},\\"model\\":{\\"anyOf\\":\[{\\"type\\":\\"string\\"},{\\"enum\\":\[\\"nomic-embed-text-v1\_5\\"\],\\"type\\":\\"string\\"}\],\\"description\\":\\"ID of the model to use.\\\\n\\",\\"example\\":\\"nomic-embed-text-v1\_5\\"},\\"user\\":{\\"description\\":\\"A unique identifier representing your end-user, which can help us monitor and detect abuse.\\",\\"nullable\\":true,\\"type\\":\\"string\\"}},\\"required\\":\[\\"model\\",\\"input\\"\],\\"type\\":\\"object\\"},\\"CreateEmbeddingResponse\\":{\\"properties\\":{\\"data\\":{\\"description\\":\\"The list of embeddings generated by the model.\\",\\"items\\":{\\"$ref\\":\\"#/components/schemas/Embedding\\"},\\"type\\":\\"array\\"},\\"model\\":{\\"description\\":\\"The name of the model used to generate the embedding.\\",\\"type\\":\\"string\\"},\\"object\\":{\\"description\\":\\"The object type, which is always \\\\\\"list\\\\\\".\\",\\"enum\\":\[\\"list\\"\],\\"type\\":\\"string\\"},\\"usage\\":{\\"description\\":\\"The usage information for the request.\\",\\"properties\\":{\\"prompt\_tokens\\":{\\"description\\":\\"The number of tokens used by the prompt.\\",\\"type\\":\\"integer\\"},\\"total\_tokens\\":{\\"description\\":\\"The total number of tokens used by the request.\\",\\"type\\":\\"integer\\"}},\\"required\\":\[\\"prompt\_tokens\\",\\"total\_tokens\\"\],\\"type\\":\\"object\\"}},\\"required\\":\[\\"object\\",\\"model\\",\\"data\\",\\"usage\\"\],\\"type\\":\\"object\\"},\\"CreateFileRequest\\":{\\"additionalProperties\\":false,\\"properties\\":{\\"file\\":{\\"description\\":\\"The File object (not file name) to be uploaded.\\\\n\\",\\"format\\":\\"binary\\",\\"type\\":\\"string\\"},\\"purpose\\":{\\"description\\":\\"The intended purpose of the uploaded file.\\\\nUse \\\\\\"batch\\\\\\" for \[Batch API\](/docs/api-reference#batches).\\\\n\\",\\"enum\\":\[\\"batch\\"\],\\"type\\":\\"string\\"}},\\"required\\":\[\\"file\\",\\"purpose\\"\],\\"type\\":\\"object\\"},\\"CreateFineTuningRequest\\":{\\"properties\\":{\\"base\_model\\":{\\"description\\":\\"BaseModel is the model that the fine tune was originally trained on.\\\\n\\",\\"type\\":\\"string\\"},\\"input\_file\_id\\":{\\"description\\":\\"InputFileID is the id of the file that was uploaded via the /files api.\\\\n\\",\\"type\\":\\"string\\"},\\"name\\":{\\"description\\":\\"Name is the given name to a fine tuned model.\\\\n\\",\\"type\\":\\"string\\"},\\"type\\":{\\"description\\":\\"Type is the type of fine tuning format such as \\\\\\"lora\\\\\\".\\\\n\\",\\"type\\":\\"string\\"}},\\"type\\":\\"object\\"},\\"CreateResponseRequest\\":{\\"additionalProperties\\":false,\\"properties\\":{\\"input\\":{\\"description\\":\\"Text input to the model, used to generate a response.\\\\n\\",\\"oneOf\\":\[{\\"description\\":\\"A text input to the model, equivalent to a text input with the \`user\` role.\\",\\"title\\":\\"Text input\\",\\"type\\":\\"string\\"},{\\"description\\":\\"A list of one or many input items to the model, containing different content types.\\",\\"items\\":{\\"$ref\\":\\"#/components/schemas/ResponseInputItem\\"},\\"title\\":\\"Input item list\\",\\"type\\":\\"array\\"}\]},\\"instructions\\":{\\"description\\":\\"Inserts a system (or developer) message as the first item in the model's context.\\\\n\\",\\"nullable\\":true,\\"type\\":\\"string\\"},\\"max\_output\_tokens\\":{\\"description\\":\\"An upper bound for the number of tokens that can be generated for a response, including visible output tokens and reasoning tokens.\\\\n\\",\\"nullable\\":true,\\"type\\":\\"integer\\"},\\"metadata\\":{\\"additionalProperties\\":{\\"type\\":\\"string\\"},\\"description\\":\\"Custom key-value pairs for storing additional information. Maximum of 16 pairs.\\\\n\\",\\"nullable\\":true,\\"type\\":\\"object\\"},\\"model\\":{\\"anyOf\\":\[{\\"type\\":\\"string\\"},{\\"enum\\":\[\\"gemma2-9b-it\\",\\"llama-3.3-70b-versatile\\",\\"llama-3.1-8b-instant\\",\\"llama-guard-3-8b\\",\\"llama3-70b-8192\\",\\"llama3-8b-8192\\"\],\\"type\\":\\"string\\"}\],\\"description\\":\\"ID of the model to use. For details on which models are compatible with the Responses API, see available \[models\](https://console.groq.com/docs/models)\\",\\"example\\":\\"llama-3.3-70b-versatile\\"},\\"parallel\_tool\_calls\\":{\\"default\\":true,\\"description\\":\\"Enable parallel execution of multiple tool calls.\\\\n\\",\\"nullable\\":true,\\"type\\":\\"boolean\\"},\\"reasoning\\":{\\"description\\":\\"Configuration for reasoning capabilities when using compatible models.\\\\n\\",\\"nullable\\":true,\\"properties\\":{\\"effort\\":{\\"default\\":\\"medium\\",\\"description\\":\\"Level of reasoning effort. Supported values: \`low\`, \`medium\`, \`high\`. Lower values provide faster responses with less reasoning depth.\\\\n\\",\\"enum\\":\[\\"low\\",\\"medium\\",\\"high\\"\],\\"nullable\\":true,\\"type\\":\\"string\\"}},\\"type\\":\\"object\\"},\\"service\_tier\\":{\\"default\\":\\"auto\\",\\"description\\":\\"Specifies the latency tier to use for processing the request.\\\\n\\",\\"enum\\":\[\\"auto\\",\\"default\\",\\"flex\\"\],\\"nullable\\":true,\\"type\\":\\"string\\"},\\"store\\":{\\"default\\":false,\\"description\\":\\"Response storage flag. Note: Currently only supports false or null values.\\\\n\\",\\"nullable\\":true,\\"type\\":\\"boolean\\"},\\"stream\\":{\\"default\\":false,\\"description\\":\\"Enable streaming mode to receive response data as server-sent events.\\\\n\\",\\"nullable\\":true,\\"type\\":\\"boolean\\"},\\"temperature\\":{\\"default\\":1,\\"description\\":\\"Controls randomness in the response generation. Range: 0 to 2. Lower values produce more deterministic outputs, higher values increase variety and creativity.\\\\n\\",\\"example\\":1,\\"maximum\\":2,\\"minimum\\":0,\\"nullable\\":true,\\"type\\":\\"number\\"},\\"text\\":{\\"description\\":\\"Response format configuration. Supports plain text or structured JSON output.\\\\n\\",\\"properties\\":{\\"format\\":{\\"$ref\\":\\"#/components/schemas/ResponseFormatConfiguration\\"}},\\"type\\":\\"object\\"},\\"tool\_choice\\":{\\"$ref\\":\\"#/components/schemas/ResponseToolChoiceOption\\"},\\"tools\\":{\\"description\\":\\"List of tools available to the model. Currently supports function definitions only. Maximum of 128 functions.\\\\n\\",\\"items\\":{\\"$ref\\":\\"#/components/schemas/ResponseTool\\"},\\"maxItems\\":128,\\"nullable\\":true,\\"type\\":\\"array\\"},\\"top\_p\\":{\\"default\\":1,\\"description\\":\\"Nucleus sampling parameter that controls the cumulative probability cutoff. Range: 0 to 1. A value of 0.1 restricts sampling to tokens within the top 10% probability mass.\\\\n\\",\\"example\\":1,\\"maximum\\":1,\\"minimum\\":0,\\"nullable\\":true,\\"type\\":\\"number\\"},\\"truncation\\":{\\"default\\":\\"disabled\\",\\"description\\":\\"Context truncation strategy. Supported values: \`auto\` or \`disabled\`.\\\\n\\",\\"enum\\":\[\\"auto\\",\\"disabled\\"\],\\"nullable\\":true,\\"type\\":\\"string\\"},\\"user\\":{\\"description\\":\\"Optional identifier for tracking end-user requests. Useful for usage monitoring and compliance.\\\\n\\",\\"example\\":\\"user-1234\\",\\"type\\":\\"string\\"}},\\"required\\":\[\\"model\\",\\"input\\"\],\\"type\\":\\"object\\"},\\"CreateResponseResponse\\":{\\"description\\":\\"Represents a response returned by model, based on the provided input.\\",\\"properties\\":{\\"background\\":{\\"default\\":false,\\"description\\":\\"Whether the response was generated in the background.\\",\\"type\\":\\"boolean\\"},\\"created\_at\\":{\\"description\\":\\"The Unix timestamp (in seconds) of when the response was created.\\",\\"type\\":\\"integer\\"},\\"error\\":{\\"description\\":\\"An error object if the response failed.\\",\\"nullable\\":true,\\"properties\\":{\\"code\\":{\\"description\\":\\"The error code.\\",\\"type\\":\\"string\\"},\\"message\\":{\\"description\\":\\"A human-readable error message.\\",\\"type\\":\\"string\\"}},\\"required\\":\[\\"code\\",\\"message\\"\],\\"type\\":\\"object\\"},\\"id\\":{\\"description\\":\\"A unique identifier for the response.\\",\\"type\\":\\"string\\"},\\"incomplete\_details\\":{\\"description\\":\\"Details about why the response is incomplete.\\",\\"nullable\\":true,\\"properties\\":{\\"reason\\":{\\"description\\":\\"The reason why the response is incomplete.\\",\\"type\\":\\"string\\"}},\\"type\\":\\"object\\"},\\"instructions\\":{\\"description\\":\\"The system instructions used for the response.\\",\\"nullable\\":true,\\"type\\":\\"string\\"},\\"max\_output\_tokens\\":{\\"description\\":\\"The maximum number of tokens configured for the response.\\",\\"nullable\\":true,\\"type\\":\\"integer\\"},\\"max\_tool\_calls\\":{\\"description\\":\\"The maximum number of tool calls allowed.\\",\\"nullable\\":true,\\"type\\":\\"integer\\"},\\"metadata\\":{\\"additionalProperties\\":{\\"type\\":\\"string\\"},\\"description\\":\\"Metadata attached to the response.\\",\\"nullable\\":true,\\"type\\":\\"object\\"},\\"model\\":{\\"description\\":\\"The model used for the response.\\",\\"type\\":\\"string\\"},\\"object\\":{\\"description\\":\\"The object type, which is always \`response\`.\\",\\"enum\\":\[\\"response\\"\],\\"type\\":\\"string\\"},\\"output\\":{\\"description\\":\\"An array of content items generated by the model.\\",\\"items\\":{\\"$ref\\":\\"#/components/schemas/ResponseOutputItem\\"},\\"type\\":\\"array\\"},\\"parallel\_tool\_calls\\":{\\"description\\":\\"Whether the model can run tool calls in parallel.\\",\\"type\\":\\"boolean\\"},\\"previous\_response\_id\\":{\\"description\\":\\"Not supported. Always null.\\",\\"nullable\\":true,\\"type\\":\\"string\\"},\\"reasoning\\":{\\"description\\":\\"Configuration options for reasoning models.\\",\\"nullable\\":true,\\"properties\\":{\\"effort\\":{\\"description\\":\\"The reasoning effort level used.\\",\\"enum\\":\[\\"low\\",\\"medium\\",\\"high\\"\],\\"nullable\\":true,\\"type\\":\\"string\\"},\\"summary\\":{\\"description\\":\\"Not supported. Always null.\\",\\"nullable\\":true,\\"type\\":\\"string\\"}},\\"type\\":\\"object\\"},\\"service\_tier\\":{\\"description\\":\\"The service tier used for processing.\\",\\"enum\\":\[\\"auto\\",\\"default\\",\\"flex\\"\],\\"type\\":\\"string\\"},\\"status\\":{\\"description\\":\\"The status of the response generation. One of \`completed\`, \`failed\`, \`in\_progress\`, or \`incomplete\`.\\\\n\\",\\"enum\\":\[\\"completed\\",\\"failed\\",\\"in\_progress\\",\\"incomplete\\"\],\\"type\\":\\"string\\"},\\"store\\":{\\"description\\":\\"Whether the response was stored.\\",\\"type\\":\\"boolean\\"},\\"temperature\\":{\\"description\\":\\"The sampling temperature used.\\",\\"type\\":\\"number\\"},\\"text\\":{\\"description\\":\\"Text format configuration used for the response.\\",\\"properties\\":{\\"format\\":{\\"$ref\\":\\"#/components/schemas/ResponseFormatConfiguration\\"}},\\"type\\":\\"object\\"},\\"tool\_choice\\":{\\"$ref\\":\\"#/components/schemas/ResponseToolChoiceOption\\"},\\"tools\\":{\\"description\\":\\"The tools that were available to the model.\\",\\"items\\":{\\"$ref\\":\\"#/components/schemas/ResponseTool\\"},\\"type\\":\\"array\\"},\\"top\_logprobs\\":{\\"default\\":0,\\"description\\":\\"The number of top log probabilities returned.\\",\\"type\\":\\"integer\\"},\\"top\_p\\":{\\"description\\":\\"The nucleus sampling parameter used.\\",\\"type\\":\\"number\\"},\\"truncation\\":{\\"description\\":\\"The truncation strategy used.\\",\\"enum\\":\[\\"auto\\",\\"disabled\\"\],\\"type\\":\\"string\\"},\\"usage\\":{\\"$ref\\":\\"#/components/schemas/ResponseUsage\\"},\\"user\\":{\\"description\\":\\"The user identifier.\\",\\"nullable\\":true,\\"type\\":\\"string\\"}},\\"required\\":\[\\"id\\",\\"object\\",\\"status\\",\\"created\_at\\",\\"output\\",\\"model\\",\\"tools\\",\\"tool\_choice\\",\\"truncation\\",\\"metadata\\",\\"temperature\\",\\"top\_p\\",\\"service\_tier\\",\\"error\\",\\"incomplete\_details\\",\\"parallel\_tool\_calls\\",\\"store\\"\],\\"type\\":\\"object\\"},\\"CreateSpeechRequest\\":{\\"additionalProperties\\":false,\\"properties\\":{\\"input\\":{\\"description\\":\\"The text to generate audio for.\\",\\"example\\":\\"The quick brown fox jumped over the lazy dog\\",\\"type\\":\\"string\\"},\\"model\\":{\\"anyOf\\":\[{\\"type\\":\\"string\\"},{\\"enum\\":\[\\"playai-tts\\",\\"playai-tts-arabic\\"\],\\"type\\":\\"string\\"}\],\\"description\\":\\"One of the \[available TTS models\](/docs/text-to-speech).\\\\n\\",\\"example\\":\\"playai-tts\\"},\\"response\_format\\":{\\"default\\":\\"mp3\\",\\"description\\":\\"The format of the generated audio. Supported formats are \`flac, mp3, mulaw, ogg, wav\`.\\",\\"enum\\":\[\\"flac\\",\\"mp3\\",\\"mulaw\\",\\"ogg\\",\\"wav\\"\],\\"type\\":\\"string\\"},\\"sample\_rate\\":{\\"default\\":48000,\\"description\\":\\"The sample rate for generated audio\\",\\"enum\\":\[8000,16000,22050,24000,32000,44100,48000\],\\"example\\":48000,\\"type\\":\\"integer\\"},\\"speed\\":{\\"default\\":1,\\"description\\":\\"The speed of the generated audio.\\",\\"example\\":1,\\"maximum\\":5,\\"minimum\\":0.5,\\"type\\":\\"number\\"},\\"voice\\":{\\"description\\":\\"The voice to use when generating the audio. List of voices can be found \[here\](/docs/text-to-speech).\\",\\"example\\":\\"Fritz-PlayAI\\",\\"type\\":\\"string\\"}},\\"required\\":\[\\"model\\",\\"input\\",\\"voice\\"\],\\"type\\":\\"object\\"},\\"CreateTranscriptionRequest\\":{\\"additionalProperties\\":false,\\"oneOf\\":\[{\\"required\\":\[\\"file\\"\]},{\\"required\\":\[\\"url\\"\]}\],\\"properties\\":{\\"file\\":{\\"description\\":\\"The audio file object (not file name) to transcribe, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.\\\\nEither a file or a URL must be provided. Note that the file field is not supported in Batch API requests.\\\\n\\",\\"format\\":\\"binary\\",\\"type\\":\\"string\\"},\\"language\\":{\\"anyOf\\":\[{\\"type\\":\\"string\\"},{\\"enum\\":\[\\"en\\",\\"zh\\",\\"de\\",\\"es\\",\\"ru\\",\\"ko\\",\\"fr\\",\\"ja\\",\\"pt\\",\\"tr\\",\\"pl\\",\\"ca\\",\\"nl\\",\\"ar\\",\\"sv\\",\\"it\\",\\"id\\",\\"hi\\",\\"fi\\",\\"vi\\",\\"he\\",\\"uk\\",\\"el\\",\\"ms\\",\\"cs\\",\\"ro\\",\\"da\\",\\"hu\\",\\"ta\\",\\"no\\",\\"th\\",\\"ur\\",\\"hr\\",\\"bg\\",\\"lt\\",\\"la\\",\\"mi\\",\\"ml\\",\\"cy\\",\\"sk\\",\\"te\\",\\"fa\\",\\"lv\\",\\"bn\\",\\"sr\\",\\"az\\",\\"sl\\",\\"kn\\",\\"et\\",\\"mk\\",\\"br\\",\\"eu\\",\\"is\\",\\"hy\\",\\"ne\\",\\"mn\\",\\"bs\\",\\"kk\\",\\"sq\\",\\"sw\\",\\"gl\\",\\"mr\\",\\"pa\\",\\"si\\",\\"km\\",\\"sn\\",\\"yo\\",\\"so\\",\\"af\\",\\"oc\\",\\"ka\\",\\"be\\",\\"tg\\",\\"sd\\",\\"gu\\",\\"am\\",\\"yi\\",\\"lo\\",\\"uz\\",\\"fo\\",\\"ht\\",\\"ps\\",\\"tk\\",\\"nn\\",\\"mt\\",\\"sa\\",\\"lb\\",\\"my\\",\\"bo\\",\\"tl\\",\\"mg\\",\\"as\\",\\"tt\\",\\"haw\\",\\"ln\\",\\"ha\\",\\"ba\\",\\"jv\\",\\"su\\",\\"yue\\"\],\\"type\\":\\"string\\"}\],\\"description\\":\\"The language of the input audio. Supplying the input language in \[ISO-639-1\](https://en.wikipedia.org/wiki/List\_of\_ISO\_639-1\_codes) format will improve accuracy and latency.\\\\n\\"},\\"model\\":{\\"anyOf\\":\[{\\"type\\":\\"string\\"},{\\"enum\\":\[\\"whisper-large-v3\\",\\"whisper-large-v3-turbo\\"\],\\"type\\":\\"string\\"}\],\\"description\\":\\"ID of the model to use. \`whisper-large-v3\` and \`whisper-large-v3-turbo\` are currently available.\\\\n\\",\\"example\\":\\"whisper-large-v3-turbo\\"},\\"prompt\\":{\\"description\\":\\"An optional text to guide the model's style or continue a previous audio segment. The \[prompt\](/docs/speech-text) should match the audio language.\\\\n\\",\\"type\\":\\"string\\"},\\"response\_format\\":{\\"default\\":\\"json\\",\\"description\\":\\"The format of the transcript output, in one of these options: \`json\`, \`text\`, or \`verbose\_json\`.\\\\n\\",\\"enum\\":\[\\"json\\",\\"text\\",\\"verbose\_json\\"\],\\"type\\":\\"string\\"},\\"temperature\\":{\\"default\\":0,\\"description\\":\\"The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use \[log probability\](https://en.wikipedia.org/wiki/Log\_probability) to automatically increase the temperature until certain thresholds are hit.\\\\n\\",\\"type\\":\\"number\\"},\\"timestamp\_granularities\[\]\\":{\\"default\\":\[\\"segment\\"\],\\"description\\":\\"The timestamp granularities to populate for this transcription. \`response\_format\` must be set \`verbose\_json\` to use timestamp granularities. Either or both of these options are supported: \`word\`, or \`segment\`. Note: There is no additional latency for segment timestamps, but generating word timestamps incurs additional latency.\\\\n\\",\\"items\\":{\\"enum\\":\[\\"word\\",\\"segment\\"\],\\"type\\":\\"string\\"},\\"type\\":\\"array\\"},\\"url\\":{\\"description\\":\\"The audio URL to translate/transcribe (supports Base64URL).\\\\nEither a file or a URL must be provided. For Batch API requests, the URL field is required since the file field is not supported.\\\\n\\",\\"type\\":\\"string\\"}},\\"required\\":\[\\"model\\"\],\\"type\\":\\"object\\"},\\"CreateTranscriptionResponseJson\\":{\\"description\\":\\"Represents a transcription response returned by model, based on the provided input.\\",\\"properties\\":{\\"text\\":{\\"description\\":\\"The transcribed text.\\",\\"type\\":\\"string\\"}},\\"required\\":\[\\"text\\"\],\\"type\\":\\"object\\"},\\"CreateTranscriptionResponseVerboseJson\\":{\\"description\\":\\"Represents a verbose json transcription response returned by model, based on the provided input.\\",\\"properties\\":{\\"duration\\":{\\"description\\":\\"The duration of the input audio.\\",\\"type\\":\\"string\\"},\\"language\\":{\\"description\\":\\"The language of the input audio.\\",\\"type\\":\\"string\\"},\\"segments\\":{\\"description\\":\\"Segments of the transcribed text and their corresponding details.\\",\\"items\\":{\\"$ref\\":\\"#/components/schemas/TranscriptionSegment\\"},\\"type\\":\\"array\\"},\\"text\\":{\\"description\\":\\"The transcribed text.\\",\\"type\\":\\"string\\"},\\"words\\":{\\"description\\":\\"Extracted words and their corresponding timestamps.\\",\\"items\\":{\\"$ref\\":\\"#/components/schemas/TranscriptionWord\\"},\\"type\\":\\"array\\"}},\\"required\\":\[\\"language\\",\\"duration\\",\\"text\\"\],\\"type\\":\\"object\\"},\\"CreateTranslationRequest\\":{\\"additionalProperties\\":false,\\"oneOf\\":\[{\\"required\\":\[\\"file\\"\]},{\\"required\\":\[\\"url\\"\]}\],\\"properties\\":{\\"file\\":{\\"description\\":\\"The audio file object (not file name) translate, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.\\\\n\\",\\"format\\":\\"binary\\",\\"type\\":\\"string\\"},\\"model\\":{\\"anyOf\\":\[{\\"type\\":\\"string\\"},{\\"enum\\":\[\\"whisper-large-v3\\",\\"whisper-large-v3-turbo\\"\],\\"type\\":\\"string\\"}\],\\"description\\":\\"ID of the model to use. \`whisper-large-v3\` and \`whisper-large-v3-turbo\` are currently available.\\\\n\\",\\"example\\":\\"whisper-large-v3-turbo\\"},\\"prompt\\":{\\"description\\":\\"An optional text to guide the model's style or continue a previous audio segment. The \[prompt\](/docs/guides/speech-to-text/prompting) should be in English.\\\\n\\",\\"type\\":\\"string\\"},\\"response\_format\\":{\\"default\\":\\"json\\",\\"description\\":\\"The format of the transcript output, in one of these options: \`json\`, \`text\`, or \`verbose\_json\`.\\\\n\\",\\"enum\\":\[\\"json\\",\\"text\\",\\"verbose\_json\\"\],\\"type\\":\\"string\\"},\\"temperature\\":{\\"default\\":0,\\"description\\":\\"The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use \[log probability\](https://en.wikipedia.org/wiki/Log\_probability) to automatically increase the temperature until certain thresholds are hit.\\\\n\\",\\"type\\":\\"number\\"},\\"url\\":{\\"description\\":\\"The audio URL to translate/transcribe (supports Base64URL). Either file or url must be provided.\\\\nWhen using the Batch API only url is supported.\\\\n\\",\\"type\\":\\"string\\"}},\\"required\\":\[\\"model\\"\],\\"type\\":\\"object\\"},\\"CreateTranslationResponseJson\\":{\\"properties\\":{\\"text\\":{\\"type\\":\\"string\\"}},\\"required\\":\[\\"text\\"\],\\"type\\":\\"object\\"},\\"CreateTranslationResponseVerboseJson\\":{\\"properties\\":{\\"duration\\":{\\"description\\":\\"The duration of the input audio.\\",\\"type\\":\\"string\\"},\\"language\\":{\\"description\\":\\"The language of the output translation (always \`english\`).\\",\\"type\\":\\"string\\"},\\"segments\\":{\\"description\\":\\"Segments of the translated text and their corresponding details.\\",\\"items\\":{\\"$ref\\":\\"#/components/schemas/TranscriptionSegment\\"},\\"type\\":\\"array\\"},\\"text\\":{\\"description\\":\\"The translated text.\\",\\"type\\":\\"string\\"}},\\"required\\":\[\\"language\\",\\"duration\\",\\"text\\"\],\\"type\\":\\"object\\"},\\"DeleteFileResponse\\":{\\"properties\\":{\\"deleted\\":{\\"type\\":\\"boolean\\"},\\"id\\":{\\"type\\":\\"string\\"},\\"object\\":{\\"enum\\":\[\\"file\\"\],\\"type\\":\\"string\\",\\"x-stainless-const\\":true}},\\"required\\":\[\\"id\\",\\"object\\",\\"deleted\\"\],\\"type\\":\\"object\\"},\\"DeleteFineTuningResponse\\":{\\"properties\\":{\\"deleted\\":{\\"type\\":\\"boolean\\"},\\"id\\":{\\"type\\":\\"string\\"},\\"object\\":{\\"type\\":\\"string\\"}},\\"type\\":\\"object\\"},\\"DeleteModelResponse\\":{\\"properties\\":{\\"deleted\\":{\\"type\\":\\"boolean\\"},\\"id\\":{\\"type\\":\\"string\\"},\\"object\\":{\\"type\\":\\"string\\"}},\\"required\\":\[\\"id\\",\\"object\\",\\"deleted\\"\],\\"type\\":\\"object\\"},\\"DocumentCitation\\":{\\"additionalProperties\\":false,\\"description\\":\\"A citation referencing a specific document that was provided in the request.\\",\\"properties\\":{\\"document\_id\\":{\\"description\\":\\"The ID of the document being cited, corresponding to a document provided in the request.\\",\\"type\\":\\"string\\"},\\"end\_index\\":{\\"description\\":\\"The character index in the message content where this citation ends.\\",\\"type\\":\\"integer\\"},\\"start\_index\\":{\\"description\\":\\"The character index in the message content where this citation begins.\\",\\"type\\":\\"integer\\"}},\\"required\\":\[\\"start\_index\\",\\"end\_index\\",\\"document\_id\\"\],\\"type\\":\\"object\\"},\\"Embedding\\":{\\"description\\":\\"Represents an embedding vector returned by embedding endpoint.\\\\n\\",\\"properties\\":{\\"embedding\\":{\\"oneOf\\":\[{\\"description\\":\\"The embedding vector, which is a list of floats. The length of vector depends on the model as listed in the \[embedding guide\](/docs/guides/embeddings).\\\\n\\",\\"items\\":{\\"type\\":\\"number\\"},\\"type\\":\\"array\\"},{\\"description\\":\\"The embedding vector, which is a base64 encoded string. The length of vector depends on the model as listed in the \[embedding guide\](/docs/guides/embeddings).\\\\n\\",\\"type\\":\\"string\\"}\]},\\"index\\":{\\"description\\":\\"The index of the embedding in the list of embeddings.\\",\\"type\\":\\"integer\\"},\\"object\\":{\\"description\\":\\"The object type, which is always \\\\\\"embedding\\\\\\".\\",\\"enum\\":\[\\"embedding\\"\],\\"type\\":\\"string\\"}},\\"required\\":\[\\"index\\",\\"object\\",\\"embedding\\"\],\\"type\\":\\"object\\"},\\"Error\\":{\\"properties\\":{\\"code\\":{\\"nullable\\":true,\\"type\\":\\"string\\"},\\"message\\":{\\"type\\":\\"string\\"},\\"param\\":{\\"nullable\\":true,\\"type\\":\\"string\\"},\\"type\\":{\\"type\\":\\"string\\"}},\\"required\\":\[\\"type\\",\\"message\\",\\"param\\",\\"code\\"\],\\"type\\":\\"object\\"},\\"ErrorResponse\\":{\\"properties\\":{\\"error\\":{\\"$ref\\":\\"#/components/schemas/Error\\"}},\\"required\\":\[\\"error\\"\],\\"type\\":\\"object\\"},\\"File\\":{\\"description\\":\\"The \`File\` object represents a document that has been uploaded.\\",\\"properties\\":{\\"bytes\\":{\\"description\\":\\"The size of the file, in bytes.\\",\\"type\\":\\"integer\\"},\\"created\_at\\":{\\"description\\":\\"The Unix timestamp (in seconds) for when the file was created.\\",\\"type\\":\\"integer\\"},\\"filename\\":{\\"description\\":\\"The name of the file.\\",\\"type\\":\\"string\\"},\\"id\\":{\\"description\\":\\"The file identifier, which can be referenced in the API endpoints.\\",\\"type\\":\\"string\\"},\\"object\\":{\\"description\\":\\"The object type, which is always \`file\`.\\",\\"enum\\":\[\\"file\\"\],\\"type\\":\\"string\\",\\"x-stainless-const\\":true},\\"purpose\\":{\\"description\\":\\"The intended purpose of the file. Supported values are \`batch\`, and \`batch\_output\`.\\",\\"enum\\":\[\\"batch\\",\\"batch\_output\\"\],\\"type\\":\\"string\\"}},\\"title\\":\\"File\\"},\\"FunctionCitation\\":{\\"additionalProperties\\":false,\\"description\\":\\"A citation referencing the result of a function or tool call.\\",\\"properties\\":{\\"end\_index\\":{\\"description\\":\\"The character index in the message content where this citation ends.\\",\\"type\\":\\"integer\\"},\\"start\_index\\":{\\"description\\":\\"The character index in the message content where this citation begins.\\",\\"type\\":\\"integer\\"},\\"tool\_call\_id\\":{\\"description\\":\\"The ID of the tool call being cited, corresponding to a tool call made during the conversation.\\",\\"type\\":\\"string\\"}},\\"required\\":\[\\"start\_index\\",\\"end\_index\\",\\"tool\_call\_id\\"\],\\"type\\":\\"object\\"},\\"FunctionObject\\":{\\"properties\\":{\\"description\\":{\\"description\\":\\"A description of what the function does, used by the model to choose when and how to call the function.\\",\\"type\\":\\"string\\"},\\"name\\":{\\"description\\":\\"The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.\\",\\"type\\":\\"string\\"},\\"parameters\\":{\\"$ref\\":\\"#/components/schemas/FunctionParameters\\"},\\"strict\\":{\\"default\\":false,\\"description\\":\\"Whether to enable strict schema adherence when generating the output. If set to true, the model will always follow the exact schema defined in the \`schema\` field. Only a subset of JSON Schema is supported when \`strict\` is \`true\`.\\\\n\\",\\"type\\":\\"boolean\\"}},\\"required\\":\[\\"name\\"\],\\"type\\":\\"object\\"},\\"FunctionParameters\\":{\\"additionalProperties\\":true,\\"description\\":\\"Function parameters defined as a JSON Schema object. Refer to https://json-schema.org/understanding-json-schema/ for schema documentation.\\",\\"type\\":\\"object\\"},\\"ListBatchesResponse\\":{\\"properties\\":{\\"data\\":{\\"items\\":{\\"$ref\\":\\"#/components/schemas/Batch\\"},\\"type\\":\\"array\\"},\\"object\\":{\\"enum\\":\[\\"list\\"\],\\"type\\":\\"string\\",\\"x-stainless-const\\":true}},\\"required\\":\[\\"object\\",\\"data\\"\],\\"type\\":\\"object\\"},\\"ListFilesResponse\\":{\\"properties\\":{\\"data\\":{\\"items\\":{\\"$ref\\":\\"#/components/schemas/File\\"},\\"type\\":\\"array\\"},\\"object\\":{\\"enum\\":\[\\"list\\"\],\\"type\\":\\"string\\"}},\\"required\\":\[\\"object\\",\\"data\\"\],\\"type\\":\\"object\\"},\\"ListFineTuningsResponse\\":{\\"properties\\":{\\"data\\":{\\"items\\":{\\"properties\\":{\\"base\_model\\":{\\"description\\":\\"BaseModel is the model that the fine tune was originally trained on.\\\\n\\",\\"type\\":\\"string\\"},\\"created\_at\\":{\\"description\\":\\"CreatedAt is the timestamp of when the fine tuned model was created.\\\\n\\",\\"type\\":\\"number\\"},\\"fine\_tuned\_model\\":{\\"description\\":\\"FineTunedModel is the final name of the fine tuned model.\\\\n\\",\\"type\\":\\"string\\"},\\"id\\":{\\"description\\":\\"ID is the unique identifier of a fine tune.\\\\n\\",\\"type\\":\\"string\\"},\\"input\_file\_id\\":{\\"description\\":\\"InputFileID is the id of the file that was uploaded via the /files api.\\\\n\\",\\"type\\":\\"string\\"},\\"name\\":{\\"description\\":\\"Name is the given name to a fine tuned model.\\\\n\\",\\"type\\":\\"string\\"},\\"type\\":{\\"description\\":\\"Type is the type of fine tuning format such as \\\\\\"lora\\\\\\".\\\\n\\",\\"type\\":\\"string\\"}},\\"type\\":\\"object\\"},\\"type\\":\\"array\\"},\\"object\\":{\\"type\\":\\"string\\"}},\\"type\\":\\"object\\"},\\"ListModelsResponse\\":{\\"properties\\":{\\"data\\":{\\"items\\":{\\"$ref\\":\\"#/components/schemas/Model\\"},\\"type\\":\\"array\\"},\\"object\\":{\\"enum\\":\[\\"list\\"\],\\"type\\":\\"string\\"}},\\"required\\":\[\\"object\\",\\"data\\"\],\\"type\\":\\"object\\"},\\"Model\\":{\\"description\\":\\"Describes an OpenAI model offering that can be used with the API.\\",\\"properties\\":{\\"created\\":{\\"description\\":\\"The Unix timestamp (in seconds) when the model was created.\\",\\"type\\":\\"integer\\"},\\"id\\":{\\"description\\":\\"The model identifier, which can be referenced in the API endpoints.\\",\\"type\\":\\"string\\"},\\"object\\":{\\"description\\":\\"The object type, which is always \\\\\\"model\\\\\\".\\",\\"enum\\":\[\\"model\\"\],\\"type\\":\\"string\\"},\\"owned\_by\\":{\\"description\\":\\"The organization that owns the model.\\",\\"type\\":\\"string\\"}},\\"required\\":\[\\"id\\",\\"object\\",\\"created\\",\\"owned\_by\\"\],\\"title\\":\\"Model\\"},\\"ReadFineTuningResponse\\":{\\"properties\\":{\\"data\\":{\\"properties\\":{\\"base\_model\\":{\\"description\\":\\"BaseModel is the model that the fine tune was originally trained on.\\\\n\\",\\"type\\":\\"string\\"},\\"created\_at\\":{\\"description\\":\\"CreatedAt is the timestamp of when the fine tuned model was created.\\\\n\\",\\"type\\":\\"number\\"},\\"fine\_tuned\_model\\":{\\"description\\":\\"FineTunedModel is the final name of the fine tuned model.\\\\n\\",\\"type\\":\\"string\\"},\\"id\\":{\\"description\\":\\"ID is the unique identifier of a fine tune.\\\\n\\",\\"type\\":\\"string\\"},\\"input\_file\_id\\":{\\"description\\":\\"InputFileID is the id of the file that was uploaded via the /files api.\\\\n\\",\\"type\\":\\"string\\"},\\"name\\":{\\"description\\":\\"Name is the given name to a fine tuned model.\\\\n\\",\\"type\\":\\"string\\"},\\"type\\":{\\"description\\":\\"Type is the type of fine tuning format such as \\\\\\"lora\\\\\\".\\\\n\\",\\"type\\":\\"string\\"}},\\"type\\":\\"object\\"},\\"id\\":{\\"type\\":\\"string\\"},\\"object\\":{\\"type\\":\\"string\\"}},\\"type\\":\\"object\\"},\\"RerankingRequest\\":{\\"additionalProperties\\":false,\\"properties\\":{\\"docs\\":{\\"description\\":\\"An array of documents to rank. Each document is a string containing the text content.\\\\nMaximum of 100 documents per request.\\\\n\\",\\"example\\":\[\\"Machine learning is a subset of artificial intelligence\\",\\"The weather forecast predicts rain tomorrow\\",\\"Deep learning uses neural networks with multiple layers\\"\],\\"items\\":{\\"minLength\\":1,\\"type\\":\\"string\\"},\\"maxItems\\":100,\\"minItems\\":1,\\"type\\":\\"array\\"},\\"instruction\\":{\\"description\\":\\"Optional instruction to guide the reranking process. If not provided, \\\\na default instruction will be used.\\\\n\\",\\"example\\":\\"Find the most relevant document about AI research\\",\\"nullable\\":true,\\"type\\":\\"string\\"},\\"model\\":{\\"description\\":\\"ID of the reranking model to use.\\\\n\\",\\"example\\":\\"qwen3-reranker-4b\\",\\"type\\":\\"string\\"},\\"query\\":{\\"description\\":\\"The search query to rank documents against.\\\\n\\",\\"example\\":\\"artificial intelligence research\\",\\"type\\":\\"string\\"}},\\"required\\":\[\\"model\\",\\"query\\",\\"docs\\"\],\\"type\\":\\"object\\"},\\"RerankingResponse\\":{\\"properties\\":{\\"results\\":{\\"description\\":\\"List of documents sorted by relevance score in descending order.\\\\nEach result contains the original document text and its relevance score.\\\\n\\",\\"items\\":{\\"$ref\\":\\"#/components/schemas/RerankingResult\\"},\\"type\\":\\"array\\"}},\\"required\\":\[\\"results\\"\],\\"type\\":\\"object\\"},\\"RerankingResult\\":{\\"properties\\":{\\"doc\\":{\\"description\\":\\"The original document text.\\",\\"example\\":\\"Machine learning is a subset of artificial intelligence\\",\\"type\\":\\"string\\"},\\"score\\":{\\"description\\":\\"Relevance score between 0.0 and 1.0, where higher scores indicate \\\\ngreater relevance to the query.\\\\n\\",\\"example\\":0.92,\\"format\\":\\"float\\",\\"maximum\\":1,\\"minimum\\":0,\\"type\\":\\"number\\"}},\\"required\\":\[\\"doc\\",\\"score\\"\],\\"type\\":\\"object\\"},\\"ResponseAnnotation\\":{\\"discriminator\\":{\\"mapping\\":{\\"file\_citation\\":\\"#/components/schemas/ResponseFileCitation\\",\\"url\_citation\\":\\"#/components/schemas/ResponseUrlCitation\\"},\\"propertyName\\":\\"type\\"},\\"oneOf\\":\[{\\"$ref\\":\\"#/components/schemas/ResponseFileCitation\\"},{\\"$ref\\":\\"#/components/schemas/ResponseUrlCitation\\"}\]},\\"ResponseEasyInputMessage\\":{\\"description\\":\\"A message input to the model with a role indicating instruction following hierarchy.\\\\n\\",\\"properties\\":{\\"content\\":{\\"description\\":\\"Text input to the model.\\\\n\\",\\"oneOf\\":\[{\\"description\\":\\"A text input to the model.\\",\\"title\\":\\"Text input\\",\\"type\\":\\"string\\"},{\\"description\\":\\"An array of content parts.\\",\\"items\\":{\\"$ref\\":\\"#/components/schemas/ResponseInputContent\\"},\\"title\\":\\"Content array\\",\\"type\\":\\"array\\"}\]},\\"role\\":{\\"description\\":\\"The role of the message input. One of \`user\`, \`assistant\`, \`system\`, or \`developer\`.\\\\n\\",\\"enum\\":\[\\"user\\",\\"assistant\\",\\"system\\",\\"developer\\"\],\\"type\\":\\"string\\"}},\\"required\\":\[\\"role\\",\\"content\\"\],\\"title\\":\\"Easy input message\\",\\"type\\":\\"object\\"},\\"ResponseFileCitation\\":{\\"description\\":\\"A citation to a file.\\",\\"properties\\":{\\"file\_id\\":{\\"description\\":\\"The ID of the file.\\",\\"type\\":\\"string\\"},\\"index\\":{\\"description\\":\\"The index of the citation in the text.\\",\\"type\\":\\"integer\\"},\\"type\\":{\\"description\\":\\"The type of the annotation. Always \`file\_citation\`.\\",\\"enum\\":\[\\"file\_citation\\"\],\\"type\\":\\"string\\",\\"x-stainless-const\\":true}},\\"required\\":\[\\"type\\",\\"file\_id\\"\],\\"title\\":\\"File citation\\",\\"type\\":\\"object\\"},\\"ResponseFormatConfiguration\\":{\\"description\\":\\"An object specifying the format that the model must output.\\\\n\\",\\"oneOf\\":\[{\\"$ref\\":\\"#/components/schemas/ResponseFormatText\\"},{\\"$ref\\":\\"#/components/schemas/ResponseFormatJsonObject\\"},{\\"$ref\\":\\"#/components/schemas/TextResponseFormatJsonSchema\\"}\]},\\"ResponseFormatJsonObject\\":{\\"description\\":\\"JSON object response format. An older method of generating JSON responses. Using \`json\_schema\` is recommended for models that support it. Note that the model will not generate JSON without a system or user message instructing it to do so.\\\\n\\",\\"properties\\":{\\"type\\":{\\"description\\":\\"The type of response format being defined. Always \`json\_object\`.\\",\\"enum\\":\[\\"json\_object\\"\],\\"type\\":\\"string\\",\\"x-stainless-const\\":true}},\\"required\\":\[\\"type\\"\],\\"title\\":\\"JSON object\\",\\"type\\":\\"object\\"},\\"ResponseFormatJsonSchema\\":{\\"description\\":\\"JSON Schema response format. Used to generate structured JSON responses.\\\\n\\",\\"properties\\":{\\"json\_schema\\":{\\"description\\":\\"Structured Outputs configuration options, including a JSON Schema.\\\\n\\",\\"properties\\":{\\"description\\":{\\"description\\":\\"A description of what the response format is for, used by the model to determine how to respond in the format.\\\\n\\",\\"type\\":\\"string\\"},\\"name\\":{\\"description\\":\\"The name of the response format. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.\\\\n\\",\\"type\\":\\"string\\"},\\"schema\\":{\\"$ref\\":\\"#/components/schemas/ResponseFormatJsonSchemaSchema\\"},\\"strict\\":{\\"default\\":false,\\"description\\":\\"Whether to enable strict schema adherence when generating the output. If set to true, the model will always follow the exact schema defined in the \`schema\` field. Only a subset of JSON Schema is supported when \`strict\` is \`true\`.\\\\n\\",\\"nullable\\":true,\\"type\\":\\"boolean\\"}},\\"required\\":\[\\"name\\"\],\\"title\\":\\"JSON schema\\",\\"type\\":\\"object\\"},\\"type\\":{\\"description\\":\\"The type of response format being defined. Always \`json\_schema\`.\\",\\"enum\\":\[\\"json\_schema\\"\],\\"type\\":\\"string\\",\\"x-stainless-const\\":true}},\\"required\\":\[\\"type\\",\\"json\_schema\\"\],\\"title\\":\\"JSON schema\\",\\"type\\":\\"object\\"},\\"ResponseFormatJsonSchemaSchema\\":{\\"additionalProperties\\":true,\\"description\\":\\"The schema for the response format, described as a JSON Schema object.\\\\nLearn how to build JSON schemas \[here\](https://json-schema.org/).\\\\n\\",\\"title\\":\\"JSON schema\\",\\"type\\":\\"object\\"},\\"ResponseFormatText\\":{\\"description\\":\\"Default response format. Used to generate text responses.\\\\n\\",\\"properties\\":{\\"type\\":{\\"description\\":\\"The type of response format being defined. Always \`text\`.\\",\\"enum\\":\[\\"text\\"\],\\"type\\":\\"string\\",\\"x-stainless-const\\":true}},\\"required\\":\[\\"type\\"\],\\"title\\":\\"Text\\",\\"type\\":\\"object\\"},\\"ResponseFunctionCall\\":{\\"description\\":\\"A function call generated by the model.\\",\\"properties\\":{\\"arguments\\":{\\"description\\":\\"A JSON string of the arguments to pass to the function.\\",\\"type\\":\\"string\\"},\\"call\_id\\":{\\"description\\":\\"The unique ID of the function tool call generated by the model.\\",\\"type\\":\\"string\\"},\\"id\\":{\\"description\\":\\"The unique ID of the function tool call.\\",\\"type\\":\\"string\\"},\\"name\\":{\\"description\\":\\"The name of the function to call.\\",\\"type\\":\\"string\\"},\\"status\\":{\\"description\\":\\"The status of the item.\\",\\"enum\\":\[\\"in\_progress\\",\\"completed\\",\\"incomplete\\"\],\\"type\\":\\"string\\"},\\"type\\":{\\"description\\":\\"The type of the function call. Always \`function\_call\`.\\",\\"enum\\":\[\\"function\_call\\"\],\\"type\\":\\"string\\",\\"x-stainless-const\\":true}},\\"required\\":\[\\"type\\",\\"call\_id\\",\\"name\\",\\"arguments\\"\],\\"title\\":\\"Function call\\",\\"type\\":\\"object\\"},\\"ResponseFunctionCallOutput\\":{\\"description\\":\\"The output of a function tool call.\\",\\"properties\\":{\\"call\_id\\":{\\"description\\":\\"The unique ID of the function tool call generated by the model.\\",\\"type\\":\\"string\\"},\\"id\\":{\\"description\\":\\"The unique ID of the function tool call output.\\",\\"type\\":\\"string\\"},\\"output\\":{\\"description\\":\\"A JSON string of the output of the function tool call.\\",\\"type\\":\\"string\\"},\\"status\\":{\\"description\\":\\"The status of the item.\\",\\"enum\\":\[\\"in\_progress\\",\\"completed\\",\\"incomplete\\"\],\\"type\\":\\"string\\"},\\"type\\":{\\"description\\":\\"The type of the function tool call output. Always \`function\_call\_output\`.\\",\\"enum\\":\[\\"function\_call\_output\\"\],\\"type\\":\\"string\\",\\"x-stainless-const\\":true}},\\"required\\":\[\\"type\\",\\"call\_id\\",\\"output\\"\],\\"title\\":\\"Function call output\\",\\"type\\":\\"object\\"},\\"ResponseInputContent\\":{\\"discriminator\\":{\\"mapping\\":{\\"input\_text\\":\\"#/components/schemas/ResponseInputTextContent\\"},\\"propertyName\\":\\"type\\"},\\"oneOf\\":\[{\\"$ref\\":\\"#/components/schemas/ResponseInputTextContent\\"}\]},\\"ResponseInputItem\\":{\\"discriminator\\":{\\"mapping\\":{\\"function\_call\\":\\"#/components/schemas/ResponseFunctionCall\\",\\"function\_call\_output\\":\\"#/components/schemas/ResponseFunctionCallOutput\\",\\"item\_reference\\":\\"#/components/schemas/ResponseItemReference\\",\\"message\\":\\"#/components/schemas/ResponseInputMessage\\"},\\"propertyName\\":\\"type\\"},\\"oneOf\\":\[{\\"$ref\\":\\"#/components/schemas/ResponseEasyInputMessage\\"},{\\"$ref\\":\\"#/components/schemas/ResponseInputMessage\\"},{\\"$ref\\":\\"#/components/schemas/ResponseItemReference\\"},{\\"$ref\\":\\"#/components/schemas/ResponseFunctionCall\\"},{\\"$ref\\":\\"#/components/schemas/ResponseFunctionCallOutput\\"}\]},\\"ResponseInputMessage\\":{\\"description\\":\\"A message input to the model with explicit type field.\\\\n\\",\\"properties\\":{\\"content\\":{\\"description\\":\\"A list of one or many input content items.\\",\\"items\\":{\\"$ref\\":\\"#/components/schemas/ResponseInputContent\\"},\\"type\\":\\"array\\"},\\"role\\":{\\"description\\":\\"The role of the message input. One of \`user\`, \`system\`, or \`developer\`. Note: assistant role is not supported with explicit type.\\\\n\\",\\"enum\\":\[\\"user\\",\\"system\\",\\"developer\\"\],\\"type\\":\\"string\\"},\\"status\\":{\\"description\\":\\"The status of item. Populated when items are returned via API.\\",\\"enum\\":\[\\"in\_progress\\",\\"completed\\",\\"incomplete\\"\],\\"type\\":\\"string\\"},\\"type\\":{\\"description\\":\\"The type of the message input. Always set to \`message\`.\\",\\"enum\\":\[\\"message\\"\],\\"type\\":\\"string\\",\\"x-stainless-const\\":true}},\\"required\\":\[\\"type\\",\\"role\\",\\"content\\"\],\\"title\\":\\"Input message\\",\\"type\\":\\"object\\"},\\"ResponseInputTextContent\\":{\\"description\\":\\"A text input to the model.\\",\\"properties\\":{\\"text\\":{\\"description\\":\\"The text input to the model.\\",\\"type\\":\\"string\\"},\\"type\\":{\\"description\\":\\"The type of the input item. Always \`input\_text\`.\\",\\"enum\\":\[\\"input\_text\\"\],\\"type\\":\\"string\\",\\"x-stainless-const\\":true}},\\"required\\":\[\\"type\\",\\"text\\"\],\\"title\\":\\"Input text\\",\\"type\\":\\"object\\"},\\"ResponseItemReference\\":{\\"description\\":\\"An internal identifier for an item to reference.\\",\\"properties\\":{\\"id\\":{\\"description\\":\\"The ID of the item to reference.\\",\\"type\\":\\"string\\"},\\"type\\":{\\"description\\":\\"The type of item to reference. Always \`item\_reference\`.\\",\\"enum\\":\[\\"item\_reference\\"\],\\"type\\":\\"string\\",\\"x-stainless-const\\":true}},\\"required\\":\[\\"type\\",\\"id\\"\],\\"title\\":\\"Item reference\\",\\"type\\":\\"object\\"},\\"ResponseNamedToolChoice\\":{\\"description\\":\\"Specifies a tool the model should use. Use to force the model to call a specific function.\\",\\"properties\\":{\\"function\\":{\\"properties\\":{\\"name\\":{\\"description\\":\\"The name of the function to call.\\",\\"type\\":\\"string\\"}},\\"required\\":\[\\"name\\"\],\\"type\\":\\"object\\"},\\"type\\":{\\"description\\":\\"The type of the tool. Currently, only \`function\` is supported.\\",\\"enum\\":\[\\"function\\"\],\\"type\\":\\"string\\"}},\\"required\\":\[\\"type\\",\\"function\\"\],\\"type\\":\\"object\\"},\\"ResponseOutputContent\\":{\\"discriminator\\":{\\"mapping\\":{\\"output\_text\\":\\"#/components/schemas/ResponseOutputTextContent\\"},\\"propertyName\\":\\"type\\"},\\"oneOf\\":\[{\\"$ref\\":\\"#/components/schemas/ResponseOutputTextContent\\"}\]},\\"ResponseOutputFunctionCall\\":{\\"description\\":\\"A function call generated by the model.\\",\\"properties\\":{\\"arguments\\":{\\"description\\":\\"A JSON string of the arguments to pass to the function.\\",\\"type\\":\\"string\\"},\\"call\_id\\":{\\"description\\":\\"The unique ID of the function tool call generated by the model.\\",\\"type\\":\\"string\\"},\\"id\\":{\\"description\\":\\"The unique ID of the function tool call.\\",\\"type\\":\\"string\\"},\\"name\\":{\\"description\\":\\"The name of the function to call.\\",\\"type\\":\\"string\\"},\\"status\\":{\\"description\\":\\"The status of the function call.\\",\\"enum\\":\[\\"in\_progress\\",\\"completed\\",\\"incomplete\\"\],\\"type\\":\\"string\\"},\\"type\\":{\\"description\\":\\"The type of the function call. Always \`function\_call\`.\\",\\"enum\\":\[\\"function\_call\\"\],\\"type\\":\\"string\\",\\"x-stainless-const\\":true}},\\"required\\":\[\\"type\\",\\"id\\",\\"call\_id\\",\\"name\\",\\"arguments\\"\],\\"title\\":\\"Function call\\",\\"type\\":\\"object\\"},\\"ResponseOutputItem\\":{\\"discriminator\\":{\\"mapping\\":{\\"function\_call\\":\\"#/components/schemas/ResponseOutputFunctionCall\\",\\"message\\":\\"#/components/schemas/ResponseOutputMessage\\",\\"reasoning\\":\\"#/components/schemas/ResponseOutputReasoning\\"},\\"propertyName\\":\\"type\\"},\\"oneOf\\":\[{\\"$ref\\":\\"#/components/schemas/ResponseOutputMessage\\"},{\\"$ref\\":\\"#/components/schemas/ResponseOutputFunctionCall\\"},{\\"$ref\\":\\"#/components/schemas/ResponseOutputReasoning\\"}\]},\\"ResponseOutputMessage\\":{\\"description\\":\\"An output message from the model.\\",\\"properties\\":{\\"content\\":{\\"description\\":\\"The content of the output message.\\",\\"items\\":{\\"$ref\\":\\"#/components/schemas/ResponseOutputContent\\"},\\"type\\":\\"array\\"},\\"id\\":{\\"description\\":\\"The unique ID of the output message.\\",\\"type\\":\\"string\\"},\\"role\\":{\\"description\\":\\"The role of the output message. Always \`assistant\`.\\",\\"enum\\":\[\\"assistant\\"\],\\"type\\":\\"string\\",\\"x-stainless-const\\":true},\\"status\\":{\\"description\\":\\"The status of the message.\\",\\"enum\\":\[\\"in\_progress\\",\\"completed\\",\\"incomplete\\"\],\\"type\\":\\"string\\"},\\"type\\":{\\"description\\":\\"The type of the output message. Always \`message\`.\\",\\"enum\\":\[\\"message\\"\],\\"type\\":\\"string\\",\\"x-stainless-const\\":true}},\\"required\\":\[\\"type\\",\\"id\\",\\"role\\",\\"content\\"\],\\"title\\":\\"Output message\\",\\"type\\":\\"object\\"},\\"ResponseOutputReasoning\\":{\\"description\\":\\"A reasoning output from the model.\\",\\"properties\\":{\\"id\\":{\\"description\\":\\"The unique ID of the reasoning output.\\",\\"type\\":\\"string\\"},\\"summary\\":{\\"description\\":\\"Summary items (currently empty).\\",\\"items\\":{\\"type\\":\\"object\\"},\\"type\\":\\"array\\"},\\"type\\":{\\"description\\":\\"The type of the reasoning output. Always \`reasoning\`.\\",\\"enum\\":\[\\"reasoning\\"\],\\"type\\":\\"string\\",\\"x-stainless-const\\":true}},\\"required\\":\[\\"type\\",\\"id\\",\\"summary\\"\],\\"title\\":\\"Reasoning\\",\\"type\\":\\"object\\"},\\"ResponseOutputTextContent\\":{\\"description\\":\\"A text output from the model.\\",\\"properties\\":{\\"annotations\\":{\\"description\\":\\"The annotations of the text output.\\",\\"items\\":{\\"$ref\\":\\"#/components/schemas/ResponseAnnotation\\"},\\"type\\":\\"array\\"},\\"logprobs\\":{\\"description\\":\\"Log probability information for the output.\\",\\"items\\":{\\"type\\":\\"string\\"},\\"nullable\\":true,\\"type\\":\\"array\\"},\\"text\\":{\\"description\\":\\"The text output from the model.\\",\\"type\\":\\"string\\"},\\"type\\":{\\"description\\":\\"The type of the output text. Always \`output\_text\`.\\",\\"enum\\":\[\\"output\_text\\"\],\\"type\\":\\"string\\",\\"x-stainless-const\\":true}},\\"required\\":\[\\"type\\",\\"text\\",\\"annotations\\"\],\\"title\\":\\"Output text\\",\\"type\\":\\"object\\"},\\"ResponseTool\\":{\\"properties\\":{\\"description\\":{\\"description\\":\\"Describes the function's purpose. The model uses this to determine when to invoke the function.\\",\\"type\\":\\"string\\"},\\"name\\":{\\"description\\":\\"The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.\\",\\"type\\":\\"string\\"},\\"parameters\\":{\\"$ref\\":\\"#/components/schemas/FunctionParameters\\"},\\"strict\\":{\\"description\\":\\"Whether to enable strict schema adherence when generating the function call.\\",\\"nullable\\":true,\\"type\\":\\"boolean\\"},\\"type\\":{\\"description\\":\\"The type of the tool. Currently, only \`function\` is supported.\\",\\"enum\\":\[\\"function\\"\],\\"type\\":\\"string\\"}},\\"required\\":\[\\"type\\",\\"name\\"\],\\"type\\":\\"object\\"},\\"ResponseToolChoiceOption\\":{\\"description\\":\\"Controls which (if any) tool is called by the model.\\\\n\`none\` means the model will not call any tool and instead generates a message.\\\\n\`auto\` means the model can pick between generating a message or calling one or more tools.\\\\n\`required\` means the model must call one or more tools.\\\\nSpecifying a particular tool via \`{\\\\\\"type\\\\\\": \\\\\\"function\\\\\\", \\\\\\"function\\\\\\": {\\\\\\"name\\\\\\": \\\\\\"my\_function\\\\\\"}}\` forces the model to call that tool.\\\\n\\\\n\`none\` is the default when no tools are present. \`auto\` is the default if tools are present.\\\\n\\",\\"nullable\\":true,\\"oneOf\\":\[{\\"description\\":\\"\`none\` means the model will not call any tool and instead generates a message. \`auto\` means the model can pick between generating a message or calling one or more tools. \`required\` means the model must call one or more tools.\\\\n\\",\\"enum\\":\[\\"none\\",\\"auto\\",\\"required\\"\],\\"type\\":\\"string\\"},{\\"$ref\\":\\"#/components/schemas/ResponseNamedToolChoice\\"}\]},\\"ResponseUrlCitation\\":{\\"description\\":\\"A citation for a web resource.\\",\\"properties\\":{\\"end\_index\\":{\\"description\\":\\"The index of the last character of the URL citation in the message.\\",\\"type\\":\\"integer\\"},\\"start\_index\\":{\\"description\\":\\"The index of the first character of the URL citation in the message.\\",\\"type\\":\\"integer\\"},\\"title\\":{\\"description\\":\\"The title of the web resource.\\",\\"type\\":\\"string\\"},\\"type\\":{\\"description\\":\\"The type of the annotation. Always \`url\_citation\`.\\",\\"enum\\":\[\\"url\_citation\\"\],\\"type\\":\\"string\\",\\"x-stainless-const\\":true},\\"url\\":{\\"description\\":\\"The URL of the web resource.\\",\\"type\\":\\"string\\"}},\\"required\\":\[\\"type\\",\\"url\\"\],\\"title\\":\\"URL citation\\",\\"type\\":\\"object\\"},\\"ResponseUsage\\":{\\"description\\":\\"Usage statistics for the response request.\\",\\"properties\\":{\\"input\_tokens\\":{\\"description\\":\\"Number of tokens in the input.\\",\\"type\\":\\"integer\\"},\\"input\_tokens\_details\\":{\\"description\\":\\"Breakdown of input tokens.\\",\\"properties\\":{\\"cached\_tokens\\":{\\"description\\":\\"Number of cached tokens.\\",\\"type\\":\\"integer\\"},\\"reasoning\_tokens\\":{\\"description\\":\\"Number of reasoning tokens.\\",\\"type\\":\\"integer\\"}},\\"required\\":\[\\"cached\_tokens\\"\],\\"type\\":\\"object\\"},\\"output\_tokens\\":{\\"description\\":\\"Number of tokens in the generated output.\\",\\"type\\":\\"integer\\"},\\"output\_tokens\_details\\":{\\"description\\":\\"Breakdown of output tokens.\\",\\"properties\\":{\\"cached\_tokens\\":{\\"description\\":\\"Number of cached tokens.\\",\\"type\\":\\"integer\\"},\\"reasoning\_tokens\\":{\\"description\\":\\"Number of reasoning tokens.\\",\\"type\\":\\"integer\\"}},\\"required\\":\[\\"cached\_tokens\\",\\"reasoning\_tokens\\"\],\\"type\\":\\"object\\"},\\"total\_tokens\\":{\\"description\\":\\"Total number of tokens used in the request (input + output).\\",\\"type\\":\\"integer\\"}},\\"required\\":\[\\"input\_tokens\\",\\"input\_tokens\_details\\",\\"output\_tokens\\",\\"output\_tokens\_details\\",\\"total\_tokens\\"\],\\"type\\":\\"object\\"},\\"TextResponseFormatJsonSchema\\":{\\"description\\":\\"JSON Schema response format. Used to generate structured JSON responses.\\\\n\\",\\"properties\\":{\\"description\\":{\\"description\\":\\"A description of what the response format is for, used by the model to determine how to respond in the format.\\\\n\\",\\"type\\":\\"string\\"},\\"name\\":{\\"description\\":\\"The name of the response format. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.\\\\n\\",\\"type\\":\\"string\\"},\\"schema\\":{\\"additionalProperties\\":true,\\"description\\":\\"The schema for the response format, described as a JSON Schema object.\\\\n\\",\\"type\\":\\"object\\"},\\"strict\\":{\\"default\\":false,\\"description\\":\\"Whether to enable strict schema adherence when generating the output.\\\\n\\",\\"nullable\\":true,\\"type\\":\\"boolean\\"},\\"type\\":{\\"description\\":\\"The type of response format being defined. Always \`json\_schema\`.\\",\\"enum\\":\[\\"json\_schema\\"\],\\"type\\":\\"string\\",\\"x-stainless-const\\":true}},\\"required\\":\[\\"type\\",\\"name\\",\\"schema\\"\],\\"title\\":\\"JSON schema\\",\\"type\\":\\"object\\"},\\"TranscriptionSegment\\":{\\"properties\\":{\\"avg\_logprob\\":{\\"description\\":\\"Average logprob of the segment. If the value is lower than -1, consider the logprobs failed.\\",\\"format\\":\\"float\\",\\"type\\":\\"number\\"},\\"compression\_ratio\\":{\\"description\\":\\"Compression ratio of the segment. If the value is greater than 2.4, consider the compression failed.\\",\\"format\\":\\"float\\",\\"type\\":\\"number\\"},\\"end\\":{\\"description\\":\\"End time of the segment in seconds.\\",\\"format\\":\\"float\\",\\"type\\":\\"number\\"},\\"id\\":{\\"description\\":\\"Unique identifier of the segment.\\",\\"type\\":\\"integer\\"},\\"no\_speech\_prob\\":{\\"description\\":\\"Probability of no speech in the segment. If the value is higher than 1.0 and the \`avg\_logprob\` is below -1, consider this segment silent.\\",\\"format\\":\\"float\\",\\"type\\":\\"number\\"},\\"seek\\":{\\"description\\":\\"Seek offset of the segment.\\",\\"type\\":\\"integer\\"},\\"start\\":{\\"description\\":\\"Start time of the segment in seconds.\\",\\"format\\":\\"float\\",\\"type\\":\\"number\\"},\\"temperature\\":{\\"description\\":\\"Temperature parameter used for generating the segment.\\",\\"format\\":\\"float\\",\\"type\\":\\"number\\"},\\"text\\":{\\"description\\":\\"Text content of the segment.\\",\\"type\\":\\"string\\"},\\"tokens\\":{\\"description\\":\\"Array of token IDs for the text content.\\",\\"items\\":{\\"type\\":\\"integer\\"},\\"type\\":\\"array\\"}},\\"required\\":\[\\"id\\",\\"seek\\",\\"start\\",\\"end\\",\\"text\\",\\"tokens\\",\\"temperature\\",\\"avg\_logprob\\",\\"compression\_ratio\\",\\"no\_speech\_prob\\"\],\\"type\\":\\"object\\"},\\"TranscriptionWord\\":{\\"properties\\":{\\"end\\":{\\"description\\":\\"End time of the word in seconds.\\",\\"format\\":\\"float\\",\\"type\\":\\"number\\"},\\"start\\":{\\"description\\":\\"Start time of the word in seconds.\\",\\"format\\":\\"float\\",\\"type\\":\\"number\\"},\\"word\\":{\\"description\\":\\"The text content of the word.\\",\\"type\\":\\"string\\"}},\\"required\\":\[\\"word\\",\\"start\\",\\"end\\"\],\\"type\\":\\"object\\"},\\"XGroq\\":{\\"properties\\":{\\"error\\":{\\"description\\":\\"An error string indicating why a stream was stopped early\\",\\"type\\":\\"string\\"},\\"id\\":{\\"description\\":\\"A groq request ID which can be used by to refer to a specific request to groq support\\\\nOnly sent with the first chunk\\\\n\\",\\"type\\":\\"string\\"},\\"usage\\":{\\"$ref\\":\\"#/components/schemas/CompletionUsage\\"},\\"usage\_breakdown\\":{\\"$ref\\":\\"#/components/schemas/ChatCompletionUsageBreakdown\\"}},\\"type\\":\\"object\\"}},\\"securitySchemes\\":{\\"api\_key\\":{\\"bearerFormat\\":\\"apiKey\\",\\"scheme\\":\\"bearer\\",\\"type\\":\\"http\\"}}},\\"info\\":{\\"contact\\":{\\"email\\":\\"support@groq.com\\",\\"name\\":\\"Groq Support\\"},\\"description\\":\\"Specification of the Groq cloud API\\",\\"termsOfService\\":\\"https://groq.com/terms-of-use/\\",\\"title\\":\\"GroqCloud API\\",\\"version\\":\\"2.1\\"},\\"openapi\\":\\"3.0.1\\",\\"paths\\":{\\"/openai/v1/audio/speech\\":{\\"post\\":{\\"operationId\\":\\"createSpeech\\",\\"requestBody\\":{\\"content\\":{\\"application/json\\":{\\"schema\\":{\\"$ref\\":\\"#/components/schemas/CreateSpeechRequest\\"}}},\\"required\\":true},\\"responses\\":{\\"200\\":{\\"content\\":{\\"audio/wav\\":{\\"schema\\":{\\"format\\":\\"binary\\",\\"type\\":\\"string\\"}}},\\"description\\":\\"OK\\",\\"headers\\":{\\"Transfer-Encoding\\":{\\"description\\":\\"chunked\\",\\"schema\\":{\\"type\\":\\"string\\"}}}}},\\"summary\\":\\"Generates audio from the input text.\\",\\"tags\\":\[\\"Audio\\"\],\\"x-groq-metadata\\":{\\"examples\\":\[{\\"request\\":{\\"curl\\":\\"curl https://api.groq.com/openai/v1/audio/speech \\\\\\\\\\\\n -H \\\\\\"Authorization: Bearer $GROQ\_API\_KEY\\\\\\" \\\\\\\\\\\\n -H \\\\\\"Content-Type: application/json\\\\\\" \\\\\\\\\\\\n -d '{\\\\n \\\\\\"model\\\\\\": \\\\\\"playai-tts\\\\\\",\\\\n \\\\\\"input\\\\\\": \\\\\\"I love building and shipping new features for our users!\\\\\\",\\\\n \\\\\\"voice\\\\\\": \\\\\\"Fritz-PlayAI\\\\\\",\\\\n \\\\\\"response\_format\\\\\\": \\\\\\"wav\\\\\\"\\\\n }'\\\\n\\",\\"js\\":\\"import fs from \\\\\\"fs\\\\\\";\\\\nimport path from \\\\\\"path\\\\\\";\\\\nimport Groq from 'groq-sdk';\\\\n\\\\nconst groq = new Groq({\\\\n apiKey: process.env.GROQ\_API\_KEY\\\\n});\\\\n\\\\nconst speechFilePath = \\\\\\"speech.wav\\\\\\";\\\\nconst model = \\\\\\"playai-tts\\\\\\";\\\\nconst voice = \\\\\\"Fritz-PlayAI\\\\\\";\\\\nconst text = \\\\\\"I love building and shipping new features for our users!\\\\\\";\\\\nconst responseFormat = \\\\\\"wav\\\\\\";\\\\n\\\\nasync function main() {\\\\n const response = await groq.audio.speech.create({\\\\n model: model,\\\\n voice: voice,\\\\n input: text,\\\\n response\_format: responseFormat\\\\n });\\\\n\\\\n const buffer = Buffer.from(await response.arrayBuffer());\\\\n await fs.promises.writeFile(speechFilePath, buffer);\\\\n}\\\\n\\\\nmain();\\\\n\\",\\"py\\":\\"import os\\\\nfrom groq import Groq\\\\n\\\\nclient = Groq(api\_key=os.environ.get(\\\\\\"GROQ\_API\_KEY\\\\\\"))\\\\n\\\\nspeech\_file\_path = \\\\\\"speech.wav\\\\\\"\\\\nmodel = \\\\\\"playai-tts\\\\\\"\\\\nvoice = \\\\\\"Fritz-PlayAI\\\\\\"\\\\ntext = \\\\\\"I love building and shipping new features for our users!\\\\\\"\\\\nresponse\_format = \\\\\\"wav\\\\\\"\\\\n\\\\nresponse = client.audio.speech.create(\\\\n model=model,\\\\n voice=voice,\\\\n input=text,\\\\n response\_format=response\_format\\\\n)\\\\n\\\\nresponse.write\_to\_file(speech\_file\_path)\\\\n\\"},\\"title\\":\\"Default\\"}\],\\"returns\\":\\"Returns an audio file in \`wav\` format.\\"}}},\\"/openai/v1/audio/transcriptions\\":{\\"post\\":{\\"operationId\\":\\"createTranscription\\",\\"requestBody\\":{\\"content\\":{\\"multipart/form-data\\":{\\"schema\\":{\\"$ref\\":\\"#/components/schemas/CreateTranscriptionRequest\\"}}},\\"required\\":true},\\"responses\\":{\\"200\\":{\\"content\\":{\\"application/json\\":{\\"schema\\":{\\"$ref\\":\\"#/components/schemas/CreateTranscriptionResponseJson\\"}}},\\"description\\":\\"OK\\"}},\\"summary\\":\\"Transcribes audio into the input language.\\",\\"tags\\":\[\\"Audio\\"\],\\"x-groq-metadata\\":{\\"examples\\":\[{\\"request\\":{\\"curl\\":\\"curl https://api.groq.com/openai/v1/audio/transcriptions \\\\\\\\\\\\n -H \\\\\\"Authorization: Bearer $GROQ\_API\_KEY\\\\\\" \\\\\\\\\\\\n -H \\\\\\"Content-Type: multipart/form-data\\\\\\" \\\\\\\\\\\\n -F file=\\\\\\"@./sample\_audio.m4a\\\\\\" \\\\\\\\\\\\n -F model=\\\\\\"whisper-large-v3\\\\\\"\\\\n\\",\\"js\\":\\"import fs from \\\\\\"fs\\\\\\";\\\\nimport Groq from \\\\\\"groq-sdk\\\\\\";\\\\n\\\\nconst groq = new Groq();\\\\nasync function main() {\\\\n const transcription = await groq.audio.transcriptions.create({\\\\n file: fs.createReadStream(\\\\\\"sample\_audio.m4a\\\\\\"),\\\\n model: \\\\\\"whisper-large-v3\\\\\\",\\\\n prompt: \\\\\\"Specify context or spelling\\\\\\", // Optional\\\\n response\_format: \\\\\\"json\\\\\\", // Optional\\\\n language: \\\\\\"en\\\\\\", // Optional\\\\n temperature: 0.0, // Optional\\\\n });\\\\n console.log(transcription.text);\\\\n}\\\\nmain();\\\\n\\",\\"py\\":\\"import os\\\\nfrom groq import Groq\\\\n\\\\nclient = Groq()\\\\nfilename = os.path.dirname(\_\_file\_\_) + \\\\\\"/sample\_audio.m4a\\\\\\"\\\\n\\\\nwith open(filename, \\\\\\"rb\\\\\\") as file:\\\\n transcription = client.audio.transcriptions.create(\\\\n file=(filename, file.read()),\\\\n model=\\\\\\"whisper-large-v3\\\\\\",\\\\n prompt=\\\\\\"Specify context or spelling\\\\\\", # Optional\\\\n response\_format=\\\\\\"json\\\\\\", # Optional\\\\n language=\\\\\\"en\\\\\\", # Optional\\\\n temperature=0.0 # Optional\\\\n )\\\\n print(transcription.text)\\\\n\\"},\\"response\\":\\"{\\\\n \\\\\\"text\\\\\\": \\\\\\"Your transcribed text appears here...\\\\\\",\\\\n \\\\\\"x\_groq\\\\\\": {\\\\n \\\\\\"id\\\\\\": \\\\\\"req\_unique\_id\\\\\\"\\\\n }\\\\n}\\\\n\\",\\"title\\":\\"Default\\"}\],\\"returns\\":\\"Returns an audio transcription object.\\"}}},\\"/openai/v1/audio/translations\\":{\\"post\\":{\\"operationId\\":\\"createTranslation\\",\\"requestBody\\":{\\"content\\":{\\"multipart/form-data\\":{\\"schema\\":{\\"$ref\\":\\"#/components/schemas/CreateTranslationRequest\\"}}},\\"required\\":true},\\"responses\\":{\\"200\\":{\\"content\\":{\\"application/json\\":{\\"schema\\":{\\"$ref\\":\\"#/components/schemas/CreateTranslationResponseJson\\"}},\\"text/plain\\":{\\"schema\\":{\\"type\\":\\"string\\"}}},\\"description\\":\\"OK\\"}},\\"summary\\":\\"Translates audio into English.\\",\\"tags\\":\[\\"Audio\\"\],\\"x-groq-metadata\\":{\\"examples\\":\[{\\"request\\":{\\"curl\\":\\"curl https://api.groq.com/openai/v1/audio/translations \\\\\\\\\\\\n -H \\\\\\"Authorization: Bearer $GROQ\_API\_KEY\\\\\\" \\\\\\\\\\\\n -H \\\\\\"Content-Type: multipart/form-data\\\\\\" \\\\\\\\\\\\n -F file=\\\\\\"@./sample\_audio.m4a\\\\\\" \\\\\\\\\\\\n -F model=\\\\\\"whisper-large-v3\\\\\\"\\\\n\\",\\"js\\":\\"// Default\\\\nimport fs from \\\\\\"fs\\\\\\";\\\\nimport Groq from \\\\\\"groq-sdk\\\\\\";\\\\n\\\\nconst groq = new Groq();\\\\nasync function main() {\\\\n const translation = await groq.audio.translations.create({\\\\n file: fs.createReadStream(\\\\\\"sample\_audio.m4a\\\\\\"),\\\\n model: \\\\\\"whisper-large-v3\\\\\\",\\\\n prompt: \\\\\\"Specify context or spelling\\\\\\", // Optional\\\\n response\_format: \\\\\\"json\\\\\\", // Optional\\\\n temperature: 0.0, // Optional\\\\n });\\\\n console.log(translation.text);\\\\n}\\\\nmain();\\\\n\\",\\"py\\":\\"# Default\\\\nimport os\\\\nfrom groq import Groq\\\\n\\\\nclient = Groq()\\\\nfilename = os.path.dirname(\_\_file\_\_) + \\\\\\"/sample\_audio.m4a\\\\\\"\\\\n\\\\nwith open(filename, \\\\\\"rb\\\\\\") as file:\\\\n translation = client.audio.translations.create(\\\\n file=(filename, file.read()),\\\\n model=\\\\\\"whisper-large-v3\\\\\\",\\\\n prompt=\\\\\\"Specify context or spelling\\\\\\", # Optional\\\\n response\_format=\\\\\\"json\\\\\\", # Optional\\\\n temperature=0.0 # Optional\\\\n )\\\\n print(translation.text)\\\\n\\"},\\"response\\":\\"{\\\\n \\\\\\"text\\\\\\": \\\\\\"Your translated text appears here...\\\\\\",\\\\n \\\\\\"x\_groq\\\\\\": {\\\\n \\\\\\"id\\\\\\": \\\\\\"req\_unique\_id\\\\\\"\\\\n }\\\\n}\\\\n\\",\\"title\\":\\"Default\\"}\],\\"returns\\":\\"Returns an audio translation object.\\"}}},\\"/openai/v1/batches\\":{\\"get\\":{\\"operationId\\":\\"listBatches\\",\\"responses\\":{\\"200\\":{\\"content\\":{\\"application/json\\":{\\"schema\\":{\\"$ref\\":\\"#/components/schemas/ListBatchesResponse\\"}}},\\"description\\":\\"Batch listed successfully.\\"}},\\"summary\\":\\"List your organization's batches.\\",\\"tags\\":\[\\"Batch\\"\],\\"x-groq-metadata\\":{\\"examples\\":\[{\\"request\\":{\\"curl\\":\\"curl https://api.groq.com/openai/v1/batches \\\\\\\\\\\\n -H \\\\\\"Authorization: Bearer $GROQ\_API\_KEY\\\\\\" \\\\\\\\\\\\n -H \\\\\\"Content-Type: application/json\\\\\\"\\\\n\\",\\"js\\":\\"import Groq from 'groq-sdk';\\\\n\\\\nconst client = new Groq({\\\\n apiKey: process.env\['GROQ\_API\_KEY'\], // This is the default and can be omitted\\\\n});\\\\n\\\\nasync function main() {\\\\n const batchList = await client.batches.list();\\\\n console.log(batchList.data);\\\\n}\\\\n\\\\nmain();\\\\n\\",\\"py\\":\\"import os\\\\nfrom groq import Groq\\\\n\\\\nclient = Groq(\\\\n api\_key=os.environ.get(\\\\\\"GROQ\_API\_KEY\\\\\\"), # This is the default and can be omitted\\\\n)\\\\nbatch\_list = client.batches.list()\\\\nprint(batch\_list.data)\\\\n\\"},\\"response\\":\\"{\\\\n \\\\\\"object\\\\\\": \\\\\\"list\\\\\\",\\\\n \\\\\\"data\\\\\\": \[\\\\n {\\\\n \\\\\\"id\\\\\\": \\\\\\"batch\_01jh6xa7reempvjyh6n3yst2zw\\\\\\",\\\\n \\\\\\"object\\\\\\": \\\\\\"batch\\\\\\",\\\\n \\\\\\"endpoint\\\\\\": \\\\\\"/v1/chat/completions\\\\\\",\\\\n \\\\\\"errors\\\\\\": null,\\\\n \\\\\\"input\_file\_id\\\\\\": \\\\\\"file\_01jh6x76wtemjr74t1fh0faj5t\\\\\\",\\\\n \\\\\\"completion\_window\\\\\\": \\\\\\"24h\\\\\\",\\\\n \\\\\\"status\\\\\\": \\\\\\"validating\\\\\\",\\\\n \\\\\\"output\_file\_id\\\\\\": null,\\\\n \\\\\\"error\_file\_id\\\\\\": null,\\\\n \\\\\\"finalizing\_at\\\\\\": null,\\\\n \\\\\\"failed\_at\\\\\\": null,\\\\n \\\\\\"expired\_at\\\\\\": null,\\\\n \\\\\\"cancelled\_at\\\\\\": null,\\\\n \\\\\\"request\_counts\\\\\\": {\\\\n \\\\\\"total\\\\\\": 0,\\\\n \\\\\\"completed\\\\\\": 0,\\\\n \\\\\\"failed\\\\\\": 0\\\\n },\\\\n \\\\\\"metadata\\\\\\": null,\\\\n \\\\\\"created\_at\\\\\\": 1736472600,\\\\n \\\\\\"expires\_at\\\\\\": 1736559000,\\\\n \\\\\\"cancelling\_at\\\\\\": null,\\\\n \\\\\\"completed\_at\\\\\\": null,\\\\n \\\\\\"in\_progress\_at\\\\\\": null\\\\n }\\\\n \]\\\\n}\\\\n\\",\\"title\\":\\"Default\\"}\],\\"returns\\":\\"A list of batches\\"}},\\"post\\":{\\"operationId\\":\\"createBatch\\",\\"requestBody\\":{\\"content\\":{\\"application/json\\":{\\"schema\\":{\\"properties\\":{\\"completion\_window\\":{\\"description\\":\\"The time frame within which the batch should be processed. Durations from \`24h\` to \`7d\` are supported.\\",\\"type\\":\\"string\\"},\\"endpoint\\":{\\"description\\":\\"The endpoint to be used for all requests in the batch. Currently \`/v1/chat/completions\` is supported.\\",\\"enum\\":\[\\"/v1/chat/completions\\"\],\\"type\\":\\"string\\"},\\"input\_file\_id\\":{\\"description\\":\\"The ID of an uploaded file that contains requests for the new batch.\\\\n\\\\nSee \[upload file\](/docs/api-reference#files-upload) for how to upload a file.\\\\n\\\\nYour input file must be formatted as a \[JSONL file\](/docs/batch), and must be uploaded with the purpose \`batch\`. The file can be up to 100 MB in size.\\\\n\\",\\"type\\":\\"string\\"},\\"metadata\\":{\\"additionalProperties\\":{\\"type\\":\\"string\\"},\\"description\\":\\"Optional custom metadata for the batch.\\",\\"nullable\\":true,\\"type\\":\\"object\\"}},\\"required\\":\[\\"input\_file\_id\\",\\"endpoint\\",\\"completion\_window\\"\],\\"type\\":\\"object\\"}}},\\"required\\":true},\\"responses\\":{\\"200\\":{\\"content\\":{\\"application/json\\":{\\"schema\\":{\\"$ref\\":\\"#/components/schemas/Batch\\"}}},\\"description\\":\\"Batch created successfully.\\"}},\\"summary\\":\\"Creates and executes a batch from an uploaded file of requests. \[Learn more\](/docs/batch).\\",\\"tags\\":\[\\"Batch\\"\],\\"x-groq-metadata\\":{\\"examples\\":\[{\\"request\\":{\\"curl\\":\\"curl https://api.groq.com/openai/v1/batches \\\\\\\\\\\\n -H \\\\\\"Authorization: Bearer $GROQ\_API\_KEY\\\\\\" \\\\\\\\\\\\n -H \\\\\\"Content-Type: application/json\\\\\\" \\\\\\\\\\\\n -d '{\\\\n \\\\\\"input\_file\_id\\\\\\": \\\\\\"file\_01jh6x76wtemjr74t1fh0faj5t\\\\\\",\\\\n \\\\\\"endpoint\\\\\\": \\\\\\"/v1/chat/completions\\\\\\",\\\\n \\\\\\"completion\_window\\\\\\": \\\\\\"24h\\\\\\"\\\\n }'\\\\n\\",\\"js\\":\\"import Groq from 'groq-sdk';\\\\n\\\\nconst client = new Groq({\\\\n apiKey: process.env\['GROQ\_API\_KEY'\], // This is the default and can be omitted\\\\n});\\\\n\\\\nasync function main() {\\\\n const batch = await client.batches.create({\\\\n completion\_window: \\\\\\"24h\\\\\\",\\\\n endpoint: \\\\\\"/v1/chat/completions\\\\\\",\\\\n input\_file\_id: \\\\\\"file\_01jh6x76wtemjr74t1fh0faj5t\\\\\\",\\\\n });\\\\n console.log(batch.id);\\\\n}\\\\n\\\\nmain();\\\\n\\",\\"py\\":\\"import os\\\\nfrom groq import Groq\\\\n\\\\nclient = Groq(\\\\n api\_key=os.environ.get(\\\\\\"GROQ\_API\_KEY\\\\\\"), # This is the default and can be omitted\\\\n)\\\\nbatch = client.batches.create(\\\\n completion\_window=\\\\\\"24h\\\\\\",\\\\n endpoint=\\\\\\"/v1/chat/completions\\\\\\",\\\\n input\_file\_id=\\\\\\"file\_01jh6x76wtemjr74t1fh0faj5t\\\\\\",\\\\n)\\\\nprint(batch.id)\\\\n\\"},\\"response\\":\\"{\\\\n \\\\\\"id\\\\\\": \\\\\\"batch\_01jh6xa7reempvjyh6n3yst2zw\\\\\\",\\\\n \\\\\\"object\\\\\\": \\\\\\"batch\\\\\\",\\\\n \\\\\\"endpoint\\\\\\": \\\\\\"/v1/chat/completions\\\\\\",\\\\n \\\\\\"errors\\\\\\": null,\\\\n \\\\\\"input\_file\_id\\\\\\": \\\\\\"file\_01jh6x76wtemjr74t1fh0faj5t\\\\\\",\\\\n \\\\\\"completion\_window\\\\\\": \\\\\\"24h\\\\\\",\\\\n \\\\\\"status\\\\\\": \\\\\\"validating\\\\\\",\\\\n \\\\\\"output\_file\_id\\\\\\": null,\\\\n \\\\\\"error\_file\_id\\\\\\": null,\\\\n \\\\\\"finalizing\_at\\\\\\": null,\\\\n \\\\\\"failed\_at\\\\\\": null,\\\\n \\\\\\"expired\_at\\\\\\": null,\\\\n \\\\\\"cancelled\_at\\\\\\": null,\\\\n \\\\\\"request\_counts\\\\\\": {\\\\n \\\\\\"total\\\\\\": 0,\\\\n \\\\\\"completed\\\\\\": 0,\\\\n \\\\\\"failed\\\\\\": 0\\\\n },\\\\n \\\\\\"metadata\\\\\\": null,\\\\n \\\\\\"created\_at\\\\\\": 1736472600,\\\\n \\\\\\"expires\_at\\\\\\": 1736559000,\\\\n \\\\\\"cancelling\_at\\\\\\": null,\\\\n \\\\\\"completed\_at\\\\\\": null,\\\\n \\\\\\"in\_progress\_at\\\\\\": null\\\\n}\\\\n\\",\\"title\\":\\"Default\\"}\],\\"returns\\":\\"A created batch object.\\"}}},\\"/openai/v1/batches/{batch\_id}\\":{\\"get\\":{\\"operationId\\":\\"retrieveBatch\\",\\"parameters\\":\[{\\"description\\":\\"The ID of the batch to retrieve.\\",\\"in\\":\\"path\\",\\"name\\":\\"batch\_id\\",\\"required\\":true,\\"schema\\":{\\"type\\":\\"string\\"}}\],\\"responses\\":{\\"200\\":{\\"content\\":{\\"application/json\\":{\\"schema\\":{\\"$ref\\":\\"#/components/schemas/Batch\\"}}},\\"description\\":\\"Batch retrieved successfully.\\"}},\\"summary\\":\\"Retrieves a batch.\\",\\"tags\\":\[\\"Batch\\"\],\\"x-groq-metadata\\":{\\"examples\\":\[{\\"request\\":{\\"curl\\":\\"curl https://api.groq.com/openai/v1/batches/batch\_01jh6xa7reempvjyh6n3yst2zw \\\\\\\\\\\\n -H \\\\\\"Authorization: Bearer $GROQ\_API\_KEY\\\\\\" \\\\\\\\\\\\n -H \\\\\\"Content-Type: application/json\\\\\\"\\\\n\\",\\"js\\":\\"import Groq from 'groq-sdk';\\\\n\\\\nconst client = new Groq({\\\\n apiKey: process.env\['GROQ\_API\_KEY'\], // This is the default and can be omitted\\\\n});\\\\n\\\\nasync function main() {\\\\n const batch = await client.batches.retrieve(\\\\\\"batch\_01jh6xa7reempvjyh6n3yst2zw\\\\\\");\\\\n console.log(batch.id);\\\\n}\\\\n\\\\nmain();\\\\n\\",\\"py\\":\\"import os\\\\nfrom groq import Groq\\\\n\\\\nclient = Groq(\\\\n api\_key=os.environ.get(\\\\\\"GROQ\_API\_KEY\\\\\\"), # This is the default and can be omitted\\\\n)\\\\nbatch = client.batches.retrieve(\\\\n \\\\\\"batch\_01jh6xa7reempvjyh6n3yst2zw\\\\\\",\\\\n)\\\\nprint(batch.id)\\\\n\\"},\\"response\\":\\"{\\\\n \\\\\\"id\\\\\\": \\\\\\"batch\_01jh6xa7reempvjyh6n3yst2zw\\\\\\",\\\\n \\\\\\"object\\\\\\": \\\\\\"batch\\\\\\",\\\\n \\\\\\"endpoint\\\\\\": \\\\\\"/v1/chat/completions\\\\\\",\\\\n \\\\\\"errors\\\\\\": null,\\\\n \\\\\\"input\_file\_id\\\\\\": \\\\\\"file\_01jh6x76wtemjr74t1fh0faj5t\\\\\\",\\\\n \\\\\\"completion\_window\\\\\\": \\\\\\"24h\\\\\\",\\\\n \\\\\\"status\\\\\\": \\\\\\"validating\\\\\\",\\\\n \\\\\\"output\_file\_id\\\\\\": null,\\\\n \\\\\\"error\_file\_id\\\\\\": null,\\\\n \\\\\\"finalizing\_at\\\\\\": null,\\\\n \\\\\\"failed\_at\\\\\\": null,\\\\n \\\\\\"expired\_at\\\\\\": null,\\\\n \\\\\\"cancelled\_at\\\\\\": null,\\\\n \\\\\\"request\_counts\\\\\\": {\\\\n \\\\\\"total\\\\\\": 0,\\\\n \\\\\\"completed\\\\\\": 0,\\\\n \\\\\\"failed\\\\\\": 0\\\\n },\\\\n \\\\\\"metadata\\\\\\": null,\\\\n \\\\\\"created\_at\\\\\\": 1736472600,\\\\n \\\\\\"expires\_at\\\\\\": 1736559000,\\\\n \\\\\\"cancelling\_at\\\\\\": null,\\\\n \\\\\\"completed\_at\\\\\\": null,\\\\n \\\\\\"in\_progress\_at\\\\\\": null\\\\n}\\\\n\\",\\"title\\":\\"Default\\"}\],\\"returns\\":\\"A batch object.\\"}}},\\"/openai/v1/batches/{batch\_id}/cancel\\":{\\"post\\":{\\"operationId\\":\\"cancelBatch\\",\\"parameters\\":\[{\\"description\\":\\"The ID of the batch to cancel.\\",\\"in\\":\\"path\\",\\"name\\":\\"batch\_id\\",\\"required\\":true,\\"schema\\":{\\"type\\":\\"string\\"}}\],\\"responses\\":{\\"200\\":{\\"content\\":{\\"application/json\\":{\\"schema\\":{\\"$ref\\":\\"#/components/schemas/Batch\\"}}},\\"description\\":\\"Batch cancelled successfully.\\"}},\\"summary\\":\\"Cancels a batch.\\",\\"tags\\":\[\\"Batch\\"\],\\"x-groq-metadata\\":{\\"examples\\":\[{\\"request\\":{\\"curl\\":\\"curl -X POST https://api.groq.com/openai/v1/batches/batch\_01jh6xa7reempvjyh6n3yst2zw/cancel \\\\\\\\\\\\n -H \\\\\\"Authorization: Bearer $GROQ\_API\_KEY\\\\\\" \\\\\\\\\\\\n -H \\\\\\"Content-Type: application/json\\\\\\"\\\\n\\",\\"js\\":\\"import Groq from 'groq-sdk';\\\\n\\\\nconst client = new Groq({\\\\n apiKey: process.env\['GROQ\_API\_KEY'\], // This is the default and can be omitted\\\\n});\\\\n\\\\nasync function main() {\\\\n const batch = await client.batches.cancel(\\\\\\"batch\_01jh6xa7reempvjyh6n3yst2zw\\\\\\");\\\\n console.log(batch.id);\\\\n}\\\\n\\\\nmain();\\\\n\\",\\"py\\":\\"import os\\\\nfrom groq import Groq\\\\n\\\\nclient = Groq(\\\\n api\_key=os.environ.get(\\\\\\"GROQ\_API\_KEY\\\\\\"), # This is the default and can be omitted\\\\n)\\\\nbatch = client.batches.cancel(\\\\n \\\\\\"batch\_01jh6xa7reempvjyh6n3yst2zw\\\\\\",\\\\n)\\\\nprint(batch.id)\\\\n\\"},\\"response\\":\\"{\\\\n \\\\\\"id\\\\\\": \\\\\\"batch\_01jh6xa7reempvjyh6n3yst2zw\\\\\\",\\\\n \\\\\\"object\\\\\\": \\\\\\"batch\\\\\\",\\\\n \\\\\\"endpoint\\\\\\": \\\\\\"/v1/chat/completions\\\\\\",\\\\n \\\\\\"errors\\\\\\": null,\\\\n \\\\\\"input\_file\_id\\\\\\": \\\\\\"file\_01jh6x76wtemjr74t1fh0faj5t\\\\\\",\\\\n \\\\\\"completion\_window\\\\\\": \\\\\\"24h\\\\\\",\\\\n \\\\\\"status\\\\\\": \\\\\\"cancelling\\\\\\",\\\\n \\\\\\"output\_file\_id\\\\\\": null,\\\\n \\\\\\"error\_file\_id\\\\\\": null,\\\\n \\\\\\"finalizing\_at\\\\\\": null,\\\\n \\\\\\"failed\_at\\\\\\": null,\\\\n \\\\\\"expired\_at\\\\\\": null,\\\\n \\\\\\"cancelled\_at\\\\\\": null,\\\\n \\\\\\"request\_counts\\\\\\": {\\\\n \\\\\\"total\\\\\\": 0,\\\\n \\\\\\"completed\\\\\\": 0,\\\\n \\\\\\"failed\\\\\\": 0\\\\n },\\\\n \\\\\\"metadata\\\\\\": null,\\\\n \\\\\\"created\_at\\\\\\": 1736472600,\\\\n \\\\\\"expires\_at\\\\\\": 1736559000,\\\\n \\\\\\"cancelling\_at\\\\\\": null,\\\\n \\\\\\"completed\_at\\\\\\": null,\\\\n \\\\\\"in\_progress\_at\\\\\\": null\\\\n}\\\\n\\",\\"title\\":\\"Default\\"}\],\\"returns\\":\\"A batch object.\\"}}},\\"/openai/v1/chat/completions\\":{\\"post\\":{\\"operationId\\":\\"createChatCompletion\\",\\"requestBody\\":{\\"content\\":{\\"application/json\\":{\\"schema\\":{\\"$ref\\":\\"#/components/schemas/CreateChatCompletionRequest\\"}}},\\"description\\":\\"The chat prompt and parameters\\",\\"required\\":true},\\"responses\\":{\\"200\\":{\\"content\\":{\\"application/json\\":{\\"schema\\":{\\"$ref\\":\\"#/components/schemas/CreateChatCompletionResponse\\"}}},\\"description\\":\\"OK\\"}},\\"summary\\":\\"Creates a model response for the given chat conversation.\\",\\"tags\\":\[\\"Chat\\"\],\\"x-groq-metadata\\":{\\"examples\\":\[{\\"request\\":{\\"curl\\":\\"curl https://api.groq.com/openai/v1/chat/completions -s \\\\\\\\\\\\n-H \\\\\\"Content-Type: application/json\\\\\\" \\\\\\\\\\\\n-H \\\\\\"Authorization: Bearer $GROQ\_API\_KEY\\\\\\" \\\\\\\\\\\\n-d '{\\\\n \\\\\\"model\\\\\\": \\\\\\"llama-3.3-70b-versatile\\\\\\",\\\\n \\\\\\"messages\\\\\\": \[{\\\\n \\\\\\"role\\\\\\": \\\\\\"user\\\\\\",\\\\n \\\\\\"content\\\\\\": \\\\\\"Explain the importance of fast language models\\\\\\"\\\\n }\]\\\\n}'\\\\n\\",\\"js\\":\\"import Groq from \\\\\\"groq-sdk\\\\\\";\\\\n\\\\nconst groq = new Groq({ apiKey: process.env.GROQ\_API\_KEY });\\\\n\\\\nasync function main() {\\\\n const completion = await groq.chat.completions\\\\n .create({\\\\n messages: \[\\\\n {\\\\n role: \\\\\\"user\\\\\\",\\\\n content: \\\\\\"Explain the importance of fast language models\\\\\\",\\\\n },\\\\n \],\\\\n model: \\\\\\"llama-3.3-70b-versatile\\\\\\",\\\\n })\\\\n console.log(completion.choices\[0\].message.content);\\\\n}\\\\n\\\\nmain();\\\\n\\",\\"py\\":\\"import os\\\\n\\\\nfrom groq import Groq\\\\n\\\\nclient = Groq(\\\\n # This is the default and can be omitted\\\\n api\_key=os.environ.get(\\\\\\"GROQ\_API\_KEY\\\\\\"),\\\\n)\\\\n\\\\nchat\_completion = client.chat.completions.create(\\\\n messages=\[\\\\n {\\\\n \\\\\\"role\\\\\\": \\\\\\"system\\\\\\",\\\\n \\\\\\"content\\\\\\": \\\\\\"You are a helpful assistant.\\\\\\"\\\\n },\\\\n {\\\\n \\\\\\"role\\\\\\": \\\\\\"user\\\\\\",\\\\n \\\\\\"content\\\\\\": \\\\\\"Explain the importance of fast language models\\\\\\",\\\\n }\\\\n \],\\\\n model=\\\\\\"llama-3.3-70b-versatile\\\\\\",\\\\n)\\\\n\\\\nprint(chat\_completion.choices\[0\].message.content)\\\\n\\"},\\"response\\":\\"$34\\",\\"title\\":\\"Default\\"}\],\\"returns\\":\\"Returns a \[chat completion\](/docs/api-reference#chat-create) object, or a streamed sequence of \[chat completion chunk\](/docs/api-reference#chat-create) objects if the request is streamed.\\"}}},\\"/openai/v1/embeddings\\":{\\"post\\":{\\"operationId\\":\\"createEmbedding\\",\\"requestBody\\":{\\"content\\":{\\"application/json\\":{\\"schema\\":{\\"$ref\\":\\"#/components/schemas/CreateEmbeddingRequest\\"}}},\\"required\\":true},\\"responses\\":{\\"200\\":{\\"content\\":{\\"application/json\\":{\\"schema\\":{\\"$ref\\":\\"#/components/schemas/CreateEmbeddingResponse\\"}}},\\"description\\":\\"OK\\"}},\\"summary\\":\\"Creates an embedding vector representing the input text.\\",\\"tags\\":\[\\"Embeddings\\"\]}},\\"/openai/v1/files\\":{\\"get\\":{\\"operationId\\":\\"listFiles\\",\\"responses\\":{\\"200\\":{\\"content\\":{\\"application/json\\":{\\"schema\\":{\\"$ref\\":\\"#/components/schemas/ListFilesResponse\\"}}},\\"description\\":\\"OK\\"}},\\"summary\\":\\"Returns a list of files.\\",\\"tags\\":\[\\"Files\\"\],\\"x-groq-metadata\\":{\\"examples\\":\[{\\"request\\":{\\"curl\\":\\"curl https://api.groq.com/openai/v1/files \\\\\\\\\\\\n -H \\\\\\"Authorization: Bearer $GROQ\_API\_KEY\\\\\\" \\\\\\\\\\\\n -H \\\\\\"Content-Type: application/json\\\\\\"\\\\n\\",\\"js\\":\\"import Groq from 'groq-sdk';\\\\n\\\\nconst client = new Groq({\\\\n apiKey: process.env\['GROQ\_API\_KEY'\], // This is the default and can be omitted\\\\n});\\\\n\\\\nasync function main() {\\\\n const fileList = await client.files.list();\\\\n console.log(fileList.data);\\\\n}\\\\n\\\\nmain();\\\\n\\",\\"py\\":\\"import os\\\\nfrom groq import Groq\\\\n\\\\nclient = Groq(\\\\n api\_key=os.environ.get(\\\\\\"GROQ\_API\_KEY\\\\\\"), # This is the default and can be omitted\\\\n)\\\\nfile\_list = client.files.list()\\\\nprint(file\_list.data)\\\\n\\"},\\"response\\":\\"{\\\\n \\\\\\"object\\\\\\": \\\\\\"list\\\\\\",\\\\n \\\\\\"data\\\\\\": \[\\\\n {\\\\n \\\\\\"id\\\\\\": \\\\\\"file\_01jh6x76wtemjr74t1fh0faj5t\\\\\\",\\\\n \\\\\\"object\\\\\\": \\\\\\"file\\\\\\",\\\\n \\\\\\"bytes\\\\\\": 966,\\\\n \\\\\\"created\_at\\\\\\": 1736472501,\\\\n \\\\\\"filename\\\\\\": \\\\\\"batch\_file.jsonl\\\\\\",\\\\n \\\\\\"purpose\\\\\\": \\\\\\"batch\\\\\\"\\\\n }\\\\n \]\\\\n}\\\\n\\",\\"title\\":\\"Default\\"}\],\\"returns\\":\\"A list of \[File\](/docs/api-reference#files-upload) objects.\\"}},\\"post\\":{\\"operationId\\":\\"uploadFile\\",\\"requestBody\\":{\\"content\\":{\\"multipart/form-data\\":{\\"schema\\":{\\"$ref\\":\\"#/components/schemas/CreateFileRequest\\"}}},\\"required\\":true},\\"responses\\":{\\"200\\":{\\"content\\":{\\"application/json\\":{\\"schema\\":{\\"$ref\\":\\"#/components/schemas/File\\"}}},\\"description\\":\\"OK\\"}},\\"summary\\":\\"Upload a file that can be used across various endpoints.\\\\n\\\\nThe Batch API only supports \`.jsonl\` files up to 100 MB in size. The input also has a specific required \[format\](/docs/batch).\\\\n\\\\nPlease contact us if you need to increase these storage limits.\\\\n\\",\\"tags\\":\[\\"Files\\"\],\\"x-groq-metadata\\":{\\"examples\\":\[{\\"request\\":{\\"curl\\":\\"curl https://api.groq.com/openai/v1/files \\\\\\\\\\\\n -H \\\\\\"Authorization: Bearer $GROQ\_API\_KEY\\\\\\" \\\\\\\\\\\\n -F purpose=\\\\\\"batch\\\\\\" \\\\\\\\\\\\n -F \\\\\\"file=@batch\_file.jsonl\\\\\\"\\\\n\\",\\"js\\":\\"import Groq from 'groq-sdk';\\\\n\\\\nconst client = new Groq({\\\\n apiKey: process.env\['GROQ\_API\_KEY'\], // This is the default and can be omitted\\\\n});\\\\n\\\\nconst fileContent = '{\\\\\\"custom\_id\\\\\\": \\\\\\"request-1\\\\\\", \\\\\\"method\\\\\\": \\\\\\"POST\\\\\\", \\\\\\"url\\\\\\": \\\\\\"/v1/chat/completions\\\\\\", \\\\\\"body\\\\\\": {\\\\\\"model\\\\\\": \\\\\\"llama-3.1-8b-instant\\\\\\", \\\\\\"messages\\\\\\": \[{\\\\\\"role\\\\\\": \\\\\\"user\\\\\\", \\\\\\"content\\\\\\": \\\\\\"Explain the importance of fast language models\\\\\\"}\]}}\\\\\\\\n';\\\\n\\\\nasync function main() {\\\\n const blob = new Blob(\[fileContent\]);\\\\n const file = new File(\[blob\], 'batch.jsonl');\\\\n\\\\n const createdFile = await client.files.create({ file: file, purpose: 'batch' });\\\\n console.log(createdFile.id);\\\\n}\\\\n\\\\nmain();\\\\n\\",\\"py\\":\\"import os\\\\nimport requests # pip install requests first!\\\\n\\\\ndef upload\_file\_to\_groq(api\_key, file\_path):\\\\n url = \\\\\\"https://api.groq.com/openai/v1/files\\\\\\"\\\\n\\\\n headers = {\\\\n \\\\\\"Authorization\\\\\\": f\\\\\\"Bearer {api\_key}\\\\\\"\\\\n }\\\\n\\\\n # Prepare the file and form data\\\\n files = {\\\\n \\\\\\"file\\\\\\": (\\\\\\"batch\_file.jsonl\\\\\\", open(file\_path, \\\\\\"rb\\\\\\"))\\\\n }\\\\n\\\\n data = {\\\\n \\\\\\"purpose\\\\\\": \\\\\\"batch\\\\\\"\\\\n }\\\\n\\\\n # Make the POST request\\\\n response = requests.post(url, headers=headers, files=files, data=data)\\\\n\\\\n return response.json()\\\\n\\\\n# Usage example\\\\napi\_key = os.environ.get(\\\\\\"GROQ\_API\_KEY\\\\\\")\\\\nfile\_path = \\\\\\"batch\_file.jsonl\\\\\\" # Path to your JSONL file\\\\n\\\\ntry:\\\\n result = upload\_file\_to\_groq(api\_key, file\_path)\\\\n print(result)\\\\nexcept Exception as e:\\\\n print(f\\\\\\"Error: {e}\\\\\\")\\\\n\\"},\\"response\\":\\"{\\\\n \\\\\\"id\\\\\\": \\\\\\"file\_01jh6x76wtemjr74t1fh0faj5t\\\\\\",\\\\n \\\\\\"object\\\\\\": \\\\\\"file\\\\\\",\\\\n \\\\\\"bytes\\\\\\": 966,\\\\n \\\\\\"created\_at\\\\\\": 1736472501,\\\\n \\\\\\"filename\\\\\\": \\\\\\"batch\_file.jsonl\\\\\\",\\\\n \\\\\\"purpose\\\\\\": \\\\\\"batch\\\\\\"\\\\n}\\\\n\\",\\"title\\":\\"Default\\"}\],\\"returns\\":\\"The uploaded File object.\\"}}},\\"/openai/v1/files/{file\_id}\\":{\\"delete\\":{\\"operationId\\":\\"deleteFile\\",\\"parameters\\":\[{\\"description\\":\\"The ID of the file to use for this request.\\",\\"in\\":\\"path\\",\\"name\\":\\"file\_id\\",\\"required\\":true,\\"schema\\":{\\"type\\":\\"string\\"}}\],\\"responses\\":{\\"200\\":{\\"content\\":{\\"application/json\\":{\\"schema\\":{\\"$ref\\":\\"#/components/schemas/DeleteFileResponse\\"}}},\\"description\\":\\"OK\\"}},\\"summary\\":\\"Delete a file.\\",\\"tags\\":\[\\"Files\\"\],\\"x-groq-metadata\\":{\\"examples\\":\[{\\"request\\":{\\"curl\\":\\"curl -X DELETE https://api.groq.com/openai/v1/files/file\_01jh6x76wtemjr74t1fh0faj5t \\\\\\\\\\\\n -H \\\\\\"Authorization: Bearer $GROQ\_API\_KEY\\\\\\" \\\\\\\\\\\\n -H \\\\\\"Content-Type: application/json\\\\\\"\\\\n\\",\\"js\\":\\"import Groq from 'groq-sdk';\\\\n\\\\nconst client = new Groq({\\\\n apiKey: process.env\['GROQ\_API\_KEY'\], // This is the default and can be omitted\\\\n});\\\\n\\\\nasync function main() {\\\\n const fileDelete = await client.files.delete(\\\\\\"file\_01jh6x76wtemjr74t1fh0faj5t\\\\\\");\\\\n console.log(fileDelete);\\\\n}\\\\n\\\\nmain();\\\\n\\",\\"py\\":\\"import os\\\\nfrom groq import Groq\\\\n\\\\nclient = Groq(\\\\n api\_key=os.environ.get(\\\\\\"GROQ\_API\_KEY\\\\\\"), # This is the default and can be omitted\\\\n)\\\\nfile\_delete = client.files.delete(\\\\n \\\\\\"file\_01jh6x76wtemjr74t1fh0faj5t\\\\\\",\\\\n)\\\\nprint(file\_delete)\\\\n\\"},\\"response\\":\\"{\\\\n \\\\\\"id\\\\\\": \\\\\\"file\_01jh6x76wtemjr74t1fh0faj5t\\\\\\",\\\\n \\\\\\"object\\\\\\": \\\\\\"file\\\\\\",\\\\n \\\\\\"deleted\\\\\\": true\\\\n}\\\\n\\",\\"title\\":\\"Default\\"}\],\\"returns\\":\\"A deleted file response object.\\"}},\\"get\\":{\\"operationId\\":\\"retrieveFile\\",\\"parameters\\":\[{\\"description\\":\\"The file to retrieve\\",\\"in\\":\\"path\\",\\"name\\":\\"file\_id\\",\\"required\\":true,\\"schema\\":{\\"type\\":\\"string\\"}}\],\\"responses\\":{\\"200\\":{\\"content\\":{\\"application/json\\":{\\"schema\\":{\\"$ref\\":\\"#/components/schemas/File\\"}}},\\"description\\":\\"OK\\"}},\\"summary\\":\\"Returns information about a file.\\",\\"tags\\":\[\\"Files\\"\],\\"x-groq-metadata\\":{\\"examples\\":\[{\\"request\\":{\\"curl\\":\\"curl https://api.groq.com/openai/v1/files/file\_01jh6x76wtemjr74t1fh0faj5t \\\\\\\\\\\\n -H \\\\\\"Authorization: Bearer $GROQ\_API\_KEY\\\\\\" \\\\\\\\\\\\n -H \\\\\\"Content-Type: application/json\\\\\\"\\\\n\\",\\"js\\":\\"import Groq from 'groq-sdk';\\\\n\\\\nconst client = new Groq({\\\\n apiKey: process.env\['GROQ\_API\_KEY'\], // This is the default and can be omitted\\\\n});\\\\n\\\\nasync function main() {\\\\n const file = await client.files.info('file\_01jh6x76wtemjr74t1fh0faj5t');\\\\n console.log(file);\\\\n}\\\\n\\\\nmain();\\\\n\\",\\"py\\":\\"import os\\\\nfrom groq import Groq\\\\n\\\\nclient = Groq(\\\\n api\_key=os.environ.get(\\\\\\"GROQ\_API\_KEY\\\\\\"), # This is the default and can be omitted\\\\n)\\\\nfile = client.files.info(\\\\n \\\\\\"file\_01jh6x76wtemjr74t1fh0faj5t\\\\\\",\\\\n)\\\\nprint(file)\\\\n\\"},\\"response\\":\\"{\\\\n \\\\\\"id\\\\\\": \\\\\\"file\_01jh6x76wtemjr74t1fh0faj5t\\\\\\",\\\\n \\\\\\"object\\\\\\": \\\\\\"file\\\\\\",\\\\n \\\\\\"bytes\\\\\\": 966,\\\\n \\\\\\"created\_at\\\\\\": 1736472501,\\\\n \\\\\\"filename\\\\\\": \\\\\\"batch\_file.jsonl\\\\\\",\\\\n \\\\\\"purpose\\\\\\": \\\\\\"batch\\\\\\"\\\\n}\\\\n\\",\\"title\\":\\"Default\\"}\],\\"returns\\":\\"A file object.\\"}}},\\"/openai/v1/files/{file\_id}/content\\":{\\"get\\":{\\"operationId\\":\\"downloadFile\\",\\"parameters\\":\[{\\"description\\":\\"The ID of the file to use for this request.\\",\\"in\\":\\"path\\",\\"name\\":\\"file\_id\\",\\"required\\":true,\\"schema\\":{\\"type\\":\\"string\\"}}\],\\"responses\\":{\\"200\\":{\\"content\\":{\\"application/octet-stream\\":{\\"schema\\":{\\"format\\":\\"binary\\",\\"type\\":\\"string\\"}}},\\"description\\":\\"OK\\"}},\\"summary\\":\\"Returns the contents of the specified file.\\",\\"tags\\":\[\\"Files\\"\],\\"x-groq-metadata\\":{\\"examples\\":\[{\\"request\\":{\\"curl\\":\\"curl https://api.groq.com/openai/v1/files/file\_01jh6x76wtemjr74t1fh0faj5t/content \\\\\\\\\\\\n -H \\\\\\"Authorization: Bearer $GROQ\_API\_KEY\\\\\\" \\\\\\\\\\\\n -H \\\\\\"Content-Type: application/json\\\\\\"\\\\n\\",\\"js\\":\\"import Groq from 'groq-sdk';\\\\n\\\\nconst client = new Groq({\\\\n apiKey: process.env\['GROQ\_API\_KEY'\], // This is the default and can be omitted\\\\n});\\\\n\\\\nasync function main() {\\\\n const response = await client.files.content('file\_01jh6x76wtemjr74t1fh0faj5t');\\\\n console.log(response);\\\\n}\\\\n\\\\nmain();\\\\n\\",\\"py\\":\\"import os\\\\nfrom groq import Groq\\\\n\\\\nclient = Groq(\\\\n api\_key=os.environ.get(\\\\\\"GROQ\_API\_KEY\\\\\\"), # This is the default and can be omitted\\\\n)\\\\nresponse = client.files.content(\\\\n \\\\\\"file\_01jh6x76wtemjr74t1fh0faj5t\\\\\\",\\\\n)\\\\nprint(response)\\\\n\\"},\\"title\\":\\"Default\\"}\],\\"returns\\":\\"The file content\\"}}},\\"/openai/v1/models\\":{\\"get\\":{\\"description\\":\\"get all available models\\",\\"operationId\\":\\"listModels\\",\\"responses\\":{\\"200\\":{\\"content\\":{\\"application/json\\":{\\"schema\\":{\\"$ref\\":\\"#/components/schemas/ListModelsResponse\\"}}},\\"description\\":\\"OK\\"}},\\"summary\\":\\"List all available \[models\](https://console.groq.com/docs/models).\\",\\"tags\\":\[\\"Models\\"\],\\"x-groq-metadata\\":{\\"examples\\":\[{\\"request\\":{\\"curl\\":\\"curl https://api.groq.com/openai/v1/models \\\\\\\\\\\\n-H \\\\\\"Authorization: Bearer $GROQ\_API\_KEY\\\\\\"\\\\n\\",\\"js\\":\\"import Groq from \\\\\\"groq-sdk\\\\\\";\\\\n\\\\nconst groq = new Groq({ apiKey: process.env.GROQ\_API\_KEY });\\\\n\\\\nasync function main() {\\\\n const models = await groq.models.list();\\\\n console.log(models);\\\\n}\\\\n\\\\nmain();\\\\n\\",\\"py\\":\\"import os\\\\nfrom groq import Groq\\\\n\\\\nclient = Groq(\\\\n # This is the default and can be omitted\\\\n api\_key=os.environ.get(\\\\\\"GROQ\_API\_KEY\\\\\\"),\\\\n)\\\\n\\\\nmodels = client.models.list()\\\\n\\\\nprint(models)\\\\n\\"},\\"response\\":\\"$35\\",\\"title\\":\\"Default\\"}\],\\"returns\\":\\"A list of model objects.\\"}}},\\"/openai/v1/models/{model}\\":{\\"delete\\":{\\"description\\":\\"Delete a model\\",\\"operationId\\":\\"deleteModel\\",\\"parameters\\":\[{\\"description\\":\\"The model to delete\\",\\"in\\":\\"path\\",\\"name\\":\\"model\\",\\"required\\":true,\\"schema\\":{\\"type\\":\\"string\\"}}\],\\"responses\\":{\\"200\\":{\\"content\\":{\\"application/json\\":{\\"schema\\":{\\"$ref\\":\\"#/components/schemas/DeleteModelResponse\\"}}},\\"description\\":\\"OK\\"}},\\"summary\\":\\"Delete model\\",\\"tags\\":\[\\"Models\\"\]},\\"get\\":{\\"description\\":\\"Get a specific model\\",\\"operationId\\":\\"retrieveModel\\",\\"parameters\\":\[{\\"description\\":\\"The model to get\\",\\"in\\":\\"path\\",\\"name\\":\\"model\\",\\"required\\":true,\\"schema\\":{\\"type\\":\\"string\\"}}\],\\"responses\\":{\\"200\\":{\\"content\\":{\\"application/json\\":{\\"schema\\":{\\"$ref\\":\\"#/components/schemas/Model\\"}}},\\"description\\":\\"OK\\"}},\\"summary\\":\\"Get detailed information about a \[model\](https://console.groq.com/docs/models).\\",\\"tags\\":\[\\"Models\\"\],\\"x-groq-metadata\\":{\\"examples\\":\[{\\"request\\":{\\"curl\\":\\"curl https://api.groq.com/openai/v1/models/llama-3.3-70b-versatile \\\\\\\\\\\\n-H \\\\\\"Authorization: Bearer $GROQ\_API\_KEY\\\\\\"\\\\n\\",\\"js\\":\\"import Groq from \\\\\\"groq-sdk\\\\\\";\\\\n\\\\nconst groq = new Groq({ apiKey: process.env.GROQ\_API\_KEY });\\\\n\\\\nasync function main() {\\\\n const model = await groq.models.retrieve(\\\\\\"llama-3.3-70b-versatile\\\\\\");\\\\n console.log(model);\\\\n}\\\\n\\\\nmain();\\\\n\\",\\"py\\":\\"import os\\\\nfrom groq import Groq\\\\n\\\\nclient = Groq(\\\\n # This is the default and can be omitted\\\\n api\_key=os.environ.get(\\\\\\"GROQ\_API\_KEY\\\\\\"),\\\\n)\\\\n\\\\nmodel = client.models.retrieve(\\\\\\"llama-3.3-70b-versatile\\\\\\")\\\\n\\\\nprint(model)\\\\n\\"},\\"response\\":\\"{\\\\n \\\\\\"id\\\\\\": \\\\\\"llama3-8b-8192\\\\\\",\\\\n \\\\\\"object\\\\\\": \\\\\\"model\\\\\\",\\\\n \\\\\\"created\\\\\\": 1693721698,\\\\n \\\\\\"owned\_by\\\\\\": \\\\\\"Meta\\\\\\",\\\\n \\\\\\"active\\\\\\": true,\\\\n \\\\\\"context\_window\\\\\\": 8192,\\\\n \\\\\\"public\_apps\\\\\\": null,\\\\n \\\\\\"max\_completion\_tokens\\\\\\": 8192\\\\n}\\\\n\\",\\"title\\":\\"Default\\"}\],\\"returns\\":\\"A model object.\\"}}},\\"/openai/v1/reranking\\":{\\"post\\":{\\"description\\":\\"Given a query and a list of documents, returns the documents ranked by their relevance to the query.\\\\nThe documents are scored and sorted in descending order of relevance.\\\\n\\",\\"operationId\\":\\"createReranking\\",\\"requestBody\\":{\\"content\\":{\\"application/json\\":{\\"schema\\":{\\"$ref\\":\\"#/components/schemas/RerankingRequest\\"}}},\\"required\\":true},\\"responses\\":{\\"200\\":{\\"content\\":{\\"application/json\\":{\\"schema\\":{\\"$ref\\":\\"#/components/schemas/RerankingResponse\\"}}},\\"description\\":\\"OK\\"}},\\"summary\\":\\"Reranks documents based on their relevance to a query.\\",\\"tags\\":\[\\"Reranking\\"\],\\"x-groq-metadata\\":{\\"examples\\":\[{\\"request\\":{\\"curl\\":\\"curl https://api.groq.com/openai/v1/reranking \\\\\\\\\\\\n -H \\\\\\"Authorization: Bearer $GROQ\_API\_KEY\\\\\\" \\\\\\\\\\\\n -H \\\\\\"Content-Type: application/json\\\\\\" \\\\\\\\\\\\n -d '{\\\\n \\\\\\"model\\\\\\": \\\\\\"qwen3-reranker-4b\\\\\\",\\\\n \\\\\\"query\\\\\\": \\\\\\"artificial intelligence\\\\\\",\\\\n \\\\\\"docs\\\\\\": \[\\\\n \\\\\\"Machine learning is a subset of AI\\\\\\",\\\\n \\\\\\"The weather is nice today\\\\\\",\\\\n \\\\\\"Deep learning uses neural networks\\\\\\"\\\\n \]\\\\n }'\\\\n\\",\\"js\\":\\"import Groq from 'groq-sdk';\\\\n\\\\nconst client = new Groq({\\\\n apiKey: process.env\['GROQ\_API\_KEY'\],\\\\n});\\\\n\\\\nasync function main() {\\\\n const reranking = await client.reranking.create({\\\\n model: 'qwen3-reranker-4b',\\\\n query: 'artificial intelligence',\\\\n docs: \[\\\\n 'Machine learning is a subset of AI',\\\\n 'The weather is nice today',\\\\n 'Deep learning uses neural networks'\\\\n \]\\\\n });\\\\n console.log(reranking.results);\\\\n}\\\\nmain();\\\\n\\",\\"py\\":\\"import os\\\\nfrom groq import Groq\\\\n\\\\nclient = Groq(api\_key=os.environ.get(\\\\\\"GROQ\_API\_KEY\\\\\\"))\\\\n\\\\nreranking = client.reranking.create(\\\\n model=\\\\\\"qwen3-reranker-4b\\\\\\",\\\\n query=\\\\\\"artificial intelligence\\\\\\",\\\\n docs=\[\\\\n \\\\\\"Machine learning is a subset of AI\\\\\\",\\\\n \\\\\\"The weather is nice today\\\\\\", \\\\n \\\\\\"Deep learning uses neural networks\\\\\\"\\\\n \]\\\\n)\\\\nprint(reranking.results)\\\\n\\"},\\"response\\":\\"{\\\\n \\\\\\"results\\\\\\": \[\\\\n {\\\\n \\\\\\"doc\\\\\\": \\\\\\"Machine learning is a subset of AI\\\\\\",\\\\n \\\\\\"score\\\\\\": 0.92\\\\n },\\\\n {\\\\n \\\\\\"doc\\\\\\": \\\\\\"Deep learning uses neural networks\\\\\\", \\\\n \\\\\\"score\\\\\\": 0.87\\\\n },\\\\n {\\\\n \\\\\\"doc\\\\\\": \\\\\\"The weather is nice today\\\\\\",\\\\n \\\\\\"score\\\\\\": 0.23\\\\n }\\\\n \]\\\\n}\\\\n\\",\\"title\\":\\"Basic Reranking\\"},{\\"request\\":{\\"json\\":\\"{\\\\n \\\\\\"model\\\\\\": \\\\\\"qwen3-reranker-4b\\\\\\",\\\\n \\\\\\"query\\\\\\": \\\\\\"climate change effects\\\\\\",\\\\n \\\\\\"docs\\\\\\": \[\\\\n \\\\\\"Global warming causes sea level rise\\\\\\",\\\\n \\\\\\"Electric cars reduce emissions\\\\\\",\\\\n \\\\\\"Renewable energy is growing fast\\\\\\"\\\\n \],\\\\n \\\\\\"instruction\\\\\\": \\\\\\"Find documents specifically about environmental impacts\\\\\\"\\\\n}\\\\n\\"},\\"response\\":\\"{\\\\n \\\\\\"results\\\\\\": \[\\\\n {\\\\n \\\\\\"doc\\\\\\": \\\\\\"Global warming causes sea level rise\\\\\\",\\\\n \\\\\\"score\\\\\\": 0.95\\\\n },\\\\n {\\\\n \\\\\\"doc\\\\\\": \\\\\\"Electric cars reduce emissions\\\\\\",\\\\n \\\\\\"score\\\\\\": 0.78\\\\n },\\\\n {\\\\n \\\\\\"doc\\\\\\": \\\\\\"Renewable energy is growing fast\\\\\\",\\\\n \\\\\\"score\\\\\\": 0.65\\\\n }\\\\n \]\\\\n}\\\\n\\",\\"title\\":\\"Reranking with Custom Instruction\\"}\],\\"returns\\":\\"A list of documents sorted by relevance score in descending order. \\\\nScores range from 0.0 to 1.0, where higher scores indicate greater relevance to the query.\\\\n\\"}}},\\"/openai/v1/responses\\":{\\"post\\":{\\"operationId\\":\\"createResponse\\",\\"requestBody\\":{\\"content\\":{\\"application/json\\":{\\"schema\\":{\\"$ref\\":\\"#/components/schemas/CreateResponseRequest\\"}}},\\"description\\":\\"The input prompt and parameters\\",\\"required\\":true},\\"responses\\":{\\"200\\":{\\"content\\":{\\"application/json\\":{\\"schema\\":{\\"$ref\\":\\"#/components/schemas/CreateResponseResponse\\"}}},\\"description\\":\\"OK\\"}},\\"summary\\":\\"Creates a model response for the given input.\\",\\"tags\\":\[\\"Responses\\"\],\\"x-groq-metadata\\":{\\"examples\\":\[{\\"request\\":{\\"curl\\":\\"curl https://api.groq.com/openai/v1/responses -s \\\\\\\\\\\\n-H \\\\\\"Content-Type: application/json\\\\\\" \\\\\\\\\\\\n-H \\\\\\"Authorization: Bearer $GROQ\_API\_KEY\\\\\\" \\\\\\\\\\\\n-d '{\\\\n \\\\\\"model\\\\\\": \\\\\\"gpt-oss\\\\\\",\\\\n \\\\\\"input\\\\\\": \\\\\\"Tell me a three sentence bedtime story about a unicorn.\\\\\\"\\\\n}'\\\\n\\"},\\"response\\":\\"$36\\",\\"title\\":\\"Default\\"}\],\\"returns\\":\\"Returns a \[response\](/docs/api-reference#responses-create) object, or a streamed sequence of \[response events\](/docs/api-reference#responses-streaming) if the request is streamed.\\"}}},\\"/v1/fine\_tunings\\":{\\"get\\":{\\"operationId\\":\\"listFineTunings\\",\\"responses\\":{\\"200\\":{\\"content\\":{\\"application/json\\":{\\"schema\\":{\\"$ref\\":\\"#/components/schemas/ListFineTuningsResponse\\"}}},\\"description\\":\\"OK\\"}},\\"summary\\":\\"Lists all previously created fine tunings. This endpoint is in closed beta. \[Contact us\](https://groq.com/contact) for more information.\\",\\"tags\\":\[\\"Fine Tuning\\"\],\\"x-groq-metadata\\":{\\"examples\\":\[{\\"request\\":{\\"curl\\":\\"curl https://api.groq.com/v1/fine\_tunings -s \\\\\\\\\\\\n -H \\\\\\"Content-Type: application/json\\\\\\" \\\\\\\\\\\\n -H \\\\\\"Authorization: Bearer $GROQ\_API\_KEY\\\\\\"\\\\n\\",\\"js\\":\\"import Groq from \\\\\\"groq-sdk\\\\\\";\\\\n\\\\nconst groq = new Groq({ apiKey: process.env.GROQ\_API\_KEY });\\\\n\\\\nasync function main() {\\\\n const fineTunings = await groq.fine\_tunings.list();\\\\n console.log(fineTunings);\\\\n}\\\\n\\\\nmain();\\\\n\\",\\"py\\":\\"import os\\\\n\\\\nfrom groq import Groq\\\\n\\\\nclient = Groq(\\\\n # This is the default and can be omitted\\\\n api\_key=os.environ.get(\\\\\\"GROQ\_API\_KEY\\\\\\"),\\\\n)\\\\n\\\\nfine\_tunings = client.fine\_tunings.list()\\\\n\\\\nprint(fine\_tunings)\\\\n\\"},\\"response\\":\\"{\\\\n \\\\\\"object\\\\\\": \\\\\\"list\\\\\\",\\\\n \\\\\\"data\\\\\\": \[\\\\n {\\\\n \\\\\\"id\\\\\\": \\\\\\"string\\\\\\",\\\\n \\\\\\"name\\\\\\": \\\\\\"string\\\\\\",\\\\n \\\\\\"base\_model\\\\\\": \\\\\\"string\\\\\\",\\\\n \\\\\\"type\\\\\\": \\\\\\"string\\\\\\",\\\\n \\\\\\"input\_file\_id\\\\\\": \\\\\\"string\\\\\\",\\\\n \\\\\\"created\_at\\\\\\": 0,\\\\n \\\\\\"fine\_tuned\_model\\\\\\": \\\\\\"string\\\\\\"\\\\n }\\\\n \]\\\\n}\\\\n\\",\\"title\\":\\"Default\\"}\],\\"returns\\":\\"The list of fine tunes\\"}},\\"post\\":{\\"operationId\\":\\"createFineTuning\\",\\"requestBody\\":{\\"content\\":{\\"application/json\\":{\\"schema\\":{\\"$ref\\":\\"#/components/schemas/CreateFineTuningRequest\\"}}}},\\"responses\\":{\\"200\\":{\\"content\\":{\\"application/json\\":{\\"schema\\":{\\"$ref\\":\\"#/components/schemas/ReadFineTuningResponse\\"}}},\\"description\\":\\"OK\\"}},\\"summary\\":\\"Creates a new fine tuning for the already uploaded files This endpoint is in closed beta. \[Contact us\](https://groq.com/contact) for more information.\\",\\"tags\\":\[\\"Fine Tuning\\"\],\\"x-groq-metadata\\":{\\"examples\\":\[{\\"request\\":{\\"curl\\":\\"curl https://api.groq.com/v1/fine\_tunings -s \\\\\\\\\\\\n -H \\\\\\"Content-Type: application/json\\\\\\" \\\\\\\\\\\\n -H \\\\\\"Authorization: Bearer $GROQ\_API\_KEY\\\\\\" \\\\\\\\\\\\n -d '{\\\\n \\\\\\"input\_file\_id\\\\\\": \\\\\\"\\u003cfile-id\\u003e\\\\\\",\\\\n \\\\\\"name\\\\\\": \\\\\\"test-1\\\\\\",\\\\n \\\\\\"type\\\\\\": \\\\\\"lora\\\\\\",\\\\n \\\\\\"base\_model\\\\\\": \\\\\\"llama-3.1-8b-instant\\\\\\"\\\\n }'\\\\n\\",\\"js\\":\\"import Groq from \\\\\\"groq-sdk\\\\\\";\\\\n\\\\nconst groq = new Groq({ apiKey: process.env.GROQ\_API\_KEY });\\\\n\\\\nasync function main() {\\\\n const fineTunings = await groq.fine\_tunings.create({\\\\n input\_file\_id: \\\\\\"\\u003cfile-id\\u003e\\\\\\",\\\\n name: \\\\\\"test-1\\\\\\",\\\\n type: \\\\\\"lora\\\\\\",\\\\n base\_model: \\\\\\"llama-3.1-8b-instant\\\\\\"\\\\n });\\\\n console.log(fineTunings);\\\\n}\\\\n\\\\nmain();\\\\n\\",\\"py\\":\\"import os\\\\n\\\\nfrom groq import Groq\\\\n\\\\nclient = Groq(\\\\n # This is the default and can be omitted\\\\n api\_key=os.environ.get(\\\\\\"GROQ\_API\_KEY\\\\\\"),\\\\n)\\\\n\\\\nfine\_tunings = client.fine\_tunings.create(\\\\n input\_file\_id=\\\\\\"\\u003cfile-id\\u003e\\\\\\",\\\\n name=\\\\\\"test-1\\\\\\",\\\\n type=\\\\\\"lora\\\\\\",\\\\n base\_model=\\\\\\"llama-3.1-8b-instant\\\\\\"\\\\n)\\\\n\\\\nprint(fine\_tunings)\\\\n\\"},\\"response\\":\\"{\\\\n \\\\\\"id\\\\\\": \\\\\\"string\\\\\\",\\\\n \\\\\\"object\\\\\\": \\\\\\"object\\\\\\",\\\\n \\\\\\"data\\\\\\": {\\\\n \\\\\\"id\\\\\\": \\\\\\"string\\\\\\",\\\\n \\\\\\"name\\\\\\": \\\\\\"string\\\\\\",\\\\n \\\\\\"base\_model\\\\\\": \\\\\\"string\\\\\\",\\\\n \\\\\\"type\\\\\\": \\\\\\"string\\\\\\",\\\\n \\\\\\"input\_file\_id\\\\\\": \\\\\\"string\\\\\\",\\\\n \\\\\\"created\_at\\\\\\": 0,\\\\n \\\\\\"fine\_tuned\_model\\\\\\": \\\\\\"string\\\\\\"\\\\n }\\\\n}\\\\n\\",\\"title\\":\\"Default\\"}\],\\"returns\\":\\"The newly created fine tune\\"}}},\\"/v1/fine\_tunings/{id}\\":{\\"delete\\":{\\"operationId\\":\\"deleteFineTuning\\",\\"parameters\\":\[{\\"in\\":\\"path\\",\\"name\\":\\"id\\",\\"required\\":true,\\"schema\\":{\\"type\\":\\"string\\"}}\],\\"responses\\":{\\"200\\":{\\"content\\":{\\"application/json\\":{\\"schema\\":{\\"$ref\\":\\"#/components/schemas/DeleteFineTuningResponse\\"}}},\\"description\\":\\"OK\\"}},\\"summary\\":\\"Deletes an existing fine tuning by id This endpoint is in closed beta. \[Contact us\](https://groq.com/contact) for more information.\\",\\"tags\\":\[\\"Fine Tuning\\"\],\\"x-groq-metadata\\":{\\"examples\\":\[{\\"request\\":{\\"curl\\":\\"curl -X DELETE https://api.groq.com/v1/fine\_tunings/:id -s \\\\\\\\\\\\n -H \\\\\\"Content-Type: application/json\\\\\\" \\\\\\\\\\\\n -H \\\\\\"Authorization: Bearer $GROQ\_API\_KEY\\\\\\"\\\\n\\",\\"js\\":\\"import Groq from \\\\\\"groq-sdk\\\\\\";\\\\n\\\\nconst groq = new Groq({ apiKey: process.env.GROQ\_API\_KEY });\\\\n\\\\nasync function main() {\\\\n await groq.fine\_tunings.delete({id: \\\\\\"\\u003cid\\u003e\\\\\\"});\\\\n}\\\\n\\\\nmain();\\\\n\\",\\"py\\":\\"import os\\\\n\\\\nfrom groq import Groq\\\\n\\\\nclient = Groq(\\\\n # This is the default and can be omitted\\\\n api\_key=os.environ.get(\\\\\\"GROQ\_API\_KEY\\\\\\"),\\\\n)\\\\n\\\\nclient.fine\_tunings.delete(id=\\\\\\"\\u003cid\\u003e\\\\\\")\\\\n\\"},\\"response\\":\\"{\\\\n \\\\\\"id\\\\\\": \\\\\\"string\\\\\\",\\\\n \\\\\\"object\\\\\\": \\\\\\"fine\_tuning\\\\\\",\\\\n \\\\\\"deleted\\\\\\": true\\\\n}\\\\n\\",\\"title\\":\\"Default\\"}\],\\"returns\\":\\"A confirmation of the deleted fine tune\\"}},\\"get\\":{\\"operationId\\":\\"getFineTuning\\",\\"parameters\\":\[{\\"in\\":\\"path\\",\\"name\\":\\"id\\",\\"required\\":true,\\"schema\\":{\\"type\\":\\"string\\"}}\],\\"responses\\":{\\"200\\":{\\"content\\":{\\"application/json\\":{\\"schema\\":{\\"$ref\\":\\"#/components/schemas/ReadFineTuningResponse\\"}}},\\"description\\":\\"OK\\"}},\\"summary\\":\\"Retrieves an existing fine tuning by id This endpoint is in closed beta. \[Contact us\](https://groq.com/contact) for more information.\\",\\"tags\\":\[\\"Fine Tuning\\"\],\\"x-groq-metadata\\":{\\"examples\\":\[{\\"request\\":{\\"curl\\":\\"curl https://api.groq.com/v1/fine\_tunings/:id -s \\\\\\\\\\\\n -H \\\\\\"Content-Type: application/json\\\\\\" \\\\\\\\\\\\n -H \\\\\\"Authorization: Bearer $GROQ\_API\_KEY\\\\\\"\\\\n\\",\\"js\\":\\"import Groq from \\\\\\"groq-sdk\\\\\\";\\\\n\\\\nconst groq = new Groq({ apiKey: process.env.GROQ\_API\_KEY });\\\\n\\\\nasync function main() {\\\\n const fineTuning = await groq.fine\_tunings.get({id: \\\\\\"\\u003cid\\u003e\\\\\\"});\\\\n console.log(fineTuning);\\\\n}\\\\n\\\\nmain();\\\\n\\",\\"py\\":\\"import os\\\\n\\\\nfrom groq import Groq\\\\n\\\\nclient = Groq(\\\\n # This is the default and can be omitted\\\\n api\_key=os.environ.get(\\\\\\"GROQ\_API\_KEY\\\\\\"),\\\\n)\\\\n\\\\nfine\_tuning = client.fine\_tunings.get(id=\\\\\\"\\u003cid\\u003e\\\\\\")\\\\n\\\\nprint(fine\_tuning)\\\\n\\"},\\"response\\":\\"{\\\\n \\\\\\"id\\\\\\": \\\\\\"string\\\\\\",\\\\n \\\\\\"object\\\\\\": \\\\\\"object\\\\\\",\\\\n \\\\\\"data\\\\\\": {\\\\n \\\\\\"id\\\\\\": \\\\\\"string\\\\\\",\\\\n \\\\\\"name\\\\\\": \\\\\\"string\\\\\\",\\\\n \\\\\\"base\_model\\\\\\": \\\\\\"string\\\\\\",\\\\n \\\\\\"type\\\\\\": \\\\\\"string\\\\\\",\\\\n \\\\\\"input\_file\_id\\\\\\": \\\\\\"string\\\\\\",\\\\n \\\\\\"created\_at\\\\\\": 0,\\\\n \\\\\\"fine\_tuned\_model\\\\\\": \\\\\\"string\\\\\\"\\\\n }\\\\n}\\\\n\\",\\"title\\":\\"Default\\"}\],\\"returns\\":\\"A fine tune metadata object\\"}}}},\\"security\\":\[{\\"api\_key\\":\[\]}\],\\"servers\\":\[{\\"url\\":\\"https://api.groq.com\\"}\],\\"x-groq-metadata\\":{\\"groups\\":\[{\\"description\\":\\"\\",\\"id\\":\\"chat\\",\\"sections\\":\[{\\"key\\":\\"createChatCompletion\\",\\"path\\":\\"create\\",\\"type\\":\\"endpoint\\"}\],\\"title\\":\\"Chat\\",\\"type\\":\\"endpoints\\"},{\\"description\\":\\"\\",\\"id\\":\\"responses\\",\\"sections\\":\[{\\"key\\":\\"createResponse\\",\\"path\\":\\"create\\",\\"type\\":\\"endpoint\\"}\],\\"title\\":\\"Responses (beta)\\",\\"type\\":\\"endpoints\\"},{\\"description\\":\\"\\",\\"id\\":\\"audio\\",\\"sections\\":\[{\\"key\\":\\"createTranscription\\",\\"path\\":\\"transcription\\",\\"type\\":\\"endpoint\\"},{\\"key\\":\\"createTranslation\\",\\"path\\":\\"translation\\",\\"type\\":\\"endpoint\\"},{\\"key\\":\\"createSpeech\\",\\"path\\":\\"speech\\",\\"type\\":\\"endpoint\\"}\],\\"title\\":\\"Audio\\",\\"type\\":\\"endpoints\\"},{\\"description\\":\\"\\",\\"id\\":\\"models\\",\\"sections\\":\[{\\"key\\":\\"listModels\\",\\"path\\":\\"list\\",\\"type\\":\\"endpoint\\"},{\\"key\\":\\"retrieveModel\\",\\"path\\":\\"retrieve\\",\\"type\\":\\"endpoint\\"}\],\\"title\\":\\"Models\\",\\"type\\":\\"endpoints\\"},{\\"description\\":\\"\\",\\"id\\":\\"batches\\",\\"sections\\":\[{\\"key\\":\\"createBatch\\",\\"path\\":\\"create\\",\\"type\\":\\"endpoint\\"},{\\"key\\":\\"retrieveBatch\\",\\"path\\":\\"retrieve\\",\\"type\\":\\"endpoint\\"},{\\"key\\":\\"listBatches\\",\\"path\\":\\"list\\",\\"type\\":\\"endpoint\\"},{\\"key\\":\\"cancelBatch\\",\\"path\\":\\"cancel\\",\\"type\\":\\"endpoint\\"}\],\\"title\\":\\"Batches\\",\\"type\\":\\"endpoints\\"},{\\"description\\":\\"\\",\\"id\\":\\"files\\",\\"sections\\":\[{\\"key\\":\\"uploadFile\\",\\"path\\":\\"upload\\",\\"type\\":\\"endpoint\\"},{\\"key\\":\\"listFiles\\",\\"path\\":\\"list\\",\\"type\\":\\"endpoint\\"},{\\"key\\":\\"deleteFile\\",\\"path\\":\\"delete\\",\\"type\\":\\"endpoint\\"},{\\"key\\":\\"retrieveFile\\",\\"path\\":\\"retrieve\\",\\"type\\":\\"endpoint\\"},{\\"key\\":\\"downloadFile\\",\\"path\\":\\"download\\",\\"type\\":\\"endpoint\\"}\],\\"title\\":\\"Files\\",\\"type\\":\\"endpoints\\"},{\\"description\\":\\"\\",\\"id\\":\\"fine-tuning\\",\\"sections\\":\[{\\"key\\":\\"listFineTunings\\",\\"path\\":\\"list\\",\\"type\\":\\"endpoint\\"},{\\"key\\":\\"createFineTuning\\",\\"path\\":\\"create\\",\\"type\\":\\"endpoint\\"},{\\"key\\":\\"getFineTuning\\",\\"path\\":\\"get\\",\\"type\\":\\"endpoint\\"},{\\"key\\":\\"deleteFineTuning\\",\\"path\\":\\"delete\\",\\"type\\":\\"endpoint\\"}\],\\"title\\":\\"Fine Tuning\\",\\"type\\":\\"endpoints\\"}\]}},\\"children\\":\[\\"$\\",\\"$L5\\",null,{\\"parallelRouterKey\\":\\"children\\",\\"error\\":\\"$undefined\\",\\"errorStyles\\":\\"$undefined\\",\\"errorScripts\\":\\"$undefined\\",\\"template\\":\[\\"$\\",\\"$L6\\",null,{}\],\\"templateStyles\\":\\"$undefined\\",\\"templateScripts\\":\\"$undefined\\",\\"notFound\\":\\"$undefined\\",\\"forbidden\\":\\"$undefined\\",\\"unauthorized\\":\\"$undefined\\"}\]}\]\\n"\])self.\_\_next\_f.push(\[1,"37:I\[57863,\[\\"8779\\",\\"static/chunks/8285d696-4c2af9547952b91b.js\\",\\"7487\\",\\"static/chunks/b3b06311-fa77c49096c4cc97.js\\",\\"7539\\",\\"static/chunks/1f447996-8974f1b7e13f2cb9.js\\",\\"8455\\",\\"static/chunks/d611311c-7b5735a4c92c90d9.js\\",\\"3596\\",\\"static/chunks/3596-81e8162c1dd9940f.js\\",\\"888\\",\\"static/chunks/888-7cd7f38e76441637.js\\",\\"1466\\",\\"static/chunks/1466-ba3c67344a908bbe.js\\",\\"1727\\",\\"static/chunks/1727-8cb7c763d81e3223.js\\",\\"7213\\",\\"static/chunks/7213-443f51519115da15.js\\",\\"7177\\",\\"static/chunks/app/layout-a8184e653bbd672b.js\\"\],\\"PostHogClientProvider\\"\]\\n38:I\[82615,\[\\"8779\\",\\"static/chunks/8285d696-4c2af9547952b91b.js\\",\\"7487\\",\\"static/chunks/b3b06311-fa77c49096c4cc97.js\\",\\"7539\\",\\"static/chunks/1f447996-8974f1b7e13f2cb9.js\\",\\"8455\\",\\"static/chunks/d611311c-7b5735a4c92c90d9.js\\",\\"3596\\",\\"static/chunks/3596-81e8162c1dd9940f.js\\",\\"888\\",\\"static/chunks/888-7cd7f38e76441637.js\\",\\"1466\\",\\"static/chunks/1466-ba3c67344a908bbe.js\\",\\"1727\\",\\"static/chunks/1727-8cb7c763d81e3223.js\\",\\"7213\\",\\"static/chunks/7213-443f51519115da15.js\\",\\"7177\\",\\"static/chunks/app/layout-a8184e653bbd672b.js\\"\],\\"ClientProviders\\"\]\\n"\])self.\_\_next\_f.push(\[1,"2f:\[\\"$\\",\\"$L37\\",null,{\\"flags\\":{\\"orion-remote-config\\":true,\\"cards-ordering\\":\\"control\\",\\"data-controls-chat-completions\\":true,\\"projects\\":true,\\"billing-improved-upgrade-message\\":\\"test\\",\\"home-hero-usage-redesign\\":\\"control\\",\\"ff-invoice-retry\\":true,\\"survey-targeting-0ac5ca675d-custom\\":true,\\"survey-targeting-ac30499a63\\":false,\\"top\_loader\\":false,\\"ff-chat-scroll-trap\\":true,\\"model-limits\\":true,\\"abab-testing\\":true,\\"survey-targeting-e28db87db8-custom\\":true,\\"home-cards\\":\\"control\\",\\"survey-targeting-7869e3894d-custom\\":true,\\"billing\_limits\\":true,\\"survey-targeting-956d3e0f6c-custom\\":true,\\"saved-prompts\\":false,\\"ff-enable-sso-selfserve\\":true,\\"server-side-mcp-preview\\":false,\\"function-calling\\":false,\\"data-controls\\":true,\\"ff-ssrl-enabled\\":false},\\"userIdentity\\":{\\"id\\":\\"0635e099-eadf-4c22-b1e7-cacbfdd22123\\",\\"name\\":\\"$undefined\\",\\"email\\":\\"$undefined\\",\\"isIdentified\\":false},\\"children\\":\[\\"$\\",\\"$L38\\",null,{\\"layoutPreferences\\":{},\\"children\\":\[\\"$\\",\\"$L5\\",null,{\\"parallelRouterKey\\":\\"children\\",\\"error\\":\\"$undefined\\",\\"errorStyles\\":\\"$undefined\\",\\"errorScripts\\":\\"$undefined\\",\\"template\\":\[\\"$\\",\\"$L6\\",null,{}\],\\"templateStyles\\":\\"$undefined\\",\\"templateScripts\\":\\"$undefined\\",\\"notFound\\":\[\[\[\\"$\\",\\"title\\",null,{\\"children\\":\\"404: This page could not be found.\\"}\],\[\\"$\\",\\"div\\",null,{\\"style\\":\\"$0:f:0:1:2:children:1:props:children:1:props:slots:children:props:notFound:0:1:props:style\\",\\"children\\":\[\\"$\\",\\"div\\",null,{\\"children\\":\[\[\\"$\\",\\"style\\",null,{\\"dangerouslySetInnerHTML\\":{\\"\_\_html\\":\\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\\"}}\],\[\\"$\\",\\"h1\\",null,{\\"className\\":\\"next-error-h1\\",\\"style\\":\\"$0:f:0:1:2:children:1:props:children:1:props:slots:children:props:notFound:0:1:props:children:props:children:1:props:style\\",\\"children\\":404}\],\[\\"$\\",\\"div\\",null,{\\"style\\":\\"$0:f:0:1:2:children:1:props:children:1:props:slots:children:props:notFound:0:1:props:children:props:children:2:props:style\\",\\"children\\":\[\\"$\\",\\"h2\\",null,{\\"style\\":\\"$0:f:0:1:2:children:1:props:children:1:props:slots:children:props:notFound:0:1:props:children:props:children:2:props:children:props:style\\",\\"children\\":\\"This page could not be found.\\"}\]}\]\]}\]}\]\],\[\]\],\\"forbidden\\":\\"$undefined\\",\\"unauthorized\\":\\"$undefined\\"}\]}\]}\]\\n"\])!function(){try{var d=document.documentElement,c=d.classList;c.remove('light','dark');var e=localStorage.getItem('theme');if('system'===e||(!e&&true)){var t='(prefers-color-scheme: dark)',m=window.matchMedia(t);if(m.media!==t||m.matches){d.style.colorScheme = 'dark';c.add('dark')}else{d.style.colorScheme = 'light';c.add('light')}}else if(e){c.add(e|| '')}if(e==='light'||e==='dark')d.style.colorScheme=e}catch(e){}}()

[![Groq](/groq-logo.svg)](/home)

[Docs](/docs/overview)[Login](/home)

[Playground](/playground)

[API Keys](/keys)

[Dashboard](/dashboard)

[Docs](/docs)

[](/settings)

[Log In](/login)

## Documentation

[Docs](/docs/overview)[API Reference](/docs/api-reference)

SearchK

Structured Outputs

## Docs

### Get Started

[Overview](/docs/overview)[Quickstart](/docs/quickstart)[OpenAI Compatibility](/docs/openai)[Responses API](/docs/responses-api)[Models](/docs/models)[Rate Limits](/docs/rate-limits)[Examples](/docs/examples)

### Features

[Text Generation](/docs/text-chat)[Speech to Text](/docs/speech-to-text)[Text to Speech](/docs/text-to-speech)[Images and Vision](/docs/vision)[Reasoning](/docs/reasoning)[Structured Outputs](/docs/structured-outputs)

### Built-In Tools

[Web Search](/docs/web-search)[Browser Search](/docs/browser-search)[Visit Website](/docs/visit-website)[Browser Automation](/docs/browser-automation)[Code Execution](/docs/code-execution)[Wolfram Alpha](/docs/wolfram-alpha)

### Compound

[Overview](/docs/compound)[Systems](/docs/compound/systems)[Compound](/docs/compound/systems/compound)[Compound Mini](/docs/compound/systems/compound-mini)[Built-In Tools](/docs/compound/built-in-tools)[Use Cases](/docs/compound/use-cases)

### Advanced Features

[Batch Processing](/docs/batch)[Flex Processing](/docs/flex-processing)[Content Moderation](/docs/content-moderation)[Prefilling](/docs/prefilling)[Tool Use](/docs/tool-use)[Remote MCP](/docs/mcp)[LoRA Inference](/docs/lora)

### Prompting Guide

[Prompt Basics](/docs/prompting)[Prompt Patterns](/docs/prompting/patterns)[Model Migration](/docs/prompting/model-migration)[Prompt Caching](/docs/prompt-caching)

### Production Readiness

[Optimizing Latency](/docs/production-readiness/optimizing-latency)[Production Checklist](/docs/production-readiness/production-ready-checklist)[Security Onboarding](/docs/production-readiness/security-onboarding)

### Developer Resources

[Groq Libraries](/docs/libraries)[Groq Badge](/docs/badge)[Integrations Catalog](/docs/integrations)

### Console

[Spend Limits](/docs/spend-limits)[Projects](/docs/projects)[Model Permissions](/docs/model-permissions)[Billing FAQs](/docs/billing-faqs)[Your Data](/docs/your-data)

### Support & Guidelines

[Developer Community](https://community.groq.com)[OpenBench](https://openbench.dev)[Errors](/docs/errors)[Changelog](/docs/changelog)[Compound Systems](/docs/changelog/compound)[Policies & Notices](/docs/legal)

SearchK

[Docs](/docs/overview)[API Reference](/docs/api-reference)

### Get Started

[Overview](/docs/overview)

[Quickstart](/docs/quickstart)

[OpenAI Compatibility](/docs/openai)

[Responses API](/docs/responses-api)

[Models](/docs/models)

[Rate Limits](/docs/rate-limits)

[Examples](/docs/examples)

### Features

[Text Generation](/docs/text-chat)

[Speech to Text](/docs/speech-to-text)

[Text to Speech](/docs/text-to-speech)

[Images and Vision](/docs/vision)

[Reasoning](/docs/reasoning)

[Structured Outputs](/docs/structured-outputs)

### Built-In Tools

[Web Search](/docs/web-search)

[Browser Search](/docs/browser-search)

[Visit Website](/docs/visit-website)

[Browser Automation](/docs/browser-automation)

[Code Execution](/docs/code-execution)

[Wolfram Alpha](/docs/wolfram-alpha)

### Compound

[Overview](/docs/compound)

[Systems](/docs/compound/systems)

[Built-In Tools](/docs/compound/built-in-tools)

[Use Cases](/docs/compound/use-cases)

### Advanced Features

[Batch Processing](/docs/batch)

[Flex Processing](/docs/flex-processing)

[Content Moderation](/docs/content-moderation)

[Prefilling](/docs/prefilling)

[Tool Use](/docs/tool-use)

[Remote MCP](/docs/mcp)

[LoRA Inference](/docs/lora)

### Prompting Guide

[Prompt Basics](/docs/prompting)

[Prompt Patterns](/docs/prompting/patterns)

[Model Migration](/docs/prompting/model-migration)

[Prompt Caching](/docs/prompt-caching)

### Production Readiness

[Optimizing Latency](/docs/production-readiness/optimizing-latency)

[Production Checklist](/docs/production-readiness/production-ready-checklist)

[Security Onboarding](/docs/production-readiness/security-onboarding)

### Developer Resources

[Groq Libraries](/docs/libraries)

[Groq Badge](/docs/badge)

[Integrations Catalog](/docs/integrations)

### Console

[Spend Limits](/docs/spend-limits)

[Projects](/docs/projects)

[Model Permissions](/docs/model-permissions)

[Billing FAQs](/docs/billing-faqs)

[Your Data](/docs/your-data)

### Support & Guidelines

[Developer Community](https://community.groq.com)

[OpenBench](https://openbench.dev)

[Errors](/docs/errors)

[Changelog](/docs/changelog)

[Policies & Notices](/docs/legal)

# Structured Outputs

Copy page

Guarantee model responses strictly conform to your JSON schema for reliable, type-safe data structures.

## [Introduction](#introduction)

Structured Outputs is a feature that makes your model responses strictly conform to your provided [JSON Schema](https://json-schema.org/overview/what-is-jsonschema) or throws an error if the model cannot produce a compliant response. The endpoint provides customers with the ability to obtain reliable data structures.

  

This feature's performance is dependent on the model's ability to produce a valid answer that matches your schema. If the model fails to generate a conforming response, the endpoint will return an error rather than an invalid or incomplete result.

  

Key benefits:

1.  **Binary output:** Either returns valid JSON Schema-compliant output or throws an error
2.  **Type-safe responses:** No need to validate or retry malformed outputs
3.  **Programmatic refusal detection:** Detect safety-based model refusals programmatically
4.  **Simplified prompting:** No complex prompts needed for consistent formatting

  

In addition to supporting Structured Outputs in our API, our SDKs also enable you to easily define your schemas with [Pydantic](https://docs.pydantic.dev/latest/) and [Zod](https://zod.dev/) to ensure further type safety. The examples below show how to extract structured information from unstructured text.

## [Supported models](#supported-models)

Structured Outputs is available with the following models:

Model ID

Model

`openai/gpt-oss-20b`

[GPT-OSS 20B](/docs/model/openai/gpt-oss-20b)

`openai/gpt-oss-120b`

[GPT-OSS 120B](/docs/model/openai/gpt-oss-120b)

`openai/gpt-oss-safeguard-20b`

[Safety GPT OSS 20B](/docs/model/openai/gpt-oss-safeguard-20b)

`moonshotai/kimi-k2-instruct-0905`

[Kimi K2 Instruct](/docs/model/moonshotai/kimi-k2-instruct-0905)

`meta-llama/llama-4-maverick-17b-128e-instruct`

[Llama 4 Maverick](/docs/model/meta-llama/llama-4-maverick-17b-128e-instruct)

`meta-llama/llama-4-scout-17b-16e-instruct`

[Llama 4 Scout](/docs/model/meta-llama/llama-4-scout-17b-16e-instruct)

  

For all other models, you can use [JSON Object Mode](#json-object-mode) to get a valid JSON object, though it may not match your schema.

  

**Note:** [streaming](/docs/text-chat#streaming-a-chat-completion) and [tool use](/docs/tool-use) are not currently supported with Structured Outputs.

### [Getting a structured response from unstructured text](#getting-a-structured-response-from-unstructured-text)

JavaScript

```
1import Groq from "groq-sdk";
2
3const groq = new Groq();
4
5const response = await groq.chat.completions.create({
6  model: "moonshotai/kimi-k2-instruct-0905",
7  messages: [
8    { role: "system", content: "Extract product review information from the text." },
9    {
10      role: "user",
11      content: "I bought the UltraSound Headphones last week and I'm really impressed! The noise cancellation is amazing and the battery lasts all day. Sound quality is crisp and clear. I'd give it 4.5 out of 5 stars.",
12    },
13  ],
14  response_format: {
15    type: "json_schema",
16    json_schema: {
17      name: "product_review",
18      schema: {
19        type: "object",
20        properties: {
21          product_name: { type: "string" },
22          rating: { type: "number" },
23          sentiment: { 
24            type: "string",
25            enum: ["positive", "negative", "neutral"]
26          },
27          key_features: { 
28            type: "array",
29            items: { type: "string" }
30          }
31        },
32        required: ["product_name", "rating", "sentiment", "key_features"],
33        additionalProperties: false
34      }
35    }
36  }
37});
38
39const result = JSON.parse(response.choices[0].message.content || "{}");
40console.log(result);
```

```
from groq import Groq
from pydantic import BaseModel
from typing import Literal
import json

client = Groq()

class ProductReview(BaseModel):
    product_name: str
    rating: float
    sentiment: Literal["positive", "negative", "neutral"]
    key_features: list[str]

response = client.chat.completions.create(
    model="moonshotai/kimi-k2-instruct-0905",
    messages=[
        {"role": "system", "content": "Extract product review information from the text."},
        {
            "role": "user",
            "content": "I bought the UltraSound Headphones last week and I'm really impressed! The noise cancellation is amazing and the battery lasts all day. Sound quality is crisp and clear. I'd give it 4.5 out of 5 stars.",
        },
    ],
    response_format={
        "type": "json_schema",
        "json_schema": {
            "name": "product_review",
            "schema": ProductReview.model_json_schema()
        }
    }
)

review = ProductReview.model_validate(json.loads(response.choices[0].message.content))
print(json.dumps(review.model_dump(), indent=2))
```

```
curl https://api.groq.com/openai/v1/chat/completions \
  -H "Authorization: Bearer $GROQ_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "moonshotai/kimi-k2-instruct-0905",
    "messages": [
      {
        "role": "system",
        "content": "Extract product review information from the text."
      },
      {
        "role": "user",
        "content": "I bought the UltraSound Headphones last week and I'\''m really impressed! The noise cancellation is amazing and the battery lasts all day. Sound quality is crisp and clear. I'\''d give it 4.5 out of 5 stars."
      }
    ],
    "response_format": {
      "type": "json_schema",
      "json_schema": {
        "name": "product_review",
        "schema": {
          "type": "object",
          "properties": {
            "product_name": { "type": "string" },
            "rating": { "type": "number" },
            "sentiment": { 
              "type": "string",
              "enum": ["positive", "negative", "neutral"]
            },
            "key_features": { 
              "type": "array",
              "items": { "type": "string" }
            }
          },
          "required": ["product_name", "rating", "sentiment", "key_features"],
          "additionalProperties": false
        }
      }
    }
  }'
```

Example Output

JSON

```
{
  product_name: 'UltraSound Headphones',
  rating: 4.5,
  sentiment: 'positive',
  key_features: [
    'amazing noise cancellation',
    'all-day battery life',
    'crisp and clear sound quality'
  ]
}
```

### [Structured Outputs vs JSON mode](#structured-outputs-vs-json-mode)

Structured Outputs builds on [JSON Object Mode](#json-object-mode) with enhanced capabilities. Both produce valid JSON, but Structured Outputs goes further by matching your response to your schema exactly or throws an error if the model cannot produce a conforming response.

  

**Note:** Constrained decoding (which is designed to output JSON Schema compliance without errors) is currently only available on a limited-access Llama 3.1 8B model. For all other models, the endpoint attempts validation that may return errors if the model cannot produce a conforming response.

  

We recommend using Structured Outputs instead of JSON Object Mode whenever possible.

## [Examples](#examples)

SQL Query GenerationEmail ClassificationAPI Response Validation

### [SQL Query Generation](#sql-query-generation)

You can generate structured SQL queries from natural language descriptions, helping ensure proper syntax and including metadata about the query structure.

  

JavaScript

```
1import Groq from "groq-sdk";
2
3const groq = new Groq();
4
5const response = await groq.chat.completions.create({
6  model: "moonshotai/kimi-k2-instruct-0905",
7  messages: [
8    {
9      role: "system",
10      content: "You are a SQL expert. Generate structured SQL queries from natural language descriptions with proper syntax validation and metadata.",
11    },
12    { role: "user", content: "Find all customers who made orders over $500 in the last 30 days, show their name, email, and total order amount" },
13  ],
14  response_format: {
15    type: "json_schema",
16    json_schema: {
17      name: "sql_query_generation",
18      schema: {
19        type: "object",
20        properties: {
21          query: { type: "string" },
22          query_type: { 
23            type: "string", 
24            enum: ["SELECT", "INSERT", "UPDATE", "DELETE", "CREATE", "ALTER", "DROP"] 
25          },
26          tables_used: {
27            type: "array",
28            items: { type: "string" }
29          },
30          estimated_complexity: {
31            type: "string",
32            enum: ["low", "medium", "high"]
33          },
34          execution_notes: {
35            type: "array",
36            items: { type: "string" }
37          },
38          validation_status: {
39            type: "object",
40            properties: {
41              is_valid: { type: "boolean" },
42              syntax_errors: {
43                type: "array",
44                items: { type: "string" }
45              }
46            },
47            required: ["is_valid", "syntax_errors"],
48            additionalProperties: false
49          }
50        },
51        required: ["query", "query_type", "tables_used", "estimated_complexity", "execution_notes", "validation_status"],
52        additionalProperties: false
53      }
54    }
55  }
56});
57
58const result = JSON.parse(response.choices[0].message.content || "{}");
59console.log(result);
```

```
from groq import Groq
from pydantic import BaseModel
import json

client = Groq()

class ValidationStatus(BaseModel):
    is_valid: bool
    syntax_errors: list[str]

class SQLQueryGeneration(BaseModel):
    query: str
    query_type: str
    tables_used: list[str]
    estimated_complexity: str
    execution_notes: list[str]
    validation_status: ValidationStatus

response = client.chat.completions.create(
    model="moonshotai/kimi-k2-instruct-0905",
    messages=[
        {
            "role": "system",
            "content": "You are a SQL expert. Generate structured SQL queries from natural language descriptions with proper syntax validation and metadata.",
        },
        {"role": "user", "content": "Find all customers who made orders over $500 in the last 30 days, show their name, email, and total order amount"},
    ],
    response_format={
        "type": "json_schema",
        "json_schema": {
            "name": "sql_query_generation",
            "schema": SQLQueryGeneration.model_json_schema()
        }
    }
)

sql_query_generation = SQLQueryGeneration.model_validate(json.loads(response.choices[0].message.content))
print(json.dumps(sql_query_generation.model_dump(), indent=2))
```

```
curl https://api.groq.com/openai/v1/chat/completions \
  -H "Authorization: Bearer $GROQ_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "moonshotai/kimi-k2-instruct-0905",
    "messages": [
      {
        "role": "system",
        "content": "You are a SQL expert. Generate structured SQL queries from natural language descriptions with proper syntax validation and metadata."
      },
      {
        "role": "user",
        "content": "Find all customers who made orders over $500 in the last 30 days, show their name, email, and total order amount"
      }
    ],
    "response_format": {
      "type": "json_schema",
      "json_schema": {
        "name": "sql_query_generation",
        "schema": {
          "type": "object",
          "properties": {
            "query": { "type": "string" },
            "query_type": { 
              "type": "string", 
              "enum": ["SELECT", "INSERT", "UPDATE", "DELETE", "CREATE", "ALTER", "DROP"] 
            },
            "tables_used": {
              "type": "array",
              "items": { "type": "string" }
            },
            "estimated_complexity": {
              "type": "string",
              "enum": ["low", "medium", "high"]
            },
            "execution_notes": {
              "type": "array",
              "items": { "type": "string" }
            },
            "validation_status": {
              "type": "object",
              "properties": {
                "is_valid": { "type": "boolean" },
                "syntax_errors": {
                  "type": "array",
                  "items": { "type": "string" }
                }
              },
              "required": ["is_valid", "syntax_errors"],
              "additionalProperties": false
            }
          },
          "required": ["query", "query_type", "tables_used", "estimated_complexity", "execution_notes", "validation_status"],
          "additionalProperties": false
        }
      }
    }
  }'
```

Example Output

JSON

```
{
  "query": "SELECT c.name, c.email, SUM(o.total_amount) as total_order_amount FROM customers c JOIN orders o ON c.customer_id = o.customer_id WHERE o.order_date >= DATE_SUB(NOW(), INTERVAL 30 DAY) AND o.total_amount > 500 GROUP BY c.customer_id, c.name, c.email ORDER BY total_order_amount DESC",
  "query_type": "SELECT",
  "tables_used": ["customers", "orders"],
  "estimated_complexity": "medium",
  "execution_notes": [
    "Query uses JOIN to connect customers and orders tables",
    "DATE_SUB function calculates 30 days ago from current date",
    "GROUP BY aggregates orders per customer",
    "Results ordered by total order amount descending"
  ],
  "validation_status": {
    "is_valid": true,
    "syntax_errors": []
  }
}
```

### [Email Classification](#email-classification)

You can classify emails into structured categories with confidence scores, priority levels, and suggested actions.

  

JavaScript

```
1import Groq from "groq-sdk";
2
3const groq = new Groq();
4
5const response = await groq.chat.completions.create({
6  model: "moonshotai/kimi-k2-instruct-0905",
7  messages: [
8    {
9      role: "system",
10      content: "You are an email classification expert. Classify emails into structured categories with confidence scores, priority levels, and suggested actions.",
11    },
12    { role: "user", content: "Subject: URGENT: Server downtime affecting production\n\nHi Team,\n\nOur main production server went down at 2:30 PM EST. Customer-facing services are currently unavailable. We need immediate action to restore services. Please join the emergency call.\n\nBest regards,\nDevOps Team" },
13  ],
14  response_format: {
15    type: "json_schema",
16    json_schema: {
17      name: "email_classification",
18      schema: {
19        type: "object",
20        properties: {
21          category: { 
22            type: "string", 
23            enum: ["urgent", "support", "sales", "marketing", "internal", "spam", "notification"] 
24          },
25          priority: { 
26            type: "string", 
27            enum: ["low", "medium", "high", "critical"] 
28          },
29          confidence_score: { 
30            type: "number", 
31            minimum: 0, 
32            maximum: 1 
33          },
34          sentiment: { 
35            type: "string", 
36            enum: ["positive", "negative", "neutral"] 
37          },
38          key_entities: {
39            type: "array",
40            items: {
41              type: "object",
42              properties: {
43                entity: { type: "string" },
44                type: { 
45                  type: "string", 
46                  enum: ["person", "organization", "location", "datetime", "system", "product"] 
47                }
48              },
49              required: ["entity", "type"],
50              additionalProperties: false
51            }
52          },
53          suggested_actions: {
54            type: "array",
55            items: { type: "string" }
56          },
57          requires_immediate_attention: { type: "boolean" },
58          estimated_response_time: { type: "string" }
59        },
60        required: ["category", "priority", "confidence_score", "sentiment", "key_entities", "suggested_actions", "requires_immediate_attention", "estimated_response_time"],
61        additionalProperties: false
62      }
63    }
64  }
65});
66
67const result = JSON.parse(response.choices[0].message.content || "{}");
68console.log(result);
```

```
from groq import Groq
from pydantic import BaseModel
import json

client = Groq()

class KeyEntity(BaseModel):
    entity: str
    type: str

class EmailClassification(BaseModel):
    category: str
    priority: str
    confidence_score: float
    sentiment: str
    key_entities: list[KeyEntity]
    suggested_actions: list[str]
    requires_immediate_attention: bool
    estimated_response_time: str

response = client.chat.completions.create(
    model="moonshotai/kimi-k2-instruct-0905",
    messages=[
        {
            "role": "system",
            "content": "You are an email classification expert. Classify emails into structured categories with confidence scores, priority levels, and suggested actions.",
        },
        {"role": "user", "content": "Subject: URGENT: Server downtime affecting production\\n\\nHi Team,\\n\\nOur main production server went down at 2:30 PM EST. Customer-facing services are currently unavailable. We need immediate action to restore services. Please join the emergency call.\\n\\nBest regards,\\nDevOps Team"},
    ],
    response_format={
        "type": "json_schema",
        "json_schema": {
            "name": "email_classification",
            "schema": EmailClassification.model_json_schema()
        }
    }
)

email_classification = EmailClassification.model_validate(json.loads(response.choices[0].message.content))
print(json.dumps(email_classification.model_dump(), indent=2))
```

```
curl https://api.groq.com/openai/v1/chat/completions \
  -H "Authorization: Bearer $GROQ_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "moonshotai/kimi-k2-instruct-0905",
    "messages": [
      {
        "role": "system",
        "content": "You are an email classification expert. Classify emails into structured categories with confidence scores, priority levels, and suggested actions."
      },
      {
        "role": "user",
        "content": "Subject: URGENT: Server downtime affecting production\n\nHi Team,\n\nOur main production server went down at 2:30 PM EST. Customer-facing services are currently unavailable. We need immediate action to restore services. Please join the emergency call.\n\nBest regards,\nDevOps Team"
      }
    ],
    "response_format": {
      "type": "json_schema",
      "json_schema": {
        "name": "email_classification",
        "schema": {
          "type": "object",
          "properties": {
            "category": { 
              "type": "string", 
              "enum": ["urgent", "support", "sales", "marketing", "internal", "spam", "notification"] 
            },
            "priority": { 
              "type": "string", 
              "enum": ["low", "medium", "high", "critical"] 
            },
            "confidence_score": { 
              "type": "number", 
              "minimum": 0, 
              "maximum": 1 
            },
            "sentiment": { 
              "type": "string", 
              "enum": ["positive", "negative", "neutral"] 
            },
            "key_entities": {
              "type": "array",
              "items": {
                "type": "object",
                "properties": {
                  "entity": { "type": "string" },
                  "type": { 
                    "type": "string", 
                    "enum": ["person", "organization", "location", "datetime", "system", "product"] 
                  }
                },
                "required": ["entity", "type"],
                "additionalProperties": false
              }
            },
            "suggested_actions": {
              "type": "array",
              "items": { "type": "string" }
            },
            "requires_immediate_attention": { "type": "boolean" },
            "estimated_response_time": { "type": "string" }
          },
          "required": ["category", "priority", "confidence_score", "sentiment", "key_entities", "suggested_actions", "requires_immediate_attention", "estimated_response_time"],
          "additionalProperties": false
        }
      }
    }
  }'
```

Example Output

JSON

```
{
  "category": "urgent",
  "priority": "critical",
  "confidence_score": 0.95,
  "sentiment": "negative",
  "key_entities": [
      {
        "entity": "production server",
        "type": "system"
      },
      {
        "entity": "2:30 PM EST",
        "type": "datetime"
      },
      {
        "entity": "DevOps Team",
        "type": "organization"
      },
      {
        "entity": "customer-facing services",
        "type": "system"
      }
  ],
  "suggested_actions": [
      "Join emergency call immediately",
      "Escalate to senior DevOps team",
      "Activate incident response protocol",
      "Prepare customer communication",
      "Monitor service restoration progress"
  ],
  "requires_immediate_attention": true,
  "estimated_response_time": "immediate"
}
```

### [API Response Validation](#api-response-validation)

You can validate and structure API responses with error handling, status codes, and standardized data formats for reliable integration.

  

JavaScript

```
1import Groq from "groq-sdk";
2
3const groq = new Groq();
4
5const response = await groq.chat.completions.create({
6  model: "moonshotai/kimi-k2-instruct-0905",
7  messages: [
8    {
9      role: "system",
10      content: "You are an API response validation expert. Validate and structure API responses with error handling, status codes, and standardized data formats for reliable integration.",
11    },
12    { role: "user", content: "Validate this API response: {\"user_id\": \"12345\", \"email\": \"invalid-email\", \"created_at\": \"2024-01-15T10:30:00Z\", \"status\": \"active\", \"profile\": {\"name\": \"John Doe\", \"age\": 25}}" },
13  ],
14  response_format: {
15    type: "json_schema",
16    json_schema: {
17      name: "api_response_validation",
18      schema: {
19        type: "object",
20        properties: {
21          validation_result: {
22            type: "object",
23            properties: {
24              is_valid: { type: "boolean" },
25              status_code: { type: "integer" },
26              error_count: { type: "integer" }
27            },
28            required: ["is_valid", "status_code", "error_count"],
29            additionalProperties: false
30          },
31          field_validations: {
32            type: "array",
33            items: {
34              type: "object",
35              properties: {
36                field_name: { type: "string" },
37                field_type: { type: "string" },
38                is_valid: { type: "boolean" },
39                error_message: { type: "string" },
40                expected_format: { type: "string" }
41              },
42              required: ["field_name", "field_type", "is_valid", "error_message", "expected_format"],
43              additionalProperties: false
44            }
45          },
46          data_quality_score: { 
47            type: "number", 
48            minimum: 0, 
49            maximum: 1 
50          },
51          suggested_fixes: {
52            type: "array",
53            items: { type: "string" }
54          },
55          compliance_check: {
56            type: "object",
57            properties: {
58              follows_rest_standards: { type: "boolean" },
59              has_proper_error_handling: { type: "boolean" },
60              includes_metadata: { type: "boolean" }
61            },
62            required: ["follows_rest_standards", "has_proper_error_handling", "includes_metadata"],
63            additionalProperties: false
64          },
65          standardized_response: {
66            type: "object",
67            properties: {
68              success: { type: "boolean" },
69              data: { type: "object" },
70              errors: {
71                type: "array",
72                items: { type: "string" }
73              },
74              metadata: {
75                type: "object",
76                properties: {
77                  timestamp: { type: "string" },
78                  request_id: { type: "string" },
79                  version: { type: "string" }
80                },
81                required: ["timestamp", "request_id", "version"],
82                additionalProperties: false
83              }
84            },
85            required: ["success", "data", "errors", "metadata"],
86            additionalProperties: false
87          }
88        },
89        required: ["validation_result", "field_validations", "data_quality_score", "suggested_fixes", "compliance_check", "standardized_response"],
90        additionalProperties: false
91      }
92    }
93  }
94});
95
96const result = JSON.parse(response.choices[0].message.content || "{}");
97console.log(result);
```

```
from groq import Groq
from pydantic import BaseModel
import json

client = Groq()

class ValidationResult(BaseModel):
    is_valid: bool
    status_code: int
    error_count: int

class FieldValidation(BaseModel):
    field_name: str
    field_type: str
    is_valid: bool
    error_message: str
    expected_format: str

class ComplianceCheck(BaseModel):
    follows_rest_standards: bool
    has_proper_error_handling: bool
    includes_metadata: bool

class Metadata(BaseModel):
    timestamp: str
    request_id: str
    version: str

class StandardizedResponse(BaseModel):
    success: bool
    data: dict
    errors: list[str]
    metadata: Metadata

class APIResponseValidation(BaseModel):
    validation_result: ValidationResult
    field_validations: list[FieldValidation]
    data_quality_score: float
    suggested_fixes: list[str]
    compliance_check: ComplianceCheck
    standardized_response: StandardizedResponse

response = client.chat.completions.create(
    model="moonshotai/kimi-k2-instruct-0905",
    messages=[
        {
            "role": "system",
            "content": "You are an API response validation expert. Validate and structure API responses with error handling, status codes, and standardized data formats for reliable integration.",
        },
        {"role": "user", "content": "Validate this API response: {\"user_id\": \"12345\", \"email\": \"invalid-email\", \"created_at\": \"2024-01-15T10:30:00Z\", \"status\": \"active\", \"profile\": {\"name\": \"John Doe\", \"age\": 25}}"},
    ],
    response_format={
        "type": "json_schema",
        "json_schema": {
            "name": "api_response_validation",
            "schema": APIResponseValidation.model_json_schema()
        }
    }
)

api_response_validation = APIResponseValidation.model_validate(json.loads(response.choices[0].message.content))
print(json.dumps(api_response_validation.model_dump(), indent=2))
```

```
curl https://api.groq.com/openai/v1/chat/completions \
  -H "Authorization: Bearer $GROQ_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "moonshotai/kimi-k2-instruct-0905",
    "messages": [
      {
        "role": "system",
        "content": "You are an API response validation expert. Validate and structure API responses with error handling, status codes, and standardized data formats for reliable integration."
      },
      {
        "role": "user",
        "content": "Validate this API response: {\"user_id\": \"12345\", \"email\": \"invalid-email\", \"created_at\": \"2024-01-15T10:30:00Z\", \"status\": \"active\", \"profile\": {\"name\": \"John Doe\", \"age\": 25}}"
      }
    ],
    "response_format": {
      "type": "json_schema",
      "json_schema": {
        "name": "api_response_validation",
        "schema": {
          "type": "object",
          "properties": {
            "validation_result": {
              "type": "object",
              "properties": {
                "is_valid": { "type": "boolean" },
                "status_code": { "type": "integer" },
                "error_count": { "type": "integer" }
              },
              "required": ["is_valid", "status_code", "error_count"],
              "additionalProperties": false
            },
            "field_validations": {
              "type": "array",
              "items": {
                "type": "object",
                "properties": {
                  "field_name": { "type": "string" },
                  "field_type": { "type": "string" },
                  "is_valid": { "type": "boolean" },
                  "error_message": { "type": "string" },
                  "expected_format": { "type": "string" }
                },
                "required": ["field_name", "field_type", "is_valid", "error_message", "expected_format"],
                "additionalProperties": false
              }
            },
            "data_quality_score": { 
              "type": "number", 
              "minimum": 0, 
              "maximum": 1 
            },
            "suggested_fixes": {
              "type": "array",
              "items": { "type": "string" }
            },
            "compliance_check": {
              "type": "object",
              "properties": {
                "follows_rest_standards": { "type": "boolean" },
                "has_proper_error_handling": { "type": "boolean" },
                "includes_metadata": { "type": "boolean" }
              },
              "required": ["follows_rest_standards", "has_proper_error_handling", "includes_metadata"],
              "additionalProperties": false
            },
            "standardized_response": {
              "type": "object",
              "properties": {
                "success": { "type": "boolean" },
                "data": { "type": "object" },
                "errors": {
                  "type": "array",
                  "items": { "type": "string" }
                },
                "metadata": {
                  "type": "object",
                  "properties": {
                    "timestamp": { "type": "string" },
                    "request_id": { "type": "string" },
                    "version": { "type": "string" }
                  },
                  "required": ["timestamp", "request_id", "version"],
                  "additionalProperties": false
                }
              },
              "required": ["success", "data", "errors", "metadata"],
              "additionalProperties": false
            }
          },
          "required": ["validation_result", "field_validations", "data_quality_score", "suggested_fixes", "compliance_check", "standardized_response"],
          "additionalProperties": false
        }
      }
    }
  }'
```

Example Output

JSON

```
{
  "validation_result": {
      "is_valid": false,
      "status_code": 400,
      "error_count": 2
  },
  "field_validations": [
      {
          "field_name": "user_id",
          "field_type": "string",
          "is_valid": true,
          "error_message": "",
          "expected_format": "string"
      },
      {
          "field_name": "email",
          "field_type": "string",
          "is_valid": false,
          "error_message": "Invalid email format",
          "expected_format": "valid email address (e.g., user@example.com)"
      }
  ],
  "data_quality_score": 0.7,
  "suggested_fixes": [
      "Fix email format validation to ensure proper email structure",
      "Add proper error handling structure to response"
  ],
  "compliance_check": {
      "follows_rest_standards": false,
      "has_proper_error_handling": false,
      "includes_metadata": false
  }
}
```

## [Schema Validation Libraries](#schema-validation-libraries)

When working with Structured Outputs, you can use popular schema validation libraries like [Zod](https://zod.dev/) for TypeScript and [Pydantic](https://docs.pydantic.dev/latest/) for Python. These libraries provide type safety, runtime validation, and seamless integration with JSON Schema generation.

### [Support Ticket Classification](#support-ticket-classification)

This example demonstrates how to classify customer support tickets using structured schemas with both Zod and Pydantic, ensuring consistent categorization and routing.

Zod (TypeScript)Pydantic (Python)

typescript

```
import Groq from "groq-sdk";
import { z } from "zod";

const groq = new Groq();

const supportTicketSchema = z.object({
  category: z.enum(["api", "billing", "account", "bug", "feature_request", "integration", "security", "performance"]),
  priority: z.enum(["low", "medium", "high", "critical"]),
  urgency_score: z.number(),
  customer_info: z.object({
    name: z.string(),
    company: z.string().optional(),
    tier: z.enum(["free", "paid", "enterprise", "trial"])
  }),
  technical_details: z.array(z.object({
    component: z.string(),
    error_code: z.string().optional(),
    description: z.string()
  })),
  keywords: z.array(z.string()),
  requires_escalation: z.boolean(),
  estimated_resolution_hours: z.number(),
  follow_up_date: z.string().datetime().optional(),
  summary: z.string()
});

type SupportTicket = z.infer<typeof supportTicketSchema>;

const response = await groq.chat.completions.create({
  model: "moonshotai/kimi-k2-instruct-0905",
  messages: [
    {
      role: "system",
      content: `You are a customer support ticket classifier for SaaS companies. 
                Analyze support tickets and categorize them for efficient routing and resolution.
                Output JSON only using the schema provided.`,
    },
    { 
      role: "user", 
      content: `Hello! I love your product and have been using it for 6 months. 
                I was wondering if you could add a dark mode feature to the dashboard? 
                Many of our team members work late hours and would really appreciate this. 
                Also, it would be great to have keyboard shortcuts for common actions. 
                Not urgent, but would be a nice enhancement! 
                Best, Mike from StartupXYZ`
    },
  ],
  response_format: {
    type: "json_schema",
    json_schema: {
      name: "support_ticket_classification",
      schema: z.toJSONSchema(supportTicketSchema)
    }
  }
});

const rawResult = JSON.parse(response.choices[0].message.content || "{}");
const result = supportTicketSchema.parse(rawResult);
console.log(result);
```

python

```
from groq import Groq
from pydantic import BaseModel, Field
from typing import List, Optional, Literal
from enum import Enum
import json

client = Groq()

class SupportCategory(str, Enum):
    API = "api"
    BILLING = "billing"
    ACCOUNT = "account"
    BUG = "bug"
    FEATURE_REQUEST = "feature_request"
    INTEGRATION = "integration"
    SECURITY = "security"
    PERFORMANCE = "performance"

class Priority(str, Enum):
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"

class CustomerTier(str, Enum):
    FREE = "free"
    PAID = "paid"
    ENTERPRISE = "enterprise"
    TRIAL = "trial"

class CustomerInfo(BaseModel):
    name: str
    company: Optional[str] = None
    tier: CustomerTier

class TechnicalDetail(BaseModel):
    component: str
    error_code: Optional[str] = None
    description: str

class SupportTicket(BaseModel):
    category: SupportCategory
    priority: Priority
    urgency_score: float
    customer_info: CustomerInfo
    technical_details: List[TechnicalDetail]
    keywords: List[str]
    requires_escalation: bool
    estimated_resolution_hours: float
    follow_up_date: Optional[str] = Field(None, description="ISO datetime string")
    summary: str

response = client.chat.completions.create(
    model="moonshotai/kimi-k2-instruct-0905",
    messages=[
        {
            "role": "system",
            "content": """You are a customer support ticket classifier for SaaS companies. 
                         Analyze support tickets and categorize them for efficient routing and resolution.
                         Output JSON only using the schema provided.""",
        },
        { 
            "role": "user", 
            "content": """Hello! I love your product and have been using it for 6 months. 
                         I was wondering if you could add a dark mode feature to the dashboard? 
                         Many of our team members work late hours and would really appreciate this. 
                         Also, it would be great to have keyboard shortcuts for common actions. 
                         Not urgent, but would be a nice enhancement! 
                         Best, Mike from StartupXYZ"""
        },
    ],
    response_format={
        "type": "json_schema",
        "json_schema": {
            "name": "support_ticket_classification",
            "schema": SupportTicket.model_json_schema()
        }
    }
)

raw_result = json.loads(response.choices[0].message.content or "{}")
result = SupportTicket.model_validate(raw_result)
print(result.model_dump_json(indent=2))
```

Example Output

JSON

```
{
  "category": "feature_request",
  "priority": "low",
  "urgency_score": 2.5,
  "customer_info": {
      "name": "Mike",
      "company": "StartupXYZ",
      "tier": "paid"
  },
  "technical_details": [
      {
          "component": "dashboard",
          "description": "Request for dark mode feature"
      },
      {
          "component": "user_interface",
          "description": "Request for keyboard shortcuts"
      }
  ],
  "keywords": ["dark mode", "dashboard", "keyboard shortcuts", "enhancement"],
  "requires_escalation": false,
  "estimated_resolution_hours": 40,
  "summary": "Feature request for dark mode and keyboard shortcuts from paying customer"
}
```

## [Implementation Guide](#implementation-guide)

### [Schema Definition](#schema-definition)

Design your JSON Schema to constrain model responses. Reference the [examples](#examples) above and see [supported schema features](#schema-requirements) for technical limitations.

  

**Schema optimization tips:**

*   Use descriptive property names and clear descriptions for complex fields
*   Create evaluation sets to test schema effectiveness
*   Include titles for important structural elements

### [API Integration](#api-integration)

Include the schema in your API request using the `response_format` parameter:

JSON

```
response_format: { type: "json_schema", json_schema: { name: "schema_name", schema:  } }
```

  

Complete implementation example:

Python

```
1from groq import Groq
2import json
3
4client = Groq()
5
6response = client.chat.completions.create(
7    model="moonshotai/kimi-k2-instruct-0905",
8    messages=[
9        {"role": "system", "content": "You are a helpful math tutor. Guide the user through the solution step by step."},
10        {"role": "user", "content": "how can I solve 8x + 7 = -23"}
11    ],
12    response_format={
13        "type": "json_schema",
14        "json_schema": {
15            "name": "math_response",
16            "schema": {
17                "type": "object",
18                "properties": {
19                    "steps": {
20                        "type": "array",
21                        "items": {
22                            "type": "object",
23                            "properties": {
24                                "explanation": {"type": "string"},
25                                "output": {"type": "string"}
26                            },
27                            "required": ["explanation", "output"],
28                            "additionalProperties": False
29                        }
30                    },
31                    "final_answer": {"type": "string"}
32                },
33                "required": ["steps", "final_answer"],
34                "additionalProperties": False
35            }
36        }
37    }
38)
39
40result = json.loads(response.choices[0].message.content)
41print(json.dumps(result, indent=2))
```

```
import Groq from "groq-sdk";

const groq = new Groq();

const response = await groq.chat.completions.create({
    model: "moonshotai/kimi-k2-instruct-0905",
    messages: [
        { role: "system", content: "You are a helpful math tutor. Guide the user through the solution step by step." },
        { role: "user", content: "how can I solve 8x + 7 = -23" }
    ],
    response_format: {
        type: "json_schema",
        json_schema: {
            name: "math_response",
            schema: {
                type: "object",
                properties: {
                    steps: {
                        type: "array",
                        items: {
                            type: "object",
                            properties: {
                                explanation: { type: "string" },
                                output: { type: "string" }
                            },
                            required: ["explanation", "output"],
                            additionalProperties: false
                        }
                    },
                    final_answer: { type: "string" }
                },
                required: ["steps", "final_answer"],
                additionalProperties: false
            }
        }
    }
});

const result = JSON.parse(response.choices[0].message.content || "{}");
console.log(result);
```

```
curl https://api.groq.com/openai/v1/chat/completions \
  -H "Authorization: Bearer $GROQ_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "moonshotai/kimi-k2-instruct-0905",
    "messages": [
      {
        "role": "system",
        "content": "You are a helpful math tutor. Guide the user through the solution step by step."
      },
      {
        "role": "user",
        "content": "how can I solve 8x + 7 = -23"
      }
    ],
    "response_format": {
      "type": "json_schema",
      "json_schema": {
        "name": "math_response",
        "schema": {
          "type": "object",
          "properties": {
            "steps": {
              "type": "array",
              "items": {
                "type": "object",
                "properties": {
                  "explanation": { "type": "string" },
                  "output": { "type": "string" }
                },
                "required": ["explanation", "output"],
                "additionalProperties": false
              }
            },
            "final_answer": { "type": "string" }
          },
          "required": ["steps", "final_answer"],
          "additionalProperties": false
        }
      }
    }
  }'
```

### [Error Handling](#error-handling)

Schema validation failures return HTTP 400 errors with the message `Generated JSON does not match the expected schema. Please adjust your prompt.`

  

**Resolution strategies:**

*   Retry requests for transient failures
*   Refine prompts for recurring schema mismatches
*   Simplify complex schemas if validation consistently fails

### [Best Practices](#best-practices)

**User input handling:** Include explicit instructions for invalid or incompatible inputs. Models attempt schema adherence even with unrelated data, potentially causing hallucinations. Specify fallback responses (empty fields, error messages) for incompatible inputs.

  

**Output quality:** Structured outputs are designed to output schema compliance but not semantic accuracy. For persistent errors, refine instructions, add system message examples, or decompose complex tasks. See the [prompt engineering guide](/docs/prompting) for optimization techniques.

## [Schema Requirements](#schema-requirements)

Structured Outputs supports a [JSON Schema](https://json-schema.org/docs) subset with specific constraints for performance and reliability.

### [Supported Data Types](#supported-data-types)

*   **Primitives:** String, Number, Boolean, Integer
*   **Complex:** Object, Array, Enum
*   **Composition:** anyOf (union types)

### [Mandatory Constraints](#mandatory-constraints)

**Required fields:** All schema properties must be marked as `required`. Optional fields are not supported.

  

JSON

```
{
  "name": "create_task",
  "description": "Creates a new task in the project management system",
  "strict": true,
  "parameters": {
    "type": "object",
    "properties": {
      "title": {
        "type": "string",
        "description": "The task title or summary"
      },
      "priority": {
        "type": "string",
        "description": "Task priority level",
        "enum": ["low", "medium", "high", "urgent"]
      }
    },
    "additionalProperties": false,
    "required": ["title", "priority"]
  }
}
```

  

**Closed objects:** All objects must set `additionalProperties: false` to prevent undefined properties. This ensures strict schema adherence.

  

JSON

```
{
  "name": "book_appointment",
  "description": "Books a medical appointment",
  "strict": true,
  "schema": {
    "type": "object",
    "properties": {
      "patient_name": {
        "type": "string",
        "description": "Full name of the patient"
      },
      "appointment_type": {
        "type": "string",
        "description": "Type of medical appointment",
        "enum": ["consultation", "checkup", "surgery", "emergency"]
      }
    },
    "additionalProperties": false,
    "required": ["patient_name", "appointment_type"]
  }
}
```

  

**Union types:** Each schema within `anyOf` must comply with all subset restrictions:

  

JSON

```
{
  "type": "object",
  "properties": {
    "payment_method": {
      "anyOf": [
        {
          "type": "object",
          "description": "Credit card payment information",
          "properties": {
            "card_number": {
              "type": "string",
              "description": "The credit card number"
            },
            "expiry_date": {
              "type": "string",
              "description": "Card expiration date in MM/YY format"
            },
            "cvv": {
              "type": "string",
              "description": "Card security code"
            }
          },
          "additionalProperties": false,
          "required": ["card_number", "expiry_date", "cvv"]
        },
        {
          "type": "object",
          "description": "Bank transfer payment information",
          "properties": {
            "account_number": {
              "type": "string",
              "description": "Bank account number"
            },
            "routing_number": {
              "type": "string",
              "description": "Bank routing number"
            },
            "bank_name": {
              "type": "string",
              "description": "Name of the bank"
            }
          },
          "additionalProperties": false,
          "required": ["account_number", "routing_number", "bank_name"]
        }
      ]
    }
  },
  "additionalProperties": false,
  "required": ["payment_method"]
}
```

  

**Reusable subschemas:** Define reusable components with `$defs` and reference them using `$ref`:

  

JSON

```
{
  "type": "object",
  "properties": {
    "milestones": {
      "type": "array",
      "items": {
        "$ref": "#/$defs/milestone"
      }
    },
    "project_status": {
      "type": "string",
      "enum": ["planning", "in_progress", "completed", "on_hold"]
    }
  },
  "$defs": {
    "milestone": {
      "type": "object",
      "properties": {
        "title": {
          "type": "string",
          "description": "Milestone name"
        },
        "deadline": {
          "type": "string",
          "description": "Due date in ISO format"
        },
        "completed": {
          "type": "boolean"
        }
      },
      "required": ["title", "deadline", "completed"],
      "additionalProperties": false
    }
  },
  "required": ["milestones", "project_status"],
  "additionalProperties": false
}
```

  

**Root recursion:** Use `#` to reference the root schema:

  

JSON

```
{
  "name": "organization_chart",
  "description": "Company organizational structure",
  "strict": true,
  "schema": {
    "type": "object",
    "properties": {
      "employee_id": {
        "type": "string",
        "description": "Unique employee identifier"
      },
      "name": {
        "type": "string",
        "description": "Employee full name"
      },
      "position": {
        "type": "string",
        "description": "Job title or position",
        "enum": ["CEO", "Manager", "Developer", "Designer", "Analyst", "Intern"]
      },
      "direct_reports": {
        "type": "array",
        "description": "Employees reporting to this person",
        "items": {
          "$ref": "#"
        }
      },
      "contact_info": {
        "type": "array",
        "description": "Contact information for the employee",
        "items": {
          "type": "object",
          "properties": {
            "type": {
              "type": "string",
              "description": "Type of contact info",
              "enum": ["email", "phone", "slack"]
            },
            "value": {
              "type": "string",
              "description": "The contact value"
            }
          },
          "additionalProperties": false,
          "required": ["type", "value"]
        }
      }
    },
    "required": [
      "employee_id",
      "name",
      "position",
      "direct_reports",
      "contact_info"
    ],
    "additionalProperties": false
  }
}
```

  

**Explicit recursion** through definition references:

  

JSON

```
{
  "type": "object",
  "properties": {
    "file_system": {
      "$ref": "#/$defs/file_node"
    }
  },
  "$defs": {
    "file_node": {
      "type": "object",
      "properties": {
        "name": {
          "type": "string",
          "description": "File or directory name"
        },
        "type": {
          "type": "string",
          "enum": ["file", "directory"]
        },
        "size": {
          "type": "number",
          "description": "Size in bytes (0 for directories)"
        },
        "children": {
          "anyOf": [
            {
              "type": "array",
              "items": {
                "$ref": "#/$defs/file_node"
              }
            },
            {
              "type": "null"
            }
          ]
        }
      },
      "additionalProperties": false,
      "required": ["name", "type", "size", "children"]
    }
  },
  "additionalProperties": false,
  "required": ["file_system"]
}
```

## [JSON Object Mode](#json-object-mode)

JSON Object Mode provides basic JSON output validation without schema enforcement. Unlike Structured Outputs with `json_schema` mode, it is designed to output valid JSON syntax but not schema compliance. The endpoint will either return valid JSON or throw an error if the model cannot produce valid JSON syntax. Use [Structured Outputs](#introduction) when available for your use case.

  

Enable JSON Object Mode by setting `response_format` to `{ "type": "json_object" }`.

  

**Requirements and limitations:**

*   Include explicit JSON instructions in your prompt (system message or user input)
*   Outputs are syntactically valid JSON but may not match your intended schema
*   Combine with validation libraries and retry logic for schema compliance

### [Sentiment Analysis Example](#sentiment-analysis-example)

This example shows prompt-guided JSON generation for sentiment analysis, adaptable to classification, extraction, or summarization tasks:

JavaScript

```
1import { Groq } from "groq-sdk";
2
3const groq = new Groq();
4
5async function main() {
6  const response = await groq.chat.completions.create({
7    model: "openai/gpt-oss-20b",
8    messages: [
9      {
10        role: "system",
11        content: `You are a data analysis API that performs sentiment analysis on text.
12                Respond only with JSON using this format:
13                {
14                    "sentiment_analysis": {
15                    "sentiment": "positive|negative|neutral",
16                    "confidence_score": 0.95,
17                    "key_phrases": [
18                        {
19                        "phrase": "detected key phrase",
20                        "sentiment": "positive|negative|neutral"
21                        }
22                    ],
23                    "summary": "One sentence summary of the overall sentiment"
24                    }
25                }`
26      },
27      { role: "user", content: "Analyze the sentiment of this customer review: 'I absolutely love this product! The quality exceeded my expectations, though shipping took longer than expected.'" }
28    ],
29    response_format: { type: "json_object" }
30  });
31
32  const result = JSON.parse(response.choices[0].message.content || "{}");
33  console.log(result);
34}
35
36main();
```

```
from groq import Groq
import json

client = Groq()

def main():
    response = client.chat.completions.create(
        model="llama-3.3-70b-versatile",
        messages=[
            {
                "role": "system",
                "content": """You are a data analysis API that performs sentiment analysis on text.
                Respond only with JSON using this format:
                {
                    "sentiment_analysis": {
                    "sentiment": "positive|negative|neutral",
                    "confidence_score": 0.95,
                    "key_phrases": [
                        {
                        "phrase": "detected key phrase",
                        "sentiment": "positive|negative|neutral"
                        }
                    ],
                    "summary": "One sentence summary of the overall sentiment"
                    }
                }"""
            },
            {
                "role": "user", 
                "content": "Analyze the sentiment of this customer review: 'I absolutely love this product! The quality exceeded my expectations, though shipping took longer than expected.'"
            }
        ],
        response_format={"type": "json_object"}
    )

    result = json.loads(response.choices[0].message.content)
    print(json.dumps(result, indent=2))

if __name__ == "__main__":
    main()
```

```
curl https://api.groq.com/openai/v1/chat/completions \
  -H "Authorization: Bearer $GROQ_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "llama-3.3-70b-versatile",
    "messages": [
      {
        "role": "system",
        "content": "You are a data analysis API that performs sentiment analysis on text. Respond only with JSON using this format: { \"sentiment_analysis\": { \"sentiment\": \"positive|negative|neutral\", \"confidence_score\": 0.95, \"key_phrases\": [ { \"phrase\": \"detected key phrase\", \"sentiment\": \"positive|negative|neutral\" } ], \"summary\": \"One sentence summary of the overall sentiment\" } }"
      },
      {
        "role": "user",
        "content": "Analyze the sentiment of this customer review: '\''I absolutely love this product! The quality exceeded my expectations, though shipping took longer than expected.'\''"
      }
    ],
    "response_format": { "type": "json_object" }
  }'
```

System prompts structure the output format while maintaining JSON validity. However, keep in mind that the JSON object output may not match your schema.

  
Example Output

JSON

```
{
  "sentiment_analysis": {
    "sentiment": "positive",
    "confidence_score": 0.84,
    "key_phrases": [
        {
            "phrase": "absolutely love this product",
            "sentiment": "positive"
        },
        {
            "phrase": "quality exceeded my expectations",
            "sentiment": "positive"
        }
    ],
    "summary": "The reviewer loves the product's quality, but was slightly disappointed with the shipping time."
  }
}
```

  

**Response structure:**

*   **sentiment**: Classification (positive/negative/neutral)
*   **confidence\_score**: Confidence level (0-1 scale)
*   **key\_phrases**: Extracted phrases with individual sentiment scores
*   **summary**: Analysis overview and main findings

### Was this page helpful?

YesNoSuggest Edits

#### On this page

*   [Introduction](#introduction)
*   [Supported models](#supported-models)
*   [Examples](#examples)
*   [Schema Validation Libraries](#schema-validation-libraries)
*   [Implementation Guide](#implementation-guide)
*   [Schema Requirements](#schema-requirements)
*   [JSON Object Mode](#json-object-mode)

window\['dataLayer'\] = window\['dataLayer'\] || \[\]; function gtag(){window\['dataLayer'\].push(arguments);} gtag('js', new Date()); gtag('config', 'G-CQ9K0VPEEQ'); (function(w,l){ w\[l\]=w\[l\]||\[\]; w\[l\].push({'gtm.start': new Date().getTime(),event:'gtm.js'}); })(window,'dataLayer');